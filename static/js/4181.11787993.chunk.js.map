{"version":3,"file":"static/js/4181.11787993.chunk.js","mappings":"yHAOO,SAASA,EAAiBC,GAC/B,MAAMC,EAAc,IAAIC,WARnB,SAAaC,GAClB,IAAIC,EAAM,EACV,IAAK,MAAMC,KAASF,EAClBC,GAAOC,EAAMC,OAEf,OAAOF,CACT,CAEqCA,CAAIJ,IACvC,IAAIO,EAAS,EACb,IAAK,MAAMF,KAASL,EAClBC,EAAYO,IAAIH,EAAOE,GACvBA,GAAUF,EAAMC,OAElB,OAAOL,CACT,C,8BCJe,MAAMQ,EAEVC,QACAC,OACAC,WAHT,WAAAC,CACSH,EACAC,EACAC,EAAa,IAFb,KAAAF,QAAAA,EACA,KAAAC,OAAAA,EACA,KAAAC,WAAAA,CACN,CAEH,YAAME,CAAOC,EAAsBC,GACjC,IAAIC,EAAY,GAChB,MAGMC,EAHcH,EAAaI,MAAM,KAGR,GAAGC,cAC5BC,QAAYC,KAAKC,WAAWL,EAAYF,GAC9C,IAAKK,EACH,MAAO,GAGT,IAAI,IAAEG,EAAG,OAAEC,GAAWJ,EAClBK,GAAO,EACX,MAAMC,EAAU,IAAIC,YAAY,QAEhC,MAAQF,GAAM,CACZ,IAAIG,GAAiB,EACrB,MAAMC,EAAMH,EAAQI,OAAON,GAIrBO,EAAQF,EACXG,MAAM,EAAGH,EAAII,YAAY,OACzBf,MAAM,MACNgB,OAAOC,KAAOA,GAEXC,EAAQ,GACd,IAAK,MAAMC,KAAQN,EAAO,CACxB,MAAMO,EAAOD,EAAKnB,MAAM,KAAK,GACvBqB,EAAQD,EAAKE,WAAWvB,IACzBW,GAAkBW,IACrBX,GAAiB,GAKfU,EAAKN,MAAM,EAAGf,EAAWZ,QAAUY,IACrCQ,GAAO,GAELc,GACFH,EAAMK,KAAKJ,EAEf,CACA,MAAMK,EAAON,EAAMO,QAAQN,IACzB,MAAOO,KAASC,GAASR,EAAKnB,MAAM,KACpC,OAAO2B,EAAMC,IAAIC,GAAO,CAACH,EAAMG,EAAI7B,MAAM,KAAK,OAKhD,GAAIF,EAAUX,OAASqC,EAAKrC,OAASgB,KAAKV,aAAec,EAAM,CAC7D,MAAMuB,QAAa3B,KAAKX,OAAOuC,KAhEpB,MAgEqC1B,EAAKR,GAGrD,GAAoB,IAAhBiC,EAAK3C,OAAc,CACrBW,EAAYA,EAAUkC,OAAOR,GAC7B,KACF,CACAlB,EAAS1B,EAAiB,CAAC0B,EAAQwB,IACnCzB,GAxEW,KAyEb,MAIK,GAAIP,EAAUX,OAASqC,EAAKrC,QAAUgB,KAAKV,YAAcc,EAAM,CAClET,EAAYA,EAAUkC,OAAOR,GAC7B,KACF,CACF,CAGA,OCtFG,SAAmBS,EAAWC,EAAoBC,KAAKC,WAC5D,MAAMC,EAAa,GACbC,EAAS,IAAIC,IAEnB,IAAK,MAAMrD,KAAS+C,EAAM,CACxB,MAAMO,EAASN,EAAOhD,GAEjBoD,EAAOG,IAAID,KACdH,EAAMd,KAAKrC,GACXoD,EAAOI,IAAIF,GAEf,CAEA,OAAOH,CACT,CDwEWM,CAAO7C,EAAW+B,GAAOA,EAAI,IAAIf,MAAM,EAAGX,KAAKV,WACxD,CAEQ,cAAMmD,CAAS/C,GAKrB,aAJmBM,KAAKZ,QAAQsD,SAAS,CACvCC,SAAU,UACPjD,KAGFG,MAAM,MACNgB,OAAOC,KAAOA,GACdW,IAAIT,IACH,MAAM4B,EAAI5B,EAAKhC,OA5FF,GA6FP6D,EAAS7B,EAAKL,MAAM,EAAGiC,GACvBE,EAAS9B,EAAKL,MAAMiC,GAE1B,MAAO,CAACC,EADIE,OAAOC,SAASF,EAAQ,MAG1C,CAEQ,gBAAM7C,CACZL,EACAF,GAEA,IAAIuD,EAAQ,EACR/C,EAAM,MACV,MAAMgD,QAAgBlD,KAAKyC,SAAS/C,GACpC,IAAK,MAAOyD,EAAKC,KAAUF,EACNC,EAAIxC,MAAM,EAAGf,EAAWZ,QAC1BY,IACfqD,EAAQG,EACRlD,EAAMkD,EAAQ,OAKlB,MAAMC,EAAMnD,EAAM+C,EAClB,KAAII,EAAM,GAIV,MAAO,CACLlD,aAFmBH,KAAKX,OAAOuC,KAAKyB,EAAKJ,EAAOvD,GAGhDQ,MAEJ,E,+CExHF,SAASoD,EAA0BC,GACjC,IACE,OAAOC,mBAAmBD,EAC5B,CAAE,MAAOE,GAEP,OAAOF,CACT,CACF,CAEA,SAASG,EAAQlD,EAAae,EAAcoC,EAAI,IAC9C,MAAMC,EAAOpD,EAAIV,cAAc+D,QAAQtC,GAEvC,OAAOf,EAAIxB,OAAS,GAChBwB,GACCsD,KAAKC,IAAI,EAAGH,EAAOD,GAAK,EAAI,MAAQ,IACnCnD,EAAIG,MAAMmD,KAAKC,IAAI,EAAGH,EAAOD,GAAIC,EAAOrC,EAAKvC,OAAS2E,GAAGK,QACxDJ,EAAOrC,EAAKvC,OAASwB,EAAIxB,OAAS,MAAQ,GACnD,CAEe,MAAMiF,UACXC,EAAAA,YAOR3E,WAAAA,CACE4E,EACAC,EACAC,GAEAC,MAAMH,EAAQC,EAAeC,GAC7B,MAAME,GAAaC,EAAAA,EAAAA,gBAAeL,EAAQ,cACpCM,GAAcD,EAAAA,EAAAA,gBAAeL,EAAQ,eAE3C,IAAKI,EACH,MAAM,IAAIG,MAAM,uBAElB,IAAKD,EACH,MAAM,IAAIC,MAAM,wBAElB1E,KAAK2E,OAAS,IAAIxF,GAChByF,EAAAA,EAAAA,cAAaH,EAAaJ,IAC1BO,EAAAA,EAAAA,cAAaL,EAAYF,GACzB,KAEJ,CAOA,iBAAMQ,CAAYnG,GAChB,MAAMoG,EAAQpG,EAAKqG,YAAYjF,cACzBkF,EAAOF,EAAMjF,MAAM,KAEnBoF,SADgBjF,KAAK2E,OAAOnF,OAAOsF,IAGtCjE,OAAO,EAAE,CAAEqE,KACVF,EAAKG,MAAMC,GACT9B,EAA0B4B,GAAMpF,cAAcuF,SAASD,KAG1D3D,IAAI,EAAEF,EAAM2D,MACX,MAAMI,EAAStD,KAAKuD,MAAML,EAAKM,WAAW,IAAK,OACxCC,EAAKC,KAAYC,GAAQL,EAAO7D,IAAImE,GACzCtC,EAA0BsC,IAGtBC,EAAgBF,EAAKG,UAAUpE,KAASA,GACxCqE,EAAaJ,EAChBlE,IAAIC,GAAOA,EAAI5B,eACfgG,UAAUhF,GAAKA,EAAEuE,SAAS9D,EAAKzB,gBAE5BkG,EAAaL,EAAKE,GAClBI,EAAeN,EAAKI,GACpBG,GACY,IAAhBH,EAAoBrC,EAAQuC,EAAc1E,QAAQ4E,EAC9CC,EAAQ1C,EAAQsC,EAAYzE,GAE5B8E,EACHH,GAAWE,EAAMtG,gBAAkBoG,EAAQpG,cAExC,GAAGsG,MAAUF,KADbE,EAGN,OAAO,IAAIE,EAAAA,EAAW,CACpBC,UAAWd,EACXW,MAAOJ,EACPK,gBACAG,cAAelB,EAAO7D,IAAImE,GAAUpC,mBAAmBoC,IACvDF,cAIN,MAA2B,UAApBhH,EAAK+H,WACRxB,EAAUpE,OACRuE,GAAKA,EAAEsB,WAAW5G,gBAAkBpB,EAAKqG,YAAYjF,eAEvDmF,CACN,E","sources":["../../../node_modules/@gmod/trix/src/util.ts","../../../node_modules/@gmod/trix/src/index.ts","../../../node_modules/@gmod/trix/src/dedupe.ts","../../../plugins/trix/src/TrixTextSearchAdapter/TrixTextSearchAdapter.ts"],"sourcesContent":["export function sum(array: Uint8Array[]) {\n  let sum = 0\n  for (const entry of array) {\n    sum += entry.length\n  }\n  return sum\n}\nexport function concatUint8Array(args: Uint8Array[]) {\n  const mergedArray = new Uint8Array(sum(args))\n  let offset = 0\n  for (const entry of args) {\n    mergedArray.set(entry, offset)\n    offset += entry.length\n  }\n  return mergedArray\n}\n","import { dedupe } from './dedupe'\nimport { concatUint8Array } from './util'\n\nimport type { GenericFilehandle } from 'generic-filehandle2'\n\nconst CHUNK_SIZE = 65536\n\n// this is the number of hex characters to use for the address in ixixx, see\n// https://github.com/GMOD/ixixx-js/blob/master/src/index.ts#L182\nconst ADDRESS_SIZE = 10\n\nexport default class Trix {\n  constructor(\n    public ixxFile: GenericFilehandle,\n    public ixFile: GenericFilehandle,\n    public maxResults = 20,\n  ) {}\n\n  async search(searchString: string, opts?: { signal?: AbortSignal }) {\n    let resultArr = [] as [string, string][]\n    const searchWords = searchString.split(' ')\n\n    // we only search one word at a time\n    const searchWord = searchWords[0].toLowerCase()\n    const res = await this._getBuffer(searchWord, opts)\n    if (!res) {\n      return []\n    }\n\n    let { end, buffer } = res\n    let done = false\n    const decoder = new TextDecoder('utf8')\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n    while (!done) {\n      let foundSomething = false\n      const str = decoder.decode(buffer)\n\n      // slice to lastIndexOf('\\n') to make sure we get complete records\n      // since the buffer fetch could get halfway into a record\n      const lines = str\n        .slice(0, str.lastIndexOf('\\n'))\n        .split('\\n')\n        .filter(f => !!f)\n\n      const hits2 = [] as string[]\n      for (const line of lines) {\n        const word = line.split(' ')[0]\n        const match = word.startsWith(searchWord)\n        if (!foundSomething && match) {\n          foundSomething = true\n        }\n\n        // we are done scanning if we are lexicographically greater than the\n        // search string\n        if (word.slice(0, searchWord.length) > searchWord) {\n          done = true\n        }\n        if (match) {\n          hits2.push(line)\n        }\n      }\n      const hits = hits2.flatMap(line => {\n        const [term, ...parts] = line.split(' ')\n        return parts.map(elt => [term, elt.split(',')[0]] as [string, string])\n      })\n\n      // if we are not done, and we haven't filled up maxResults with hits yet,\n      // then refetch\n      if (resultArr.length + hits.length < this.maxResults && !done) {\n        const res2 = await this.ixFile.read(CHUNK_SIZE, end, opts)\n\n        // early break if empty response\n        if (res2.length === 0) {\n          resultArr = resultArr.concat(hits)\n          break\n        }\n        buffer = concatUint8Array([buffer, res2])\n        end += CHUNK_SIZE\n      }\n\n      // if we have filled up the hits, or we are detected to be done via the\n      // filtering, then return\n      else if (resultArr.length + hits.length >= this.maxResults || done) {\n        resultArr = resultArr.concat(hits)\n        break\n      }\n    }\n\n    // de-duplicate results based on the detail column (resultArr[1])\n    return dedupe(resultArr, elt => elt[1]).slice(0, this.maxResults)\n  }\n\n  private async getIndex(opts?: { signal?: AbortSignal }) {\n    const file = await this.ixxFile.readFile({\n      encoding: 'utf8',\n      ...opts,\n    })\n    return file\n      .split('\\n')\n      .filter(f => !!f)\n      .map(line => {\n        const p = line.length - ADDRESS_SIZE\n        const prefix = line.slice(0, p)\n        const posStr = line.slice(p)\n        const pos = Number.parseInt(posStr, 16)\n        return [prefix, pos] as const\n      })\n  }\n\n  private async _getBuffer(\n    searchWord: string,\n    opts?: { signal?: AbortSignal },\n  ) {\n    let start = 0\n    let end = 65536\n    const indexes = await this.getIndex(opts)\n    for (const [key, value] of indexes) {\n      const trimmedKey = key.slice(0, searchWord.length)\n      if (trimmedKey < searchWord) {\n        start = value\n        end = value + 65536\n      }\n    }\n\n    // Return the buffer and its end position in the file.\n    const len = end - start\n    if (len < 0) {\n      return undefined\n    }\n    const buffer = await this.ixFile.read(len, start, opts)\n    return {\n      buffer,\n      end,\n    }\n  }\n}\n","type Hasher<T> = (input: T) => string\n\n// from https://github.com/seriousManual/dedupe/blob/master/LICENSE\nexport function dedupe<T>(list: T[], hasher: Hasher<T> = JSON.stringify) {\n  const clone: T[] = []\n  const lookup = new Set<string>()\n\n  for (const entry of list) {\n    const hashed = hasher(entry)\n\n    if (!lookup.has(hashed)) {\n      clone.push(entry)\n      lookup.add(hashed)\n    }\n  }\n\n  return clone\n}\n","import Trix from '@gmod/trix'\nimport BaseResult from '@jbrowse/core/TextSearch/BaseResults'\nimport { readConfObject } from '@jbrowse/core/configuration'\nimport { BaseAdapter } from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { openLocation } from '@jbrowse/core/util/io'\n\nimport type PluginManager from '@jbrowse/core/PluginManager'\nimport type { AnyConfigurationModel } from '@jbrowse/core/configuration'\nimport type {\n  BaseTextSearchAdapter,\n  BaseTextSearchArgs,\n} from '@jbrowse/core/data_adapters/BaseAdapter'\nimport type { getSubAdapterType } from '@jbrowse/core/data_adapters/dataAdapterCache'\n\nfunction decodeURIComponentNoThrow(uri: string) {\n  try {\n    return decodeURIComponent(uri)\n  } catch (e) {\n    // avoid throwing exception on a failure to decode URI component\n    return uri\n  }\n}\n\nfunction shorten(str: string, term: string, w = 15) {\n  const tidx = str.toLowerCase().indexOf(term)\n\n  return str.length < 40\n    ? str\n    : (Math.max(0, tidx - w) > 0 ? '...' : '') +\n        str.slice(Math.max(0, tidx - w), tidx + term.length + w).trim() +\n        (tidx + term.length < str.length ? '...' : '')\n}\n\nexport default class TrixTextSearchAdapter\n  extends BaseAdapter\n  implements BaseTextSearchAdapter\n{\n  indexingAttributes?: string[]\n  trixJs: Trix\n  tracksNames?: string[]\n\n  constructor(\n    config: AnyConfigurationModel,\n    getSubAdapter?: getSubAdapterType,\n    pluginManager?: PluginManager,\n  ) {\n    super(config, getSubAdapter, pluginManager)\n    const ixFilePath = readConfObject(config, 'ixFilePath')\n    const ixxFilePath = readConfObject(config, 'ixxFilePath')\n\n    if (!ixFilePath) {\n      throw new Error('must provide out.ix')\n    }\n    if (!ixxFilePath) {\n      throw new Error('must provide out.ixx')\n    }\n    this.trixJs = new Trix(\n      openLocation(ixxFilePath, pluginManager),\n      openLocation(ixFilePath, pluginManager),\n      1500,\n    )\n  }\n\n  /**\n   * Returns list of results\n   * @param args - search options/arguments include: search query\n   * limit of results to return, searchType...prefix | full | exact\", etc.\n   */\n  async searchIndex(args: BaseTextSearchArgs) {\n    const query = args.queryString.toLowerCase()\n    const strs = query.split(' ')\n    const results = await this.trixJs.search(query)\n    const formatted = results\n      // if multi-word search try to filter out relevant items\n      .filter(([, data]) =>\n        strs.every(r =>\n          decodeURIComponentNoThrow(data).toLowerCase().includes(r),\n        ),\n      )\n      .map(([term, data]) => {\n        const result = JSON.parse(data.replaceAll('|', ',')) as string[]\n        const [loc, trackId, ...rest] = result.map(record =>\n          decodeURIComponentNoThrow(record),\n        )\n\n        const labelFieldIdx = rest.findIndex(elt => !!elt)\n        const contextIdx = rest\n          .map(elt => elt.toLowerCase())\n          .findIndex(f => f.includes(term.toLowerCase()))\n\n        const labelField = rest[labelFieldIdx]!\n        const contextField = rest[contextIdx]!\n        const context =\n          contextIdx !== -1 ? shorten(contextField, term) : undefined\n        const label = shorten(labelField, term)\n\n        const displayString =\n          !context || label.toLowerCase() === context.toLowerCase()\n            ? label\n            : `${label} (${context})`\n\n        return new BaseResult({\n          locString: loc,\n          label: labelField,\n          displayString,\n          matchedObject: result.map(record => decodeURIComponent(record)),\n          trackId,\n        })\n      })\n\n    return args.searchType === 'exact'\n      ? formatted.filter(\n          r => r.getLabel().toLowerCase() === args.queryString.toLowerCase(),\n        )\n      : formatted\n  }\n}\n"],"names":["concatUint8Array","args","mergedArray","Uint8Array","array","sum","entry","length","offset","set","Trix","ixxFile","ixFile","maxResults","constructor","search","searchString","opts","resultArr","searchWord","split","toLowerCase","res","this","_getBuffer","end","buffer","done","decoder","TextDecoder","foundSomething","str","decode","lines","slice","lastIndexOf","filter","f","hits2","line","word","match","startsWith","push","hits","flatMap","term","parts","map","elt","res2","read","concat","list","hasher","JSON","stringify","clone","lookup","Set","hashed","has","add","dedupe","getIndex","readFile","encoding","p","prefix","posStr","Number","parseInt","start","indexes","key","value","len","decodeURIComponentNoThrow","uri","decodeURIComponent","e","shorten","w","tidx","indexOf","Math","max","trim","TrixTextSearchAdapter","BaseAdapter","config","getSubAdapter","pluginManager","super","ixFilePath","readConfObject","ixxFilePath","Error","trixJs","openLocation","searchIndex","query","queryString","strs","formatted","data","every","r","includes","result","parse","replaceAll","loc","trackId","rest","record","labelFieldIdx","findIndex","contextIdx","labelField","contextField","context","undefined","label","displayString","BaseResult","locString","matchedObject","searchType","getLabel"],"sourceRoot":""}