{"version":3,"file":"static/js/9409.8f09ed10.chunk.js","mappings":"iOA6Be,MAAMA,UAA6BC,EAAAA,uBAMhD,oBAA6B,CAAC,cAAe,eAE7C,WAAMC,CAAMC,GAOV,OANKC,KAAKC,SACRD,KAAKC,OAASD,KAAKE,SAASH,GAAMI,OAAMC,IAEtC,MADAJ,KAAKC,YAASI,EACRD,CAAC,KAGJJ,KAAKC,MACd,CACA,cAAMC,CAASH,GACb,MAAMO,EAAgBN,KAAKO,QAAQ,iBAC7BC,EAAKR,KAAKS,cACVC,GAAOC,EAAAA,EAAAA,cAAaX,KAAKO,QAAQ,gBAAiBC,GAClDI,GAAOD,EAAAA,EAAAA,cAAaX,KAAKO,QAAQ,gBAAiBC,GAClDK,GAASF,EAAAA,EAAAA,cAAaX,KAAKO,QAAQ,+BAAgCC,IAClEM,EAAUC,EAAUC,SAAoBC,QAAQC,IACrD,CAACR,EAAME,EAAMC,GAAQM,KAAIC,IAAKC,EAAAA,EAAAA,IAASD,EAAGrB,MAEtCuB,GAAUC,EAAAA,EAAAA,IAAST,GACnBU,GAAUD,EAAAA,EAAAA,IAASR,GA0BzB,MAAO,CACLT,gBACAmB,MA3BYT,EACXU,MAAM,cACNC,QAAOC,KAAOA,GAAW,QAANA,IACnBT,KAAI,CAACU,EAAMC,KACV,MAAOC,EAAKC,EAAKC,EAAKC,EAAKC,EAAOC,GAAUP,EAAKH,MAAM,MACjDW,EAAMf,EAAQgB,IAAIP,GAClBQ,EAAMjB,EAAQgB,IAAIN,GAClBQ,EAAMhB,EAAQc,IAAIL,GAClBQ,EAAMjB,EAAQc,IAAIJ,GACxB,KAAKG,GAAQE,GAAQC,GAAQC,GAC3B,MAAM,IAAIC,MACP,sBAAqBX,KAAOC,KAAOC,KAAOC,KAAOG,KAAOE,KAAOC,KAAOC,KAG3E,MAAO,CACLJ,EACAE,EACAC,EACAC,GACCN,EACU,MAAXC,GAAkB,EAAI,EACtBN,EACD,IAOP,CAEA,uBAAMa,GAIJ,OAAO,CACT,CAEA,iBAAMC,GAEJ,MAAO,EACT,CAEAC,WAAAA,CAAYC,EAAgB/C,EAAoB,CAAC,GAC/C,OAAOgD,EAAAA,EAAAA,mBAA0BC,UAC/B,MAAM,cAAE1C,EAAa,MAAEmB,SAAgBzB,KAAKF,MAAMC,GAI5C+B,EAAQxB,EAAc2C,QAAQH,EAAOI,cAC3C,IAAe,IAAXpB,EAAc,CAChB,MAAMqB,EAAiB,IAAVrB,EACbL,EAAM2B,SAAQxB,IACZ,MAAOyB,EAAKC,EAAKC,EAAKC,EAAKrB,EAAOC,EAAQqB,GAAU7B,EACpD,IAAI8B,EAAK,CACPC,QAASN,EAAIM,QACbC,MAAOC,KAAKC,IAAIT,EAAIO,MAAON,EAAIM,OAC/BG,IAAKF,KAAKG,IAAIX,EAAIU,IAAKT,EAAIS,MAEzBE,EAAK,CACPN,QAASJ,EAAII,QACbC,MAAOC,KAAKC,IAAIP,EAAIK,MAAOJ,EAAII,OAC/BG,IAAKF,KAAKG,IAAIT,EAAIQ,IAAKP,EAAIO,MAExBZ,KACDc,EAAIP,GAAM,CAACA,EAAIO,IAGjBP,EAAGC,UAAYb,EAAOa,UACtBO,EAAAA,EAAAA,gBAAeR,EAAGE,MAAOF,EAAGK,IAAKjB,EAAOc,MAAOd,EAAOiB,MAEtDI,EAASC,KACP,IAAIC,EAAAA,EAAc,IACbX,EACHY,SAAW,GAAEb,IACbc,UAAWd,EACXP,aAAc5C,IAAgB6C,GAC9BhB,QACAC,SACAoC,KAAM,IACDP,EACHf,aAAc5C,GAAe6C,MAIrC,GAEJ,CAEAgB,EAASM,UAAU,GAEvB,CAOAC,aAAAA,GAAuC,E,iHCtJlC,SAASC,EAAOC,GACrB,OAAkB,KAAXA,EAAI,IAAwB,MAAXA,EAAI,IAAyB,IAAXA,EAAI,EAChD,CAEO,SAASrD,EAASsD,GACvB,OAAO,IAAIC,IACTD,EACGnD,MAAM,cACNC,QAAOC,KAAOA,GAAKA,EAAEmD,WAAW,OAChC5D,KAAIU,IACH,MAAO8B,EAASC,EAAOG,EAAKiB,EAAM7C,EAAOC,GAAUP,EAAKH,MAAM,MAC9D,MAAO,CACLsD,EACA,CACErB,UACAC,OAAQA,EACRG,KAAMA,EACN5B,OAAQA,EACR6C,OACA5C,OAAmB,MAAXA,GAAkB,EAAI,GAEjC,IAGT,CAEOY,eAAe3B,EAAS4D,EAAyBlF,GACtD,MAAMmF,QAAgBD,EAAK5D,SAAStB,GACpC,OAAO,IAAIoF,YAAY,OAAQ,CAAEC,OAAO,IAAQC,OAC9CV,EAAOO,SAAgBI,EAAAA,EAAAA,OAAMJ,GAAUA,EAE3C,CAEO,SAASK,EAAIC,EAAaC,GAC/B,OAAOD,EAAErE,KAAI,CAACf,EAAGsF,IAAM,CAACtF,EAAGqF,EAAEC,KAC/B,CAEA,MAAMC,EACmB,oBAAhBR,YAA8B,IAAIA,YAAY,aAAU9E,EAE1D,SAASuF,EACdV,EACAW,GAEA,IAAIC,EAAa,EACjB,MAAMC,EAAU,GAChB,KAAOD,EAAaZ,EAAOc,QAAQ,CACjC,MAAMC,EAAIf,EAAOjC,QAAQ,KAAM6C,GAC/B,IAAW,IAAPG,EACF,MAEF,MAAMR,EAAIP,EAAOgB,MAAMJ,EAAYG,GAC7BpE,GAAQ8D,GAASN,OAAOI,IAAMA,EAAEU,YAAYC,OAC9CvE,GACFkE,EAAQM,KAAKR,EAAGhE,IAGlBiE,EAAaG,EAAI,CACnB,CACA,OAAOF,CACT,CAEO,SAASO,EAAazE,GAC3B,MACE0E,EAAM,CAENC,EACAC,EACArE,EACAsE,EAAM,CAENC,EACAC,EACAC,EACAC,EACAC,KACGC,GACDnF,EAAKH,MAAM,MAWf,MAAO,CACLgF,QACAC,QAASA,EACTC,MAAOA,EACPL,QACAC,QAASA,EACTC,MAAOA,EACPrE,OAAmB,MAAXA,GAAkB,EAAI,EAC9B6E,MAAO,CACLJ,YAAaA,EACbC,UAAWA,EACXC,aAAcA,KApBLG,OAAOC,YAClBH,EAAO7F,KAAIiG,IACT,MAAMhG,EAAIgG,EAAMnE,QAAQ,KAGxB,MAAO,CAFWmE,EAAMlB,MAAM,EAAG9E,GACdgG,EAAMlB,MAAM9E,EAAI,GACL,MAmBpC,CAEO,SAASiG,EAAUC,GACxB,MAAMC,EAAM,GACZ,IAAK,IAAI7B,EAAI4B,EAAMtB,OAAS,EAAGN,GAAK,EAAGA,GAAK,EAAG,CAC7C6B,EAAIlB,KAAKiB,EAAM5B,IACf,MAAM8B,EAAKF,EAAM5B,EAAI,GACV,MAAP8B,EACFD,EAAIlB,KAAK,KACO,MAAPmB,EACTD,EAAIlB,KAAK,KAETkB,EAAIlB,KAAKmB,EAEb,CACA,OAAOD,CACT,CAEO,SAASE,EAAeH,GAC7B,OAAOA,EAAMI,WAAW,IAAK,KAAKA,WAAW,IAAK,KAAKA,WAAW,IAAK,IACzE,C,6FC/GA1E,eAAesC,EAAMqC,GACnB,IACE,IAAIC,EACAC,EAAM,EACNnC,EAAI,EACR,MAAMoC,EAAS,GACf,IACIC,EADAC,EAAY,EAEhB,EAAG,CACD,MAAMC,EAAiBN,EAAUO,SAASL,GAK1C,GAJAE,EAAW,IAAI,EAAAI,UAEXP,QAASG,GACbA,EAAS1B,KAAK4B,EAAgB,EAAAG,cAC1BL,EAASM,IACX,MAAM,IAAI3F,MAAMqF,EAASO,KAG3BT,GAAOD,EAAKW,QACZT,EAAOpC,GAAKqC,EAASS,OACrBR,GAAaF,EAAOpC,GAAGM,OACvBN,GAAK,C,OACEkC,EAAKa,UAEd,MAAMD,EAAS,IAAIE,WAAWV,GAC9B,IAAK,IAAItC,EAAI,EAAGiD,EAAS,EAAGjD,EAAIoC,EAAO9B,OAAQN,IAC7C8C,EAAOI,IAAId,EAAOpC,GAAIiD,GACtBA,GAAUb,EAAOpC,GAAGM,OAEtB,OAAO,EAAA6C,OAAOC,KAAKN,E,CACnB,MAAOpI,GAEP,GAAI,GAAGA,IAAI2I,MAAM,0BACf,MAAM,IAAIrG,MACR,4DAGJ,MAAMtC,C,CAEV,CAgDA4C,eAAegG,EAAgBrB,EAAmBsB,GAChD,IACE,IAAIrB,EACJ,MAAM,KAAEsB,EAAI,KAAEC,GAASF,EACvB,IAAIG,EAAOF,EAAKG,cACZC,EAAOJ,EAAKK,aAChB,MAAMzB,EAAS,GACT0B,EAAa,GACbC,EAAa,GAEnB,IAAIzB,EAAY,EACZtC,EAAI,EACR,EAAG,CACD,MAAMuC,EAAiBN,EAAUO,SAASkB,EAAOF,EAAKG,eAChDtB,EAAW,IAAI,EAAAI,QAIrB,KAFIP,QAASG,GACbA,EAAS1B,KAAK4B,EAAgB,EAAAG,cAC1BL,EAASM,IACX,MAAM,IAAI3F,MAAMqF,EAASO,KAG3B,MAAMpD,EAAS6C,EAASS,OACxBV,EAAOzB,KAAKnB,GACZ,IAAIwE,EAAMxE,EAAOc,OAEjBwD,EAAWnD,KAAK+C,GAChBK,EAAWpD,KAAKiD,GACM,IAAlBxB,EAAO9B,QAAgBkD,EAAKK,eAE9BzB,EAAO,GAAKA,EAAO,GAAGI,SAASgB,EAAKK,cACpCG,EAAM5B,EAAO,GAAG9B,QAElB,MAAM2D,EAAWP,EAIjB,GAHAA,GAAQxB,EAAKW,QACbe,GAAQI,EAEJC,GAAYR,EAAKE,cAAe,CAKlCvB,EAAOpC,GAAKoC,EAAOpC,GAAGwC,SACpB,EACAiB,EAAKE,gBAAkBH,EAAKG,cACxBF,EAAKI,aAAeL,EAAKK,aAAe,EACxCJ,EAAKI,aAAe,GAG1BC,EAAWnD,KAAK+C,GAChBK,EAAWpD,KAAKiD,GAChBtB,GAAaF,EAAOpC,GAAGM,OACvB,K,CAEFgC,GAAaF,EAAOpC,GAAGM,OACvBN,G,OACOkC,EAAKa,UAEd,MAAMD,EAAS,IAAIE,WAAWV,GAC9B,IAAK,IAAItC,EAAI,EAAGiD,EAAS,EAAGjD,EAAIoC,EAAO9B,OAAQN,IAC7C8C,EAAOI,IAAId,EAAOpC,GAAIiD,GACtBA,GAAUb,EAAOpC,GAAGM,OAItB,MAAO,CAAEd,OAFM,EAAA2D,OAAOC,KAAKN,GAEVgB,aAAYC,a,CAC7B,MAAOrJ,GAEP,GAAI,GAAGA,IAAI2I,MAAM,0BACf,MAAM,IAAIrG,MACR,4DAGJ,MAAMtC,C,CAEV,C,wBC5Ke,MAAMwJ,EAKnB,WAAAC,EAAY,WACVC,EAAU,KACVC,IAKA,GAAID,EACF9J,KAAK8J,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,UAAU,6CAFpBhK,KAAK8J,WAAa,IAAI,KAAUC,E,CAIpC,CAEA,qBAAAE,CAAsBrF,EAAa+D,EAAS,EAAGuB,GAAW,GAExD,MAAMC,EAAO,gBAAiBvF,EAAIsB,MAAMyC,EAAQA,EAAS,GAAIuB,GAC7D,GACEC,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAIR,UAAU,oBAGtB,OAAOG,EAAKM,UACd,CAEA,SAAAC,GAIE,OAHK1K,KAAK8B,QACR9B,KAAK8B,MAAQ9B,KAAK2K,cAEb3K,KAAK8B,KACd,CAEA,gBAAM6I,GACJ,IAAI/F,EAAM,EAAAiE,OAAO+B,YAAY,SACvB5K,KAAK8J,WAAWe,KAAKjG,EAAK,EAAG,EAAG,GACtC,MAAMkG,EAAa9K,KAAKiK,sBAAsBrF,EAAK,GAAG,GACtD,IAAKkG,EACH,MAAO,CAAC,CAAC,EAAG,IAGd,MAAM/E,EAAU,IAAIgF,MAAMD,EAAa,GACvC/E,EAAQ,GAAK,CAAC,EAAG,GAGjB,MAAMiF,EAAU,GAAQF,EACxB,GAAIE,EAAUX,OAAOC,iBACnB,MAAM,IAAIN,UAAU,oBAEtBpF,EAAM,EAAAiE,OAAO+B,YAAYI,SACnBhL,KAAK8J,WAAWe,KAAKjG,EAAK,EAAGoG,EAAS,GAC5C,IAAK,IAAIC,EAAc,EAAGA,EAAcH,EAAYG,GAAe,EAAG,CACpE,MAAMC,EAAqBlL,KAAKiK,sBAC9BrF,EACc,GAAdqG,GAEIE,EAAuBnL,KAAKiK,sBAChCrF,EACc,GAAdqG,EAAmB,GAErBlF,EAAQkF,EAAc,GAAK,CAACC,EAAoBC,E,CAGlD,OAAOpF,CACT,CAEA,kBAAMqF,GACJ,MAAMrF,QAAgB/F,KAAK0K,YAC3B,GAAK3E,EAAQC,OAGb,OAAOD,EAAQA,EAAQC,OAAS,EAClC,CAEA,8BAAMqF,CAAyBrF,EAAgBsF,GAC7C,MAAMC,EAAcD,EAAWtF,EAC/B,GAAe,IAAXA,EACF,MAAO,GAET,MAAMD,QAAgB/F,KAAK0K,YACrBc,EAAW,GAIXC,EAAU,CAACC,EAAYC,KAC3B,MAAMR,EAAuBO,EA/FL,GAgGlBE,EAA2BD,EAC7BA,EAjGoB,GAkGpBE,IAEJ,OACEV,GAAwBG,GACxBM,EAA2BN,EAEpB,EAGLH,EAAuBG,GACjB,EAGH,CAAC,EAGV,IAAIQ,EAAa,EACbC,EAAahG,EAAQC,OAAS,EAC9BgG,EAAiBnI,KAAKoI,MAAMlG,EAAQC,OAAS,GAE7CkG,EAAaT,EACf1F,EAAQiG,GACRjG,EAAQiG,EAAiB,IAE3B,KAAsB,IAAfE,GACDA,EAAa,EACfH,EAAaC,EAAiB,EACrBE,EAAa,IACtBJ,EAAaE,EAAiB,GAEhCA,EAAiBnI,KAAKsI,MAAMJ,EAAaD,GAAc,GAAKA,EAC5DI,EAAaT,EAAQ1F,EAAQiG,GAAiBjG,EAAQiG,EAAiB,IAIzER,EAASnF,KAAKN,EAAQiG,IACtB,IAAItG,EAAIsG,EAAiB,EACzB,KAAOtG,EAAIK,EAAQC,SACjBwF,EAASnF,KAAKN,EAAQL,MAClBK,EAAQL,GAzIY,IAyIiB6F,IAFhB7F,GAAK,GAShC,OAHI8F,EAASA,EAASxF,OAAS,GA7IL,GA6IiCuF,GACzDC,EAASnF,KAAK,IAETmF,CACT,EC/Ia,MAAMY,EAInB,WAAAvC,EAAY,WACVC,EAAU,KACVC,EAAI,cACJsC,EAAa,QACbC,IAOA,GAAIxC,EACF9J,KAAK8J,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,UAAU,6CAFpBhK,KAAK8J,WAAa,IAAI,KAAUC,E,CAKlC,IAAKsC,IAAkBC,IAAYvC,EACjC,MAAM,IAAIC,UAAU,mDAGtBhK,KAAKuM,IAAM,IAAI3C,EAAS,CACtBE,WAAYuC,EACZtC,KAAOsC,GAAkBC,IAAWvC,EAAiB,GAAGA,QAAbuC,GAE/C,CAEA,UAAME,GACJ,MAAMC,QAAuBzM,KAAK8J,WAAW0C,OAC7C,OAAOtF,OAAOwF,OAAOD,EAAgB,CACnCE,WAAY3M,KAAK4M,0BACjBC,YAAQxM,EACRyM,aAASzM,GAEb,CAEA,6BAAMuM,GAGJ,MAAO,CAAEzB,SAA8BnL,KAAKuM,IAAInB,gBAE1C,KAAEuB,SAAe3M,KAAK8J,WAAW0C,OAEjC5H,EAAM,EAAAiE,OAAO+B,YAAY,IAGzB,UAAEmC,SAAoB/M,KAAK8J,WAAWe,KAAKjG,EAAK,EAAG,EAAG+H,EAAO,GAAK,GACxE,GAAkB,IAAdI,EACF,MAAM,IAAIrK,MAAM,cAGlB,OAAOyI,EAD2BvG,EAAIoI,aAAa,EAErD,CAEA,6BAAMC,CACJC,GACChC,IACAiC,IAED,IAAI/I,EAAO+I,EACN/I,IACHA,SAAcpE,KAAK8J,WAAW0C,QAAQG,MAIxC,MAAMS,EAAwBhJ,EAAO8G,EAcrC,aAZMlL,KAAK8J,WAAWe,KACpBqC,EACA,EACAE,EACAlC,SAI2B5F,EAC3B4H,EAAYhH,MAAM,EAAGkH,GAIzB,CAEA,UAAMvC,CAAKjG,EAAa+D,EAAgB3C,EAAgBsF,GAEtD,MAAM+B,QAAuBrN,KAAKuM,IAAIlB,yBACpCrF,EACAsF,GAEI4B,EAAc,EAAArE,OAAO+B,YAAY,OAEvC,IAAI0C,EAAoB3E,EACpBoE,EAAY,EAChB,IACE,IAAIQ,EAAW,EACfA,EAAWF,EAAerH,OAAS,EACnCuH,GAAY,EACZ,CAEA,MAAMC,QAA2BxN,KAAKiN,wBACpCC,EACAG,EAAeE,GACfF,EAAeE,EAAW,KAErB,CAAEpC,GAAwBkC,EAAeE,GAC1CE,EACJtC,GAAwBG,EAAW,EAAIA,EAAWH,EAC9CuC,EACJ7J,KAAKC,IACHwH,EAAWtF,EACXmF,EAAuBqC,EAAmBxH,QACxCmF,EACFsC,GAAgB,GAAKA,EAAeD,EAAmBxH,SACzDwH,EAAmBG,KAAK/I,EAAK0I,EAAmBG,EAAcC,GAC9DJ,GAAqBI,EAAYD,EACjCV,GAAaW,EAAYD,E,CAI7B,MAAO,CAAEV,YAAW7H,OAAQN,EAC9B,E","sources":["../../../plugins/comparative-adapters/src/MCScanSimpleAnchorsAdapter/MCScanSimpleAnchorsAdapter.ts","../../../plugins/comparative-adapters/src/util.ts","../../../node_modules/@gmod/bgzf-filehandle/src/unzip-pako.ts","../../../node_modules/@gmod/bgzf-filehandle/src/gziIndex.ts","../../../node_modules/@gmod/bgzf-filehandle/src/bgzFilehandle.ts"],"sourcesContent":["import {\n  BaseFeatureDataAdapter,\n  BaseOptions,\n} from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { Region } from '@jbrowse/core/util/types'\nimport { openLocation } from '@jbrowse/core/util/io'\nimport { doesIntersect2 } from '@jbrowse/core/util'\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs'\nimport SimpleFeature, { Feature } from '@jbrowse/core/util/simpleFeature'\nimport { readFile, parseBed } from '../util'\n\ninterface BareFeature {\n  refName: string\n  start: number\n  end: number\n  score: number\n  name: string\n}\n\ntype Row = [\n  BareFeature,\n  BareFeature,\n  BareFeature,\n  BareFeature,\n  number,\n  number,\n  number,\n]\n\nexport default class MCScanAnchorsAdapter extends BaseFeatureDataAdapter {\n  private setupP?: Promise<{\n    assemblyNames: string[]\n    feats: Row[]\n  }>\n\n  public static capabilities = ['getFeatures', 'getRefNames']\n\n  async setup(opts: BaseOptions) {\n    if (!this.setupP) {\n      this.setupP = this.setupPre(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n  async setupPre(opts: BaseOptions) {\n    const assemblyNames = this.getConf('assemblyNames') as string[]\n    const pm = this.pluginManager\n    const bed1 = openLocation(this.getConf('bed1Location'), pm)\n    const bed2 = openLocation(this.getConf('bed2Location'), pm)\n    const mcscan = openLocation(this.getConf('mcscanSimpleAnchorsLocation'), pm)\n    const [bed1text, bed2text, mcscantext] = await Promise.all(\n      [bed1, bed2, mcscan].map(r => readFile(r, opts)),\n    )\n    const bed1Map = parseBed(bed1text)\n    const bed2Map = parseBed(bed2text)\n    const feats = mcscantext\n      .split(/\\n|\\r\\n|\\r/)\n      .filter(f => !!f && f !== '###')\n      .map((line, index) => {\n        const [n11, n12, n21, n22, score, strand] = line.split('\\t')\n        const r11 = bed1Map.get(n11)\n        const r12 = bed1Map.get(n12)\n        const r21 = bed2Map.get(n21)\n        const r22 = bed2Map.get(n22)\n        if (!r11 || !r12 || !r21 || !r22) {\n          throw new Error(\n            `feature not found, ${n11} ${n12} ${n21} ${n22} ${r11} ${r12} ${r21} ${r22}`,\n          )\n        }\n        return [\n          r11,\n          r12,\n          r21,\n          r22,\n          +score,\n          strand === '-' ? -1 : 1,\n          index,\n        ] as Row\n      })\n\n    return {\n      assemblyNames,\n      feats,\n    }\n  }\n\n  async hasDataForRefName() {\n    // determining this properly is basically a call to getFeatures\n    // so is not really that important, and has to be true or else\n    // getFeatures is never called (BaseFeatureDataAdapter filters it out)\n    return true\n  }\n\n  async getRefNames() {\n    // we cannot determine this accurately\n    return []\n  }\n\n  getFeatures(region: Region, opts: BaseOptions = {}) {\n    return ObservableCreate<Feature>(async observer => {\n      const { assemblyNames, feats } = await this.setup(opts)\n\n      // The index of the assembly name in the region list corresponds to\n      // the adapter in the subadapters list\n      const index = assemblyNames.indexOf(region.assemblyName)\n      if (index !== -1) {\n        const flip = index === 0\n        feats.forEach(f => {\n          const [f11, f12, f21, f22, score, strand, rowNum] = f\n          let r1 = {\n            refName: f11.refName,\n            start: Math.min(f11.start, f12.start),\n            end: Math.max(f11.end, f12.end),\n          }\n          let r2 = {\n            refName: f21.refName,\n            start: Math.min(f21.start, f22.start),\n            end: Math.max(f21.end, f22.end),\n          }\n          if (!flip) {\n            ;[r2, r1] = [r1, r2]\n          }\n          if (\n            r1.refName === region.refName &&\n            doesIntersect2(r1.start, r1.end, region.start, region.end)\n          ) {\n            observer.next(\n              new SimpleFeature({\n                ...r1,\n                uniqueId: `${rowNum}`,\n                syntenyId: rowNum,\n                assemblyName: assemblyNames[+!flip],\n                score,\n                strand,\n                mate: {\n                  ...r2,\n                  assemblyName: assemblyNames[+flip],\n                },\n              }),\n            )\n          }\n        })\n      }\n\n      observer.complete()\n    })\n  }\n\n  /**\n   * called to provide a hint that data tied to a certain region\n   * will not be needed for the foreseeable future and can be purged\n   * from caches, etc\n   */\n  freeResources(/* { region } */): void {}\n}\n","import { BaseOptions } from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { GenericFilehandle } from 'generic-filehandle'\nimport { unzip } from '@gmod/bgzf-filehandle'\nimport { PAFRecord } from './PAFAdapter/util'\n\nexport function isGzip(buf: Buffer) {\n  return buf[0] === 31 && buf[1] === 139 && buf[2] === 8\n}\n\nexport function parseBed(text: string) {\n  return new Map(\n    text\n      .split(/\\n|\\r\\n|\\r/)\n      .filter(f => !!f || f.startsWith('#'))\n      .map(line => {\n        const [refName, start, end, name, score, strand] = line.split('\\t')\n        return [\n          name,\n          {\n            refName,\n            start: +start,\n            end: +end,\n            score: +score,\n            name,\n            strand: strand === '-' ? -1 : 1,\n          },\n        ]\n      }),\n  )\n}\n\nexport async function readFile(file: GenericFilehandle, opts?: BaseOptions) {\n  const buffer = (await file.readFile(opts)) as Buffer\n  return new TextDecoder('utf8', { fatal: true }).decode(\n    isGzip(buffer) ? await unzip(buffer) : buffer,\n  )\n}\n\nexport function zip(a: number[], b: number[]) {\n  return a.map((e, i) => [e, b[i]] as [number, number])\n}\n\nconst decoder =\n  typeof TextDecoder !== 'undefined' ? new TextDecoder('utf8') : undefined\n\nexport function parseLineByLine(\n  buffer: Buffer,\n  cb: (line: string) => PAFRecord,\n) {\n  let blockStart = 0\n  const entries = []\n  while (blockStart < buffer.length) {\n    const n = buffer.indexOf('\\n', blockStart)\n    if (n === -1) {\n      break\n    }\n    const b = buffer.slice(blockStart, n)\n    const line = (decoder?.decode(b) || b.toString()).trim()\n    if (line) {\n      entries.push(cb(line))\n    }\n\n    blockStart = n + 1\n  }\n  return entries\n}\n\nexport function parsePAFLine(line: string) {\n  const [\n    qname,\n    ,\n    qstart,\n    qend,\n    strand,\n    tname,\n    ,\n    tstart,\n    tend,\n    numMatches,\n    blockLen,\n    mappingQual,\n    ...fields\n  ] = line.split('\\t')\n\n  const rest = Object.fromEntries(\n    fields.map(field => {\n      const r = field.indexOf(':')\n      const fieldName = field.slice(0, r)\n      const fieldValue = field.slice(r + 3)\n      return [fieldName, fieldValue]\n    }),\n  )\n\n  return {\n    tname,\n    tstart: +tstart,\n    tend: +tend,\n    qname,\n    qstart: +qstart,\n    qend: +qend,\n    strand: strand === '-' ? -1 : 1,\n    extra: {\n      numMatches: +numMatches,\n      blockLen: +blockLen,\n      mappingQual: +mappingQual,\n      ...rest,\n    },\n  } as PAFRecord\n}\n\nexport function flipCigar(cigar: string[]) {\n  const arr = []\n  for (let i = cigar.length - 2; i >= 0; i -= 2) {\n    arr.push(cigar[i])\n    const op = cigar[i + 1]\n    if (op === 'D') {\n      arr.push('I')\n    } else if (op === 'I') {\n      arr.push('D')\n    } else {\n      arr.push(op)\n    }\n  }\n  return arr\n}\n\nexport function swapIndelCigar(cigar: string) {\n  return cigar.replaceAll('D', 'K').replaceAll('I', 'D').replaceAll('K', 'I')\n}\n","import { Buffer } from 'buffer'\n//@ts-ignore\nimport { Z_SYNC_FLUSH, Inflate } from 'pako'\n\ninterface VirtualOffset {\n  blockPosition: number\n  dataPosition: number\n}\ninterface Chunk {\n  minv: VirtualOffset\n  maxv: VirtualOffset\n}\n\n// browserify-zlib, which is the zlib shim used by default in webpacked code,\n// does not properly uncompress bgzf chunks that contain more than\n// one bgzf block, so export an unzip function that uses pako directly\n// if we are running in a browser.\nasync function unzip(inputData: Buffer) {\n  try {\n    let strm\n    let pos = 0\n    let i = 0\n    const chunks = []\n    let totalSize = 0\n    let inflator\n    do {\n      const remainingInput = inputData.subarray(pos)\n      inflator = new Inflate()\n      //@ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      pos += strm.next_in\n      chunks[i] = inflator.result as Uint8Array\n      totalSize += chunks[i].length\n      i += 1\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    return Buffer.from(result)\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to pakounzip, except it does extra counting\n// to return the positions of compressed and decompressed\n// data offsets\nasync function unzipChunk(inputData: Buffer) {\n  try {\n    let strm\n    let cpos = 0\n    let dpos = 0\n    const blocks = []\n    const cpositions = []\n    const dpositions = []\n    do {\n      const remainingInput = inputData.slice(cpos)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = Buffer.from(inflator.result)\n      blocks.push(buffer)\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n\n      cpos += strm.next_in\n      dpos += buffer.length\n    } while (strm.avail_in)\n\n    const buffer = Buffer.concat(blocks)\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to unzipChunk above but slices (0,minv.dataPosition) and\n// (maxv.dataPosition,end) off\nasync function unzipChunkSlice(inputData: Buffer, chunk: Chunk) {\n  try {\n    let strm\n    const { minv, maxv } = chunk\n    let cpos = minv.blockPosition\n    let dpos = minv.dataPosition\n    const chunks = []\n    const cpositions = []\n    const dpositions = []\n\n    let totalSize = 0\n    let i = 0\n    do {\n      const remainingInput = inputData.subarray(cpos - minv.blockPosition)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = inflator.result\n      chunks.push(buffer as Uint8Array)\n      let len = buffer.length\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n      if (chunks.length === 1 && minv.dataPosition) {\n        // this is the first chunk, trim it\n        chunks[0] = chunks[0].subarray(minv.dataPosition)\n        len = chunks[0].length\n      }\n      const origCpos = cpos\n      cpos += strm.next_in\n      dpos += len\n\n      if (origCpos >= maxv.blockPosition) {\n        // this is the last chunk, trim it and stop decompressing\n        // note if it is the same block is minv it subtracts that already\n        // trimmed part of the slice length\n\n        chunks[i] = chunks[i].subarray(\n          0,\n          maxv.blockPosition === minv.blockPosition\n            ? maxv.dataPosition - minv.dataPosition + 1\n            : maxv.dataPosition + 1,\n        )\n\n        cpositions.push(cpos)\n        dpositions.push(dpos)\n        totalSize += chunks[i].length\n        break\n      }\n      totalSize += chunks[i].length\n      i++\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    const buffer = Buffer.from(result)\n\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\nfunction nodeUnzip() {\n  throw new Error('nodeUnzip not implemented.')\n}\n\nexport { unzip, unzipChunk, unzipChunkSlice, unzip as pakoUnzip, nodeUnzip }\n","import Long from 'long'\nimport { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// const COMPRESSED_POSITION = 0\nconst UNCOMPRESSED_POSITION = 1\n\nexport default class GziIndex {\n  filehandle: GenericFilehandle\n\n  index?: any\n\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n  }\n\n  _readLongWithOverflow(buf: Buffer, offset = 0, unsigned = true) {\n    //@ts-ignore\n    const long = Long.fromBytesLE(buf.slice(offset, offset + 8), unsigned)\n    if (\n      long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n      long.lessThan(Number.MIN_SAFE_INTEGER)\n    ) {\n      throw new TypeError('integer overflow')\n    }\n\n    return long.toNumber()\n  }\n\n  _getIndex() {\n    if (!this.index) {\n      this.index = this._readIndex()\n    }\n    return this.index\n  }\n\n  async _readIndex() {\n    let buf = Buffer.allocUnsafe(8)\n    await this.filehandle.read(buf, 0, 8, 0)\n    const numEntries = this._readLongWithOverflow(buf, 0, true)\n    if (!numEntries) {\n      return [[0, 0]]\n    }\n\n    const entries = new Array(numEntries + 1)\n    entries[0] = [0, 0]\n\n    // TODO rewrite this to make an index-index that stays in memory\n    const bufSize = 8 * 2 * numEntries\n    if (bufSize > Number.MAX_SAFE_INTEGER) {\n      throw new TypeError('integer overflow')\n    }\n    buf = Buffer.allocUnsafe(bufSize)\n    await this.filehandle.read(buf, 0, bufSize, 8)\n    for (let entryNumber = 0; entryNumber < numEntries; entryNumber += 1) {\n      const compressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16,\n      )\n      const uncompressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16 + 8,\n      )\n      entries[entryNumber + 1] = [compressedPosition, uncompressedPosition]\n    }\n\n    return entries\n  }\n\n  async getLastBlock() {\n    const entries = await this._getIndex()\n    if (!entries.length) {\n      return undefined\n    }\n    return entries[entries.length - 1]\n  }\n\n  async getRelevantBlocksForRead(length: number, position: number) {\n    const endPosition = position + length\n    if (length === 0) {\n      return []\n    }\n    const entries = await this._getIndex()\n    const relevant = []\n\n    // binary search to find the block that the\n    // read starts in and extend forward from that\n    const compare = (entry: any, nextEntry: any) => {\n      const uncompressedPosition = entry[UNCOMPRESSED_POSITION]\n      const nextUncompressedPosition = nextEntry\n        ? nextEntry[UNCOMPRESSED_POSITION]\n        : Infinity\n      // block overlaps read start\n      if (\n        uncompressedPosition <= position &&\n        nextUncompressedPosition > position\n      ) {\n        return 0\n        // block is before read start\n      }\n      if (uncompressedPosition < position) {\n        return -1\n      }\n      // block is after read start\n      return 1\n    }\n\n    let lowerBound = 0\n    let upperBound = entries.length - 1\n    let searchPosition = Math.floor(entries.length / 2)\n\n    let comparison = compare(\n      entries[searchPosition],\n      entries[searchPosition + 1],\n    )\n    while (comparison !== 0) {\n      if (comparison > 0) {\n        upperBound = searchPosition - 1\n      } else if (comparison < 0) {\n        lowerBound = searchPosition + 1\n      }\n      searchPosition = Math.ceil((upperBound - lowerBound) / 2) + lowerBound\n      comparison = compare(entries[searchPosition], entries[searchPosition + 1])\n    }\n\n    // here's where we read forward\n    relevant.push(entries[searchPosition])\n    let i = searchPosition + 1\n    for (; i < entries.length; i += 1) {\n      relevant.push(entries[i])\n      if (entries[i][UNCOMPRESSED_POSITION] >= endPosition) {\n        break\n      }\n    }\n    if (relevant[relevant.length - 1][UNCOMPRESSED_POSITION] < endPosition) {\n      relevant.push([])\n    }\n    return relevant\n  }\n}\n","import { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// locals\nimport { unzip } from './unzip'\nimport GziIndex from './gziIndex'\n\nexport default class BgzFilehandle {\n  filehandle: GenericFilehandle\n  gzi: GziIndex\n\n  constructor({\n    filehandle,\n    path,\n    gziFilehandle,\n    gziPath,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n    gziFilehandle?: GenericFilehandle\n    gziPath?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n\n    if (!gziFilehandle && !gziPath && !path) {\n      throw new TypeError('either gziFilehandle or gziPath must be defined')\n    }\n\n    this.gzi = new GziIndex({\n      filehandle: gziFilehandle,\n      path: !gziFilehandle && !gziPath && path ? gziPath : `${path}.gzi`,\n    })\n  }\n\n  async stat() {\n    const compressedStat = await this.filehandle.stat()\n    return Object.assign(compressedStat, {\n      size: await this.getUncompressedFileSize(),\n      blocks: undefined,\n      blksize: undefined,\n    })\n  }\n\n  async getUncompressedFileSize() {\n    // read the last block's ISIZE (see gzip RFC),\n    // and add it to its uncompressedPosition\n    const [, uncompressedPosition] = await this.gzi.getLastBlock()\n\n    const { size } = await this.filehandle.stat()\n\n    const buf = Buffer.allocUnsafe(4)\n    // note: there should be a 28-byte EOF marker (an empty block) at\n    // the end of the file, so we skip backward past that\n    const { bytesRead } = await this.filehandle.read(buf, 0, 4, size - 28 - 4)\n    if (bytesRead !== 4) {\n      throw new Error('read error')\n    }\n    const lastBlockUncompressedSize = buf.readUInt32LE(0)\n    return uncompressedPosition + lastBlockUncompressedSize\n  }\n\n  async _readAndUncompressBlock(\n    blockBuffer: Buffer,\n    [compressedPosition]: [number],\n    [nextCompressedPosition]: [number],\n  ) {\n    let next = nextCompressedPosition\n    if (!next) {\n      next = (await this.filehandle.stat()).size\n    }\n\n    // read the compressed data into the block buffer\n    const blockCompressedLength = next - compressedPosition\n\n    await this.filehandle.read(\n      blockBuffer,\n      0,\n      blockCompressedLength,\n      compressedPosition,\n    )\n\n    // uncompress it\n    const unzippedBuffer = await unzip(\n      blockBuffer.slice(0, blockCompressedLength),\n    )\n\n    return unzippedBuffer as Buffer\n  }\n\n  async read(buf: Buffer, offset: number, length: number, position: number) {\n    // get the block positions for this read\n    const blockPositions = await this.gzi.getRelevantBlocksForRead(\n      length,\n      position,\n    )\n    const blockBuffer = Buffer.allocUnsafe(32768 * 2)\n    // uncompress the blocks and read from them one at a time to keep memory usage down\n    let destinationOffset = offset\n    let bytesRead = 0\n    for (\n      let blockNum = 0;\n      blockNum < blockPositions.length - 1;\n      blockNum += 1\n    ) {\n      // eslint-disable-next-line no-await-in-loop\n      const uncompressedBuffer = await this._readAndUncompressBlock(\n        blockBuffer,\n        blockPositions[blockNum],\n        blockPositions[blockNum + 1],\n      )\n      const [, uncompressedPosition] = blockPositions[blockNum]\n      const sourceOffset =\n        uncompressedPosition >= position ? 0 : position - uncompressedPosition\n      const sourceEnd =\n        Math.min(\n          position + length,\n          uncompressedPosition + uncompressedBuffer.length,\n        ) - uncompressedPosition\n      if (sourceOffset >= 0 && sourceOffset < uncompressedBuffer.length) {\n        uncompressedBuffer.copy(buf, destinationOffset, sourceOffset, sourceEnd)\n        destinationOffset += sourceEnd - sourceOffset\n        bytesRead += sourceEnd - sourceOffset\n      }\n    }\n\n    return { bytesRead, buffer: buf }\n  }\n}\n"],"names":["MCScanAnchorsAdapter","BaseFeatureDataAdapter","setup","opts","this","setupP","setupPre","catch","e","undefined","assemblyNames","getConf","pm","pluginManager","bed1","openLocation","bed2","mcscan","bed1text","bed2text","mcscantext","Promise","all","map","r","readFile","bed1Map","parseBed","bed2Map","feats","split","filter","f","line","index","n11","n12","n21","n22","score","strand","r11","get","r12","r21","r22","Error","hasDataForRefName","getRefNames","getFeatures","region","ObservableCreate","async","indexOf","assemblyName","flip","forEach","f11","f12","f21","f22","rowNum","r1","refName","start","Math","min","end","max","r2","doesIntersect2","observer","next","SimpleFeature","uniqueId","syntenyId","mate","complete","freeResources","isGzip","buf","text","Map","startsWith","name","file","buffer","TextDecoder","fatal","decode","unzip","zip","a","b","i","decoder","parseLineByLine","cb","blockStart","entries","length","n","slice","toString","trim","push","parsePAFLine","qname","qstart","qend","tname","tstart","tend","numMatches","blockLen","mappingQual","fields","extra","Object","fromEntries","field","flipCigar","cigar","arr","op","swapIndelCigar","replaceAll","inputData","strm","pos","chunks","inflator","totalSize","remainingInput","subarray","Inflate","Z_SYNC_FLUSH","err","msg","next_in","result","avail_in","Uint8Array","offset","set","Buffer","from","match","unzipChunkSlice","chunk","minv","maxv","cpos","blockPosition","dpos","dataPosition","cpositions","dpositions","len","origCpos","GziIndex","constructor","filehandle","path","TypeError","_readLongWithOverflow","unsigned","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","_getIndex","_readIndex","allocUnsafe","read","numEntries","Array","bufSize","entryNumber","compressedPosition","uncompressedPosition","getLastBlock","getRelevantBlocksForRead","position","endPosition","relevant","compare","entry","nextEntry","nextUncompressedPosition","Infinity","lowerBound","upperBound","searchPosition","floor","comparison","ceil","BgzFilehandle","gziFilehandle","gziPath","gzi","stat","compressedStat","assign","size","getUncompressedFileSize","blocks","blksize","bytesRead","readUInt32LE","_readAndUncompressBlock","blockBuffer","nextCompressedPosition","blockCompressedLength","blockPositions","destinationOffset","blockNum","uncompressedBuffer","sourceOffset","sourceEnd","copy"],"sourceRoot":""}