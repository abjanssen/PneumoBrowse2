{"version":3,"file":"static/js/7886.5e6c5ac8.chunk.js","mappings":"oMAGA,MAAMA,UAAmBC,OAelB,SAASC,EAAiBC,GAC/B,GAAKA,GAIDA,EAAOC,QAAS,CAClB,GAA4B,oBAAjBC,aACT,MAAM,IAAIA,aAAa,UAAW,cAC7B,CACL,MAAMC,EAAI,IAAIN,EAAW,WAEzB,MADAM,EAAEC,KAAO,cACHD,CACR,CACF,CACF,CAoBO,SAASE,EAAeC,EAAiBC,GAC9C,MAAMC,EAAwB,GAC9B,IAAIC,EAA0B,KAE9B,OAAsB,IAAlBH,EAAOI,OACFJ,GAGTA,EAAOK,MAAK,SAAUC,EAAIC,GACxB,MAAMC,EAAMF,EAAGG,KAAKC,cAAgBH,EAAGE,KAAKC,cAC5C,OAAe,IAARF,EAAYA,EAAMF,EAAGG,KAAKE,aAAeJ,EAAGE,KAAKE,YAC1D,IAEAX,EAAOY,SAAQC,IApBV,IAAwBC,EAAeC,IAqBrCd,GAAUY,EAAMG,KAAKC,UAAUhB,GAAU,KAC1B,OAAdE,GACFD,EAAagB,KAAKL,GAClBV,EAAYU,IAxBWC,EA0BJX,GA1BmBY,EA0BRF,GAxB3BJ,KAAKC,cAAgBI,EAAOE,KAAKN,cAAgB,MACxDK,EAAOC,KAAKN,cAAgBI,EAAOL,KAAKC,cAAgB,IAwB9CG,EAAMG,KAAKC,UAAUd,EAAUa,MAAQ,IACzCb,EAAUa,KAAOH,EAAMG,OAGzBd,EAAagB,KAAKL,GAClBV,EAAYU,IAGlB,IAGKX,EACT,CCpFe,MAAMiB,EAGnB,WAAAC,CAAYV,EAAuBC,GACjCU,KAAKX,cAAgBA,EACrBW,KAAKV,aAAeA,CACtB,CAEA,QAAAW,GACE,MAAO,GAAGD,KAAKX,iBAAiBW,KAAKV,cACvC,CAEA,SAAAM,CAAUM,GACR,OACEF,KAAKX,cAAgBa,EAAEb,eAAiBW,KAAKV,aAAeY,EAAEZ,YAElE,EAEK,SAASa,EAAUC,EAAmBC,EAAS,GACpD,OAAO,IAAIP,EACY,cAArBM,EAAMC,EAAS,GACQ,WAArBD,EAAMC,EAAS,GACM,SAArBD,EAAMC,EAAS,GACM,MAArBD,EAAMC,EAAS,GACM,IAArBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAChBD,EAAMC,EAAS,IAAO,EAAKD,EAAMC,GAEtC,CCzBe,MAAMC,EAMnB,WAAAP,CACEX,EACAO,EACAY,EACAC,OAAcC,GAEdT,KAAKZ,KAAOA,EACZY,KAAKL,KAAOA,EACZK,KAAKO,IAAMA,EACXP,KAAKU,aAAeF,CACtB,CAEA,cAAAG,GACE,MAAO,GAAGX,KAAKZ,SAASY,KAAKL,aAC3BK,KAAKO,oBACUP,KAAKQ,gBACxB,CAEA,QAAAP,GACE,OAAOD,KAAKW,gBACd,CAEA,SAAAf,CAAUM,GACR,OACEF,KAAKZ,KAAKQ,UAAUM,EAAEd,OACtBY,KAAKL,KAAKC,UAAUM,EAAEP,OACtBK,KAAKO,IAAML,EAAEK,GAEjB,CAEA,WAAAC,GACE,YAA0BC,IAAtBT,KAAKU,aACAV,KAAKU,aAEPV,KAAKL,KAAKN,cAAgB,MAAYW,KAAKZ,KAAKC,aACzD,EC1Ba,MAAeuB,EAK5B,WAAAb,EAAY,WACVc,EAAU,cACVC,EAAiBC,GAAcA,IAK/Bf,KAAKa,WAAaA,EAClBb,KAAKgB,aAAeF,CACtB,CAMO,iBAAMG,CAAYC,EAAgB,CAAC,GACxC,MAAQC,QAASC,KAAaC,SAAerB,KAAKsB,MAAMJ,GACxD,OAAOG,CACT,CASA,cAAAE,CACEC,EACAC,GAEA,OAAID,EACKA,EAAW5B,UAAU6B,GAAiB,EACzCA,EACAD,EAEGC,CAEX,CAEA,WAAMH,CAAMJ,EAAgB,CAAC,GAO3B,OANKlB,KAAK0B,SACR1B,KAAK0B,OAAS1B,KAAK2B,OAAOT,GAAMU,OAAOpD,IAErC,MADAwB,KAAK0B,YAASjB,EACRjC,CAAC,KAGJwB,KAAK0B,MACd,CAEA,eAAMG,CAAUC,EAAeZ,EAAgB,CAAC,GAC9C,MAAMa,QAAY/B,KAAKsB,MAAMJ,GAC7B,QAASa,EAAIZ,QAAQW,IAAQE,QAC/B,ECzEK,SAASC,EAAwBC,EAAoBC,EAAI,GAC9D,MAAMC,EACJF,EAAOC,GACND,EAAOC,EAAI,IAAO,EAClBD,EAAOC,EAAI,IAAO,GAClBD,EAAOC,EAAI,IAAO,GAMrB,OAb4BE,aAS1BH,EAAOC,EAAI,GACVD,EAAOC,EAAI,IAAO,EAClBD,EAAOC,EAAI,IAAO,GAClBD,EAAOC,EAAI,IAAO,MACJ,IAAuBC,IAAQ,EAClD,CCYe,MAAME,UAAmB1B,EACtC,eAAM2B,CAAUC,EAAiBtB,EAAgB,CAAC,GAChD,MAAMuB,QAAkBzC,KAAKsB,MAAMJ,GAC7BwB,EAAQD,EAAUE,YAAYH,GACpC,YAAc/B,IAAViC,GACM,EAEED,EAAUtB,QAAQuB,GAIvBD,EAAUtB,QAAQuB,GAAOE,OAAOL,YAAc,GAF3C,CAGZ,CAGA,YAAMZ,CAAOT,EAAgB,CAAC,GAC5B,MAAM2B,QAAY7C,KAAKa,WAAWiC,SAAS5B,GACrCd,QAAc,QAAMyC,GAC1BzE,EAAiB8C,EAAK7C,QACtB,MAAM0E,EAAW,IAAIC,SAAS5C,EAAM6C,QAGpC,GA1Cc,WAyCAF,EAASG,UAAU,GAAG,GAElC,MAAM,IAAI/E,MAAM,kBAIlB,MAAMgF,EAAWJ,EAASG,UAAU,GAAG,GACjCE,EAAcL,EAASG,UAAU,GAAG,GACpCG,EACU,MAAdD,EAAwB,uBAAyB,iBAM7CE,EALqC,CACzC,EAAG,UACH,EAAG,MACH,EAAG,OAEmC,GAAdF,GAC1B,IAAKE,EACH,MAAM,IAAInF,MAAM,qCAAqCiF,KAEvD,MAAMG,EAAgB,CACpBC,IAAKT,EAASU,SAAS,IAAI,GAC3BC,MAAOX,EAASU,SAAS,IAAI,GAC7BE,IAAKZ,EAASU,SAAS,IAAI,IAEvBG,EAAYb,EAASU,SAAS,IAAI,GAIlCI,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,KACxDI,EAAYjB,EAASU,SAAS,IAAI,GAGlCQ,EAAoBlB,EAASU,SAAS,IAAI,IAC1C,YAAEd,EAAW,YAAEuB,GAAgBlE,KAAKmE,gBACxC/D,EAAMgE,MAAM,GAAI,GAAKH,IAIvB,IACII,EADAC,EAAa,GAAKL,EAqDtB,MAAO,CACL9C,QApDc,IAAIoD,MAAMpB,GAAUqB,KAAK,GAAGC,KAAI,KAE9C,MAAMC,EAAW3B,EAASU,SAASa,GAAY,GAC/CA,GAAc,EACd,MAAMtC,EAAoC,CAAC,EAC3C,IAAIY,EACJ,IAAK,IAAI+B,EAAI,EAAGA,EAAID,EAAUC,GAAK,EAAG,CACpC,MAAMpE,EAAMwC,EAASG,UAAUoB,GAAY,GAE3C,GADAA,GAAc,EACV/D,EAAMqE,MACR,MAAM,IAAIzG,MACR,8DAEG,GAAYyG,QAARrE,EAA0B,CACnC,MAAMsE,EAAa9B,EAASU,SAASa,GAAY,GACjDA,GAAc,EACK,IAAfO,IACFjC,EAAQ5C,KAAK8E,eAAe1E,EAAOkE,IAErCA,GAAc,GAAKO,CACrB,KAAO,CACL,MAAMA,EAAa9B,EAASU,SAASa,GAAY,GACjDA,GAAc,EACd,MAAM3F,EAAS,IAAI4F,MAAMM,GACzB,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAYE,GAAK,EAAG,CACtC,MAAMC,EAAI7E,EAAUC,EAAOkE,GACrBW,EAAI9E,EAAUC,EAAOkE,EAAa,GACxCA,GAAc,GACdD,EAAgBrE,KAAKuB,eAAe8C,EAAeW,GACnDrG,EAAOoG,GAAK,IAAIzE,EAAM0E,EAAGC,EAAG1E,EAC9B,CACAyB,EAASzB,GAAO5B,CAClB,CACF,CAGA,MAAMuG,EAAcnC,EAASU,SAASa,GAAY,GAClDA,GAAc,EACd,MAAMa,EAAc,IAAIZ,MAAMW,GAC9B,IAAK,IAAIH,EAAI,EAAGA,EAAIG,EAAaH,GAAK,EACpCI,EAAYJ,GAAK5E,EAAUC,EAAOkE,GAClCA,GAAc,EACdD,EAAgBrE,KAAKuB,eAAe8C,EAAec,EAAYJ,IAEjE,MAAO,CACL/C,WACAmD,cACAvC,QACD,IAKDiB,WACAe,aApEmB,MAqEnBQ,aApEmB,UAqEnBpB,YACAK,gBACAd,gBACAF,iBACAC,SACAY,cACAvB,cACA0C,aAAc,MAElB,CAEA,cAAAP,CAAe1E,EAAmBC,GAChC,MAAO,CACLkC,UAAWN,EAAwB7B,EAAOC,EAAS,IAEvD,CAEA,eAAA8D,CAAgBmB,GACd,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMtB,EAAwB,GACxBvB,EAAsC,CAAC,EACvC8C,EAAU,IAAIC,YAAY,QAChC,IAAK,IAAIvD,EAAI,EAAGA,EAAImD,EAAWvG,OAAQoD,GAAK,EAC1C,IAAKmD,EAAWnD,GAAI,CAClB,GAAIqD,EAAgBrD,EAAG,CACrB,MAAMK,EAAUxC,KAAKgB,aACnByE,EAAQE,OAAOL,EAAWM,SAASJ,EAAerD,KAEpD+B,EAAYqB,GAAa/C,EACzBG,EAAYH,GAAW+C,CACzB,CACAC,EAAgBrD,EAAI,EACpBoD,GAAa,CACf,CAEF,MAAO,CACL5C,cACAuB,cAEJ,CAEA,oBAAM2B,CACJrD,EACAsD,EACAC,EACA7E,EAAgB,CAAC,GAEb4E,EAAM,IACRA,EAAM,GAGR,MAAMrD,QAAkBzC,KAAKsB,MAAMJ,GAC7BwB,EAAQD,EAAUE,YAAYH,GACpC,QAAc/B,IAAViC,EACF,MAAO,GAET,MAAMsD,EAAKvD,EAAUtB,QAAQuB,GAC7B,IAAKsD,EACH,MAAO,IAGSA,EAAGb,YAAYpG,OAC7BiH,EAAGb,YACDW,GAxMa,IAwMYE,EAAGb,YAAYpG,OACpCiH,EAAGb,YAAYpG,OAAS,EACxB+G,GA1MS,IA4Mf,IAAIhG,EAAc,EAAG,KAEvBmG,QAAQC,KAAK,4CAKf,MAAMC,GA7MQC,EA6MmBN,EA7MNnC,EA6MWoC,EA1MjC,CACL,CAAC,EAAG,GACJ,CAAC,IAJHK,GAAO,IAIQ,IAAK,IAHpBzC,GAAO,IAGyB,KAC9B,CAAC,GAAKyC,GAAO,IAAK,GAAKzC,GAAO,KAC9B,CAAC,IAAMyC,GAAO,IAAK,IAAMzC,GAAO,KAChC,CAAC,KAAOyC,GAAO,IAAK,KAAOzC,GAAO,KAClC,CAAC,MAAQyC,GAAO,IAAK,MAAQzC,GAAO,OATxC,IAAkByC,EAAazC,EA8M3B,MAAMhF,EAAkB,GAGxB,IAAK,MAAO+E,EAAOC,KAAQwC,EACzB,IAAK,IAAI5F,EAAMmD,EAAOnD,GAAOoD,EAAKpD,IAChC,GAAIyF,EAAGhE,SAASzB,GACd,IAAK,MAAM8F,KAAKL,EAAGhE,SAASzB,GAC1B5B,EAAOkB,KAAK,IAAIS,EAAM+F,EAAEjH,KAAMiH,EAAE1G,KAAMY,IAQ9C,MAAM+F,EAAQN,EAAGb,YAAYpG,OAC7B,IAAIH,EAAS,KACb,MAAM2H,EAASC,KAAKV,IAAIA,GAAO,GAAIQ,EAAQ,GACrCG,EAASD,KAAKV,IAAIC,GAAO,GAAIO,EAAQ,GAC3C,IAAK,IAAInE,EAAIoE,EAAQpE,GAAKsE,IAAUtE,EAAG,CACrC,MAAMuE,EAAKV,EAAGb,YAAYhD,GACtBuE,KACG9H,GAAU8H,EAAG9G,UAAUhB,GAAU,KACpCA,EAAS8H,EAGf,CAEA,OAAOhI,EAAeC,EAAQC,EAChC,EChPF,MAGM+H,EAAU,CACd,EAAG,UACH,EAAG,MACH,EAAG,OAML,SAASC,EAAOC,EAAaC,GAC3B,OAAON,KAAKO,MAAMF,EAAM,GAAKC,EAC/B,CAEe,MAAME,UAAYpG,EAI/B,WAAAb,CAAYkH,GACVC,MAAMD,GACNjH,KAAK4E,aAAe,EACpB5E,KAAKmH,MAAQ,EACbnH,KAAKoH,SAAW,CAClB,CACA,eAAM7E,CAAUC,EAAiBtB,EAAgB,CAAC,GAChD,MAAMuB,QAAkBzC,KAAKsB,MAAMJ,GAC7BwB,EAAQD,EAAUE,YAAYH,GACpC,QAAc/B,IAAViC,EACF,OAAQ,EAGV,IADYD,EAAUtB,QAAQuB,GAE5B,OAAQ,EAEV,MAAM,MAAEE,GAAUH,EAAUtB,QAAQuB,GACpC,OAAIE,EACKA,EAAML,WAEP,CACV,CAEA,QAAA8E,GACE,MAAM,IAAIlJ,MAAM,sCAClB,CAEA,YAAAmJ,CAAalH,EAAmBC,GAC9B,MAAM0C,EAAW,IAAIC,SAAS5C,EAAM6C,QAC9BG,EAAcL,EAASU,SAASpD,GAAQ,GACxCgD,EACU,MAAdD,EAAwB,uBAAyB,iBAC7CE,EAASqD,EAAuB,GAAdvD,GACxB,IAAKE,EACH,MAAM,IAAInF,MAAM,qCAAqCiF,KAEvD,MAAMG,EAAgB,CACpBC,IAAKT,EAASU,SAASpD,EAAS,GAAG,GACnCqD,MAAOX,EAASU,SAASpD,EAAS,GAAG,GACrCsD,IAAKZ,EAASU,SAASpD,EAAS,IAAI,IAEhCuD,EAAYb,EAASU,SAASpD,EAAS,IAAI,GAC3CwD,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,KACxDI,EAAYjB,EAASU,SAASpD,EAAS,IAAI,GAC3C4D,EAAoBlB,EAASU,SAASpD,EAAS,IAAI,IAEnD,YAAE6D,EAAW,YAAEvB,GAAgB3C,KAAKmE,gBACxC/D,EAAMwF,SAASvF,EAAS,GAAIA,EAAS,GAAK4D,IAG5C,MAAO,CACLC,cACAvB,cACAqB,YACAH,WACAN,gBACAD,SACAD,iBAEJ,CAEA,eAAAc,CAAgBmB,GACd,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMtB,EAAc,GACdvB,EAAsC,CAAC,EACvC8C,EAAU,IAAIC,YAAY,QAChC,IAAK,IAAIvD,EAAI,EAAGA,EAAImD,EAAWvG,OAAQoD,GAAK,EAC1C,IAAKmD,EAAWnD,GAAI,CAClB,GAAIqD,EAAgBrD,EAAG,CACrB,MAAMK,EAAUxC,KAAKgB,aACnByE,EAAQE,OAAOL,EAAWM,SAASJ,EAAerD,KAEpD+B,EAAYqB,GAAa/C,EACzBG,EAAYH,GAAW+C,CACzB,CACAC,EAAgBrD,EAAI,EACpBoD,GAAa,CACf,CAEF,MAAO,CACL5C,cACAuB,cAEJ,CAIA,YAAMvC,CAAOT,EAAgB,CAAC,GAC5B,MAAMd,QAAc,cAAYJ,KAAKa,WAAWiC,SAAS5B,IACnD6B,EAAW,IAAIC,SAAS5C,EAAM6C,QAGpC,IAAIsE,EACJ,GAlHe,WAkHXxE,EAASG,UAAU,GAAG,GACxBqE,EAAa,MACR,IAnHQ,WAmHJxE,EAASG,UAAU,GAAG,GAG/B,MAAM,IAAI/E,MAAM,kBAFhBoJ,EAAa,CAGf,CAEAvH,KAAKoH,SAAWrE,EAASU,SAAS,GAAG,GACrCzD,KAAKmH,MAAQpE,EAASU,SAAS,GAAG,GAClCzD,KAAK4E,eAAiB,GAAyB,GAAlB5E,KAAKmH,MAAQ,IAAW,GAAK,EAC1D,MAAM/B,EAAe,IAAMpF,KAAKoH,SAAwB,EAAbpH,KAAKmH,OAC1CK,EAAYzE,EAASU,SAAS,IAAI,GAClCgE,EACJD,GAAaA,GAAa,GACtBxH,KAAKsH,aAAalH,EAAO,IACzB,CACE8D,YAAa,GACbvB,YAAa,CAAC,EACdkB,SAAU,KACVN,cAAe,CAAEC,IAAK,EAAGE,MAAO,EAAGC,IAAK,GACxCN,eAAgB,uBAChBC,OAAQ,WAEVH,EAAWJ,EAASU,SAAS,GAAK+D,GAAW,GAGnD,IAAInD,EACAC,EAAa,GAAKkD,EAAY,EAClC,MAAMrG,EAAU,IAAIoD,MAAMpB,GAAUqB,KAAK,GAAGC,KAAI,KAC9C,MAAMC,EAAW3B,EAASU,SAASa,GAAY,GAC/CA,GAAc,EACd,MAAMtC,EAAoC,CAAC,EAC3C,IAAIY,EACJ,IAAK,IAAI+B,EAAI,EAAGA,EAAID,EAAUC,GAAK,EAAG,CACpC,MAAMpE,EAAMwC,EAASG,UAAUoB,GAAY,GAC3C,GAAI/D,EAAMP,KAAK4E,aAGbhC,EAAQ5C,KAAK8E,eAAe1E,EAAOkE,EAAa,GAChDA,GAAc,OACT,CACL,MAAMoD,EAAUvH,EAAUC,EAAOkE,EAAa,GAC9CD,EAAgBrE,KAAKuB,eAAe8C,EAAeqD,GACnD,MAAM7C,EAAa9B,EAASU,SAASa,EAAa,IAAI,GACtDA,GAAc,GACd,MAAM3F,EAAS,IAAI4F,MAAMM,GACzB,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAYE,GAAK,EAAG,CACtC,MAAMC,EAAI7E,EAAUC,EAAOkE,GACrBW,EAAI9E,EAAUC,EAAOkE,EAAa,GACxCA,GAAc,GACd3F,EAAOoG,GAAK,IAAIzE,EAAM0E,EAAGC,EAAG1E,EAC9B,CACAyB,EAASzB,GAAO5B,CAClB,CACF,CAEA,MAAO,CAAEqD,WAAUY,QAAO,IAG5B,MAAO,IACF6E,EACHE,KAAK,EACLxE,WACAkC,aAAc,MACdhB,gBACAkD,aACApG,UACAgG,MAAOnH,KAAKmH,MACZvC,aAAc5E,KAAK4E,aACnBQ,eAEJ,CAEA,cAAAN,CAAe1E,EAAmBC,GAChC,MAAO,CACLkC,UAAWN,EAAwB7B,EAAOC,EAAS,IAEvD,CAEA,oBAAMwF,CACJrD,EACAsD,EACAC,EACA7E,EAAgB,CAAC,GAEb4E,EAAM,IACRA,EAAM,GAGR,MAAMrD,QAAkBzC,KAAKsB,MAAMJ,GAC7BwB,EAAQD,EAAUE,YAAYH,GACpC,QAAc/B,IAAViC,EACF,MAAO,GAET,MAAMsD,EAAKvD,EAAUtB,QAAQuB,GAC7B,IAAKsD,EACH,MAAO,GAIT,MAAMG,EAAkBnG,KAAK4H,SAAS9B,EAAKC,GACrCpH,EAAkB,GAGxB,IAAK,MAAO+E,EAAOC,KAAQwC,EACzB,IAAK,IAAI5F,EAAMmD,EAAOnD,GAAOoD,EAAKpD,IAChC,GAAIyF,EAAGhE,SAASzB,GACd,IAAK,MAAM8F,KAAKL,EAAGhE,SAASzB,GAC1B5B,EAAOkB,KAAK,IAAIS,EAAM+F,EAAEjH,KAAMiH,EAAE1G,KAAMY,IAM9C,OAAO7B,EAAeC,EAAQ,IAAImB,EAAc,EAAG,GACrD,CAKA,QAAA8H,CAASxB,EAAazC,IACpByC,GAAO,GACG,IACRA,EAAM,GAEJzC,EAAM,GAAK,KACbA,EAAM,GAAK,IAEbA,GAAO,EACP,IAAIkE,EAAI,EACJC,EAAI,EACJC,EAAI/H,KAAKoH,SAAwB,EAAbpH,KAAKmH,MAC7B,MAAMa,EAAO,GACb,KAAOH,GAAK7H,KAAKmH,MAAOY,GAAK,EAAGD,GAAY,EA9OjC,IA8OwC,EAAJD,GAAQA,GAAK,EAAG,CAC7D,MAAM3H,EAAI4H,EAAIlB,EAAOR,EAAK2B,GACpBvJ,EAAIsJ,EAAIlB,EAAOjD,EAAKoE,GAC1B,GAAIvJ,EAAI0B,EAAI8H,EAAKjJ,OAASiB,KAAK4E,aAC7B,MAAM,IAAIzG,MACR,SAASiI,KAAOzC,oDAAsD3D,KAAKoH,mBAAmBpH,KAAKmH,iEAGvGa,EAAKnI,KAAK,CAACK,EAAG1B,GAChB,CACA,OAAOwJ,CACT,ECjQF,SAASC,EAAQC,GAEf,MAAO,qBAAqBC,KAAKD,EACnC,CAgBe,MAAME,EAgCnB,WAAArI,EAAY,KACVsI,EAAI,WACJxH,EAAU,IACVyH,EAAG,QACHC,EAAO,OACPC,EAAM,cACNC,EAAa,QACbC,EAAO,OACPC,EAAM,cACNC,EAAa,cACb9H,EAAgBC,GAAKA,EAAC,eACtB8H,EAAiB,UAcjB,GAAIhI,EACFb,KAAKa,WAAaA,OACb,GAAIwH,EACTrI,KAAKa,WAAa,IAAI,KAAUwH,OAC3B,KAAIC,EAGT,MAAM,IAAIQ,UAAU,0CAFpB9I,KAAKa,WAAa,IAAI,KAAWyH,EAGnC,CAEA,GAAIG,EACFzI,KAAK+I,MAAQ,IAAI,EAAI,CACnBlI,WAAY4H,EACZ3H,uBAEG,GAAI8H,EACT5I,KAAK+I,MAAQ,IAAI/B,EAAI,CACnBnG,WAAY+H,EACZ9H,uBAEG,GAAIyH,EACTvI,KAAK+I,MAAQ,IAAI,EAAI,CACnBlI,WAAY,IAAI,KAAU0H,GAC1BzH,uBAEG,GAAI4H,EACT1I,KAAK+I,MAAQ,IAAI/B,EAAI,CACnBnG,WAAY,IAAI,KAAU6H,GAC1B5H,uBAEG,GAAIuH,EACTrI,KAAK+I,MAAQ,IAAI,EAAI,CACnBlI,WAAY,IAAI,KAAU,GAAGwH,SAC7BvH,uBAEG,GAAI6H,EACT3I,KAAK+I,MAAQ,IAAI/B,EAAI,CACnBnG,WAAY,IAAI,KAAW8H,UAExB,GAAIH,EACTxI,KAAK+I,MAAQ,IAAI,EAAI,CACnBlI,WAAY,IAAI,KAAW2H,SAExB,KAAIF,EAKT,MAAM,IAAIQ,UACR,sFALF9I,KAAK+I,MAAQ,IAAI,EAAI,CACnBlI,WAAY,IAAI,KAAW,GAAGyH,UAMlC,CAEAtI,KAAKgB,aAAeF,EACpBd,KAAKgJ,WAAa,IAAIC,EAAAC,EAAwC,CAC5DC,MAAO,IAAI,IAAJ,CAAQ,CAAEC,QAAS5C,KAAKO,MAAM8B,EAAiB,SACtDrE,KAAM,CAACyC,EAAa5I,IAClB2B,KAAKqJ,UAAUpC,EAAM,CAAE5I,YAE7B,CAeA,cAAMiL,CACJ9G,EACAuF,EACAvJ,EACA0C,GAEA,IAAI7C,EAEAkL,EADAC,EAAmB,CAAC,EAGJ,mBAATtI,EACTqI,EAAWrI,GAEXsI,EAAUtI,EACVqI,EAAWrI,EAAKuI,aAChBpL,EAAS6C,EAAK7C,QAGhB,MAAMqL,QAAiB1J,KAAK+I,MAAM9H,YAAYuI,GAC9CpL,EAAiBC,GACjB,MAAMqF,EAAQqE,GAAK,EACbpE,EAAMnF,GAAKkL,EAAStE,aAC1B,KAAM1B,GAASC,GACb,MAAM,IAAImF,UACR,8EAGJ,GAAIpF,IAAUC,EACZ,OAGF,MAAMhF,QAAeqB,KAAK+I,MAAMlD,eAAerD,EAASkB,EAAOC,EAAK6F,GACpEpL,EAAiBC,GACjB,MAAMoH,EAAU,IAAIC,YAAY,QAGhC,IAAK,MAAMW,KAAK1H,EAAQ,CACtB,MAAM,OAAEsE,EAAM,WAAE0G,EAAU,WAAEC,SAAqB5J,KAAKgJ,WAAWa,IAC/DxD,EAAEpG,WACFoG,EACAhI,GAGFD,EAAiBC,GACjB,IAAIyL,EAAa,EACbC,EAAM,EAKV,MAAM7B,EAAMzC,EAAQE,OAAO1C,GACrB+G,EAAa/B,EAAQC,GAC3B,KAAO4B,EAAa5B,EAAInJ,QAAQ,CAC9B,IAAIkL,EACAlJ,EACJ,GAAIiJ,EAAY,CAEd,GADAjJ,EAAImH,EAAIgC,QAAQ,KAAMJ,IACX,IAAP/I,EACF,MAEFkJ,EAAO/B,EAAI9D,MAAM0F,EAAY/I,EAC/B,KAAO,CAEL,GADAA,EAAIkC,EAAOiH,QAAQ,KAAKC,WAAW,GAAIL,IAC5B,IAAP/I,EACF,MAEF,MAAMb,EAAI+C,EAAOmB,MAAM0F,EAAY/I,GACnCkJ,EAAOxE,EAAQE,OAAOzF,EACxB,CAGA,GAAI0J,EAAY,CACd,KAAOE,EAAazD,EAAEjH,KAAKE,cAAgBsK,EAAWG,OACtDA,GACF,CAGA,MAAM,gBAAEK,EAAe,SAAEC,GAAarK,KAAKsK,UACzCZ,EACAlH,EACAkB,EACAC,EACAsG,GAGF,GAAII,EACFd,EACEU,EAYmB,IAAnBN,EAAWI,IACRD,EAAaF,EAAWG,IACzB1D,EAAEjH,KAAKE,aACP,QAEC,QAAwBmB,IAApB2J,GAAiCA,GAAmBzG,EAI7D,OAEFmG,EAAa/I,EAAI,CACnB,CACF,CACF,CAEA,iBAAME,CAAYC,EAAgB,CAAC,GACjC,OAAOlB,KAAK+I,MAAM9H,YAAYC,EAChC,CAMA,qBAAMqJ,CAAgBrJ,EAAgB,CAAC,GACrC,MAAM,cAAEmD,EAAa,SAAER,EAAQ,aAAEwB,SACzBrF,KAAKiB,YAAYC,GAEzB9C,EAAiB8C,EAAK7C,QAEtB,MAAMmM,GAAYnG,GAAehF,eAAiB,GAAKgG,EAIjDxC,QAAY7C,KAAKa,WAAW4J,KAAKD,EAAU,EAAGtJ,GAC9Cd,QAAc,QAAMyC,GAG1B,GAAIgB,EAAU,CAEZ,IAAI6G,GAAe,EACnB,MAAMC,EAAc,KAAKR,WAAW,GAC9BS,EAAW/G,EAASsG,WAAW,GACrC,IAAK,IAAIhI,EAAI,EAAGA,EAAI/B,EAAMrB,SACpBoD,IAAMuI,EAAc,GAAKtK,EAAM+B,KAAOyI,GADVzI,GAAK,EAIjC/B,EAAM+B,KAAOwI,IACfD,EAAcvI,GAGlB,OAAO/B,EAAMwF,SAAS,EAAG8E,EAAc,EACzC,CACA,OAAOtK,CACT,CAQA,eAAMyK,CAAU3J,EAAgB,CAAC,GAC/B,MAAMuE,EAAU,IAAIC,YAAY,QAC1BtF,QAAcJ,KAAKuK,gBAAgBrJ,GACzC,OAAOuE,EAAQE,OAAOvF,EACxB,CAMA,+BAAM0K,CAA0B5J,EAAgB,CAAC,GAE/C,aADuBlB,KAAKiB,YAAYC,IACxBgD,WAClB,CAiBA,SAAAoG,CACEZ,EACAqB,EACAC,EACAC,EACAhB,GAEA,MAAM,cAAE1G,EAAa,SAAEM,EAAQ,eAAER,EAAc,OAAEC,GAAWoG,EAE5D,GAAI7F,GAAYoG,EAAKiB,WAAWrH,GAC9B,MAAO,CAAEwG,UAAU,GAIrB,IAAI,IAAE7G,EAAG,MAAEE,EAAK,IAAEC,GAAQJ,EACrBC,IACHA,EAAM,GAEHE,IACHA,EAAQ,GAELC,IACHA,EAAM,GAEO,QAAXL,IACFK,EAAM,GAER,MAAMwH,EAAY3E,KAAKT,IAAIvC,EAAKE,EAAOC,GAMvC,IAAIyH,EAAsB,EACtBC,EAAqB,EACrBC,EAAS,GACTlB,GAAkB,IACtB,MAAMvC,EAAIoC,EAAKlL,OACf,IAAK,IAAIoD,EAAI,EAAGA,EAAI0F,EAAI,EAAG1F,IACzB,GAAgB,OAAZ8H,EAAK9H,IAAeA,IAAM0F,EAAG,CAC/B,GAAIuD,IAAwB5H,GAC1B,GACExD,KAAKgB,aAAaiJ,EAAK7F,MAAMiH,EAAoBlJ,MACjD4I,EAEA,MAAO,CACLV,UAAU,QAGT,GAAIe,IAAwB1H,EAAO,CAMxC,GALA0G,EAAkBmB,SAAStB,EAAK7F,MAAMiH,EAAoBlJ,GAAI,IAEvC,mBAAnBkB,IACF+G,GAAmB,GAEjBA,GAAmBa,EACrB,MAAO,CACLb,kBACAC,UAAU,GAGd,IAAY,IAAR1G,GAAaA,IAAQD,IAEnB0G,EAAkB,GAAKY,EACzB,MAAO,CACLZ,kBACAC,UAAU,EAIlB,MAAO,GAAe,QAAX/G,GAA4C,IAAxB8H,EAC7BE,EAASrB,EAAK7F,MAAMiH,EAAoBlJ,QACnC,GAAIiJ,IAAwBzH,IAGpB,QAAXL,EACItD,KAAKwL,WACHpB,EACAkB,EACArB,EAAK7F,MAAMiH,EAAoBlJ,IAEjCsJ,OAAOF,SAAStB,EAAK7F,MAAMiH,EAAoBlJ,GAAI,MACpC6I,EACnB,MAAO,CACLX,UAAU,GAMhB,GAFAgB,EAAqBlJ,EAAI,EACzBiJ,GAAuB,EACnBA,EAAsBD,EACxB,KAEJ,CAEF,MAAO,CACLf,kBACAC,UAAU,EAEd,CAEA,UAAAmB,CAAWpB,EAAyBkB,EAAgBI,GAClD,IAAIC,EAAgBvB,EAAkBkB,EAAOvM,OAM7C,MAAM6M,EAAQF,EAAKG,SAAS,cAC5B,GAAgB,MAAZH,EAAK,IAAeE,GAajB,GAAIA,EACT,OAAOxB,EAAkB,MAdI,CAC7B,IAAI0B,EAAW,IACf,IAAK,IAAInH,EAAI,EAAGA,EAAI+G,EAAK3M,OAAQ4F,GAAK,EAAG,CACvC,GAAiB,MAAbmH,GAA6C,SAAzBJ,EAAKtH,MAAMO,EAAGA,EAAI,GAAe,CACvD,IAAIoH,EAAWL,EAAKxB,QAAQ,IAAKvF,IACf,IAAdoH,IACFA,EAAWL,EAAK3M,QAElB4M,EAAgBJ,SAASG,EAAKtH,MAAMO,EAAI,EAAGoH,GAAW,IACtD,KACF,CACAD,EAAWJ,EAAK/G,EAClB,CACF,CAGA,OAAOgH,CACT,CAUA,eAAMpJ,CAAUC,EAAiBtB,EAAgB,CAAC,GAChD,OAAOlB,KAAK+I,MAAMxG,UAAUC,EAAStB,EACvC,CAMA,eAAMmI,CAAUhD,EAAUnF,EAAgB,CAAC,GACzC,MAAM8K,QAAYhM,KAAKa,WAAW4J,KAChCpE,EAAE7F,cACF6F,EAAEjH,KAAKC,cACP6B,GAEF,OAAO,QAAgB8K,EAAK3F,EAC9B,E,mCCvfF,MAAM4F,GAMS,MAAMC,EAArB,cACE,KAAAC,QAAU,IAAIC,IACd,KAAAC,gBAAkB,IAAIC,eAyCxB,CAjCE,SAAAC,CAAUlO,EAAsB,IAAI4N,GAClC,GAAIjM,KAAK3B,OAAOC,QACd,MAAM,IAAIH,MAAM,yCAKlB6B,KAAKmM,QAAQK,IAAInO,GACbA,EAAOC,QAGT0B,KAAKyM,cAAcpO,GACyB,mBAA5BA,EAAOqO,kBACvBrO,EAAOqO,iBAAiB,SAAS,KAC/B1M,KAAKyM,cAAcpO,EAAO,GAGhC,CAEA,aAAAoO,CAAcpO,GACZ2B,KAAKmM,QAAQQ,OAAOtO,GACM,IAAtB2B,KAAKmM,QAAQS,MACf5M,KAAKqM,gBAAgBQ,OAEzB,CAEA,UAAIxO,GACF,OAAO2B,KAAKqM,gBAAgBhO,MAC9B,CAEA,KAAAwO,GACE7M,KAAKqM,gBAAgBQ,OACvB,EChDa,MAAMC,EAArB,cACE,KAAAC,UAAY,IAAIX,GAclB,CAXE,WAAAY,CAAYzD,EAAqB,QAC/BvJ,KAAK+M,UAAUP,IAAIjD,GACnBA,EAASvJ,KAAKiN,eAChB,CAEA,QAAA1D,CAAS2D,GACPlN,KAAKiN,eAAiBC,EACtB,IAAK,MAAMC,KAAOnN,KAAK+M,UACrBI,EAAID,EAER,ECSa,MAAMjE,EAWnB,WAAAlJ,EAAY,KACVyE,EAAI,MACJ2E,IAKA,GAAoB,mBAAT3E,EACT,MAAM,IAAIsE,UAAU,6BAEtB,GAAqB,iBAAVK,EACT,MAAM,IAAIL,UAAU,4BAEtB,GACuB,mBAAdK,EAAMU,KACQ,mBAAdV,EAAMiE,KACW,mBAAjBjE,EAAMwD,OAEb,MAAM,IAAI7D,UACR,qEAIJ9I,KAAKmJ,MAAQA,EACbnJ,KAAKqN,aAAe7I,CACtB,CAEA,uBAAO8I,CAAiBC,GACtB,MAEqB,eAAnBA,EAAUC,MAGS,gBAAnBD,EAAU9O,MAEY,wBAAtB8O,EAAUL,SAEY,mBAAtBK,EAAUL,OAEd,CAEA,KAAAO,CAAMC,EAAaC,GACb3N,KAAKmJ,MAAMU,IAAI6D,KAASC,GAC1B3N,KAAKmJ,MAAMwD,OAAOe,EAEtB,CAEA,IAAAlJ,CAAKkJ,EAAaE,EAASvP,EAAsBwP,GAC/C,MAAMC,EAAU,IAAI5B,EACd6B,EAAiB,IAAIjB,EAC3BiB,EAAef,YAAYa,GAC3B,MAAMG,EAAqB,CACzBF,QAASA,EACTG,QAASjO,KAAKqN,aAAaO,EAAME,EAAQzP,QAAS6O,IAChDa,EAAexE,SAAS2D,EAAQ,IAElCgB,SAAS,EACTH,iBACA,WAAIzP,GACF,OAAO0B,KAAK8N,QAAQzP,OAAOC,OAC7B,GAEF0P,EAASF,QAAQvB,UAAUlO,GAG3B2P,EAASF,QAAQzP,OAAOqO,iBAAiB,SAAS,KAC3CsB,EAASE,SACZlO,KAAKyN,MAAMC,EAAKM,EAClB,IAIFA,EAASC,QACNE,MACC,KACEH,EAASE,SAAU,CAAI,IAEzB,KACEF,EAASE,SAAU,EAGnBlO,KAAKyN,MAAMC,EAAKM,EAAS,IAG5BpM,OAAMwM,IAIL,MADAnI,QAAQmI,MAAMA,GACRA,CAAK,IAGfpO,KAAKmJ,MAAMiE,IAAIM,EAAKM,EACtB,CAEA,yBAAOK,CAAsBJ,EAAqB5P,GAIhD,SAASiQ,IACP,GAAIjQ,aAAM,EAANA,EAAQC,QACV,MAAMiQ,OAAOC,OAAO,IAAIrQ,MAAM,WAAY,CAAEM,KAAM,eAEtD,CAEA,OAAOwP,EAAQE,MACbM,IACEH,IACOG,KAETL,IAEE,MADAE,IACMF,CAAK,GAGjB,CAEA,GAAAM,CAAIhB,GACF,OAAO1N,KAAKmJ,MAAMuF,IAAIhB,EACxB,CAeA,GAAA7D,CACE6D,EACAE,EACAvP,EACAwP,GAEA,IAAKxP,GAAUuP,aAAgBe,YAC7B,MAAM,IAAI7F,UACR,yGAGJ,MAAM8F,EAAa5O,KAAKmJ,MAAMU,IAAI6D,GAElC,OAAIkB,EACEA,EAAWtQ,UAAYsQ,EAAWV,SAEpClO,KAAKyN,MAAMC,EAAKkB,GACT5O,KAAK6J,IAAI6D,EAAKE,EAAMvP,EAAQwP,IAGjCe,EAAWV,QAENU,EAAWX,SAKpBW,EAAWd,QAAQvB,UAAUlO,GAC7BuQ,EAAWb,eAAef,YAAYa,GAE/B5E,EAAsBoF,mBAC3BO,EAAWX,QACX5P,KAKJ2B,KAAKwE,KAAKkJ,EAAKE,EAAMvP,EAAQwP,GACtB5E,EAAsBoF,mBAG3BrO,KAAKmJ,MAAMU,IAAI6D,GAAMO,QACrB5P,GAEJ,CAQA,OAAOqP,GACL,MAAMmB,EAAc7O,KAAKmJ,MAAMU,IAAI6D,GAC/BmB,IACGA,EAAYX,SACfW,EAAYf,QAAQjB,QAEtB7M,KAAKmJ,MAAMwD,OAAOe,GAEtB,CAMA,KAAAoB,GAEE,MAAMC,EAAU/O,KAAKmJ,MAAM6F,OAC3B,IAAIC,EAAc,EAClB,IAAK,IAAIR,EAASM,EAAQG,QAAST,EAAOU,KAAMV,EAASM,EAAQG,OAC/DlP,KAAK2M,OAAO8B,EAAOW,OACnBH,GAAe,EAEjB,OAAOA,CACT,E","sources":["../../../node_modules/@gmod/tabix/src/util.ts","../../../node_modules/@gmod/tabix/src/virtualOffset.ts","../../../node_modules/@gmod/tabix/src/chunk.ts","../../../node_modules/@gmod/tabix/src/indexFile.ts","../../../node_modules/@gmod/tabix/src/long.ts","../../../node_modules/@gmod/tabix/src/tbi.ts","../../../node_modules/@gmod/tabix/src/csi.ts","../../../node_modules/@gmod/tabix/src/tabixIndexedFile.ts","../../../node_modules/@gmod/abortable-promise-cache/src/AggregateAbortController.ts","../../../node_modules/@gmod/abortable-promise-cache/src/AggregateStatusReporter.ts","../../../node_modules/@gmod/abortable-promise-cache/src/AbortablePromiseCache.ts"],"sourcesContent":["import Chunk from './chunk'\nimport VirtualOffset from './virtualOffset'\n\nclass AbortError extends Error {\n  public code: string | undefined\n}\n/**\n * Properly check if the given AbortSignal is aborted. Per the standard, if the\n * signal reads as aborted, this function throws either a DOMException\n * AbortError, or a regular error with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted`\n * attribute\n *\n * @returns nothing\n */\nexport function checkAbortSignal(signal?: AbortSignal) {\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    if (typeof DOMException !== 'undefined') {\n      throw new DOMException('aborted', 'AbortError')\n    } else {\n      const e = new AbortError('aborted')\n      e.code = 'ERR_ABORTED'\n      throw e\n    }\n  }\n}\n\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal?: AbortSignal) {\n  await Promise.resolve()\n  checkAbortSignal(signal)\n}\n\nexport function canMergeBlocks(chunk1: Chunk, chunk2: Chunk) {\n  return (\n    chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n    chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000\n  )\n}\n\nexport function optimizeChunks(chunks: Chunk[], lowest?: VirtualOffset) {\n  const mergedChunks: Chunk[] = []\n  let lastChunk: Chunk | null = null\n\n  if (chunks.length === 0) {\n    return chunks\n  }\n\n  chunks.sort(function (c0, c1) {\n    const dif = c0.minv.blockPosition - c1.minv.blockPosition\n    return dif !== 0 ? dif : c0.minv.dataPosition - c1.minv.dataPosition\n  })\n\n  chunks.forEach(chunk => {\n    if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n      if (lastChunk === null) {\n        mergedChunks.push(chunk)\n        lastChunk = chunk\n      } else {\n        if (canMergeBlocks(lastChunk, chunk)) {\n          if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n            lastChunk.maxv = chunk.maxv\n          }\n        } else {\n          mergedChunks.push(chunk)\n          lastChunk = chunk\n        }\n      }\n    }\n  })\n\n  return mergedChunks\n}\n","export default class VirtualOffset {\n  public blockPosition: number\n  public dataPosition: number\n  constructor(blockPosition: number, dataPosition: number) {\n    this.blockPosition = blockPosition // < offset of the compressed data block\n    this.dataPosition = dataPosition // < offset into the uncompressed data\n  }\n\n  toString() {\n    return `${this.blockPosition}:${this.dataPosition}`\n  }\n\n  compareTo(b: VirtualOffset) {\n    return (\n      this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition\n    )\n  }\n}\nexport function fromBytes(bytes: Uint8Array, offset = 0) {\n  return new VirtualOffset(\n    bytes[offset + 7]! * 0x10000000000 +\n      bytes[offset + 6]! * 0x100000000 +\n      bytes[offset + 5]! * 0x1000000 +\n      bytes[offset + 4]! * 0x10000 +\n      bytes[offset + 3]! * 0x100 +\n      bytes[offset + 2]!,\n    (bytes[offset + 1]! << 8) | bytes[offset]!,\n  )\n}\n","import VirtualOffset from './virtualOffset'\n\n// little class representing a chunk in the index\nexport default class Chunk {\n  public minv: VirtualOffset\n  public maxv: VirtualOffset\n  public bin: number\n  public _fetchedSize?: number\n\n  constructor(\n    minv: VirtualOffset,\n    maxv: VirtualOffset,\n    bin: number,\n    fetchedSize = undefined,\n  ) {\n    this.minv = minv\n    this.maxv = maxv\n    this.bin = bin\n    this._fetchedSize = fetchedSize\n  }\n\n  toUniqueString() {\n    return `${this.minv}..${this.maxv} (bin ${\n      this.bin\n    }, fetchedSize ${this.fetchedSize()})`\n  }\n\n  toString() {\n    return this.toUniqueString()\n  }\n\n  compareTo(b: Chunk) {\n    return (\n      this.minv.compareTo(b.minv) ||\n      this.maxv.compareTo(b.maxv) ||\n      this.bin - b.bin\n    )\n  }\n\n  fetchedSize() {\n    if (this._fetchedSize !== undefined) {\n      return this._fetchedSize\n    }\n    return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition\n  }\n}\n","import { GenericFilehandle } from 'generic-filehandle2'\nimport VirtualOffset from './virtualOffset'\nimport Chunk from './chunk'\n\nexport interface Options {\n  signal?: AbortSignal\n}\n\nexport interface IndexData {\n  refNameToId: Record<string, number>\n  refIdToName: string[]\n  metaChar: string | null\n  columnNumbers: { ref: number; start: number; end: number }\n  coordinateType: string\n  format: string\n  [key: string]: any\n}\n\nexport default abstract class IndexFile {\n  public filehandle: GenericFilehandle\n  public renameRefSeq: (arg0: string) => string\n  private parseP?: Promise<IndexData>\n\n  constructor({\n    filehandle,\n    renameRefSeqs = (n: string) => n,\n  }: {\n    filehandle: GenericFilehandle\n    renameRefSeqs?: (a: string) => string\n  }) {\n    this.filehandle = filehandle\n    this.renameRefSeq = renameRefSeqs\n  }\n\n  public abstract lineCount(refName: string, args: Options): Promise<number>\n\n  protected abstract _parse(opts: Options): Promise<IndexData>\n\n  public async getMetadata(opts: Options = {}) {\n    const { indices: _indices, ...rest } = await this.parse(opts)\n    return rest\n  }\n\n  public abstract blocksForRange(\n    refName: string,\n    start: number,\n    end: number,\n    opts: Options,\n  ): Promise<Chunk[]>\n\n  _findFirstData(\n    currentFdl: VirtualOffset | undefined,\n    virtualOffset: VirtualOffset,\n  ) {\n    if (currentFdl) {\n      return currentFdl.compareTo(virtualOffset) > 0\n        ? virtualOffset\n        : currentFdl\n    } else {\n      return virtualOffset\n    }\n  }\n\n  async parse(opts: Options = {}) {\n    if (!this.parseP) {\n      this.parseP = this._parse(opts).catch((e: unknown) => {\n        this.parseP = undefined\n        throw e\n      })\n    }\n    return this.parseP\n  }\n\n  async hasRefSeq(seqId: number, opts: Options = {}) {\n    const idx = await this.parse(opts)\n    return !!idx.indices[seqId]?.binIndex\n  }\n}\n","export const TWO_PWR_16_DBL = 1 << 16\nexport const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL\n\nexport function longFromBytesToUnsigned(source: Uint8Array, i = 0) {\n  const low =\n    source[i]! |\n    (source[i + 1]! << 8) |\n    (source[i + 2]! << 16) |\n    (source[i + 3]! << 24)\n  const high =\n    source[i + 4]! |\n    (source[i + 5]! << 8) |\n    (source[i + 6]! << 16) |\n    (source[i + 7]! << 24)\n  return (high >>> 0) * TWO_PWR_32_DBL + (low >>> 0)\n}\n","import VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\nimport { unzip } from '@gmod/bgzf-filehandle'\nimport { optimizeChunks, checkAbortSignal } from './util'\nimport IndexFile, { Options } from './indexFile'\nimport { longFromBytesToUnsigned } from './long'\n\nconst TBI_MAGIC = 21578324 // TBI\\1\nconst TAD_LIDX_SHIFT = 14\n\n/**\n * calculate the list of bins that may overlap with region [beg,end)\n * (zero-based half-open)\n */\nfunction reg2bins(beg: number, end: number) {\n  beg += 1 // < convert to 1-based closed\n  end -= 1\n  return [\n    [0, 0],\n    [1 + (beg >> 26), 1 + (end >> 26)],\n    [9 + (beg >> 23), 9 + (end >> 23)],\n    [73 + (beg >> 20), 73 + (end >> 20)],\n    [585 + (beg >> 17), 585 + (end >> 17)],\n    [4681 + (beg >> 14), 4681 + (end >> 14)],\n  ] as const\n}\n\nexport default class TabixIndex extends IndexFile {\n  async lineCount(refName: string, opts: Options = {}) {\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return -1\n    }\n    const idx = indexData.indices[refId]\n    if (!idx) {\n      return -1\n    }\n    return indexData.indices[refId].stats?.lineCount ?? -1\n  }\n\n  // fetch and parse the index\n  async _parse(opts: Options = {}) {\n    const buf = await this.filehandle.readFile(opts)\n    const bytes = await unzip(buf)\n    checkAbortSignal(opts.signal)\n    const dataView = new DataView(bytes.buffer)\n\n    const magic = dataView.getUint32(0, true)\n    if (magic !== TBI_MAGIC /* \"TBI\\1\" */) {\n      throw new Error('Not a TBI file')\n    }\n\n    // number of reference sequences in the index\n    const refCount = dataView.getUint32(4, true)\n    const formatFlags = dataView.getUint32(8, true)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const formatOpts: Record<number, string> = {\n      0: 'generic',\n      1: 'SAM',\n      2: 'VCF',\n    }\n    const format = formatOpts[formatFlags & 0xf]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: dataView.getInt32(12, true),\n      start: dataView.getInt32(16, true),\n      end: dataView.getInt32(20, true),\n    }\n    const metaValue = dataView.getInt32(24, true)\n    const depth = 5\n    const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7\n    const maxRefLength = 2 ** (14 + depth * 3)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : null\n    const skipLines = dataView.getInt32(28, true)\n\n    // read sequence dictionary\n    const nameSectionLength = dataView.getInt32(32, true)\n    const { refNameToId, refIdToName } = this._parseNameBytes(\n      bytes.slice(36, 36 + nameSectionLength),\n    )\n\n    // read the indexes for each reference sequence\n    let currOffset = 36 + nameSectionLength\n    let firstDataLine: VirtualOffset | undefined\n    const indices = new Array(refCount).fill(0).map(() => {\n      // the binning index\n      const binCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const binIndex: Record<number, Chunk[]> = {}\n      let stats\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = dataView.getUint32(currOffset, true)\n        currOffset += 4\n        if (bin > maxBinNumber + 1) {\n          throw new Error(\n            'tabix index contains too many bins, please use a CSI index',\n          )\n        } else if (bin === maxBinNumber + 1) {\n          const chunkCount = dataView.getInt32(currOffset, true)\n          currOffset += 4\n          if (chunkCount === 2) {\n            stats = this.parsePseudoBin(bytes, currOffset)\n          }\n          currOffset += 16 * chunkCount\n        } else {\n          const chunkCount = dataView.getInt32(currOffset, true)\n          currOffset += 4\n          const chunks = new Array(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, currOffset)\n            const v = fromBytes(bytes, currOffset + 8)\n            currOffset += 16\n            firstDataLine = this._findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      // the linear index\n      const linearCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const linearIndex = new Array(linearCount)\n      for (let k = 0; k < linearCount; k += 1) {\n        linearIndex[k] = fromBytes(bytes, currOffset)\n        currOffset += 8\n        firstDataLine = this._findFirstData(firstDataLine, linearIndex[k])\n      }\n      return {\n        binIndex,\n        linearIndex,\n        stats,\n      }\n    })\n\n    return {\n      indices,\n      metaChar,\n      maxBinNumber,\n      maxRefLength,\n      skipLines,\n      firstDataLine,\n      columnNumbers,\n      coordinateType,\n      format,\n      refIdToName,\n      refNameToId,\n      maxBlockSize: 1 << 16,\n    }\n  }\n\n  parsePseudoBin(bytes: Uint8Array, offset: number) {\n    return {\n      lineCount: longFromBytesToUnsigned(bytes, offset + 16),\n    }\n  }\n\n  _parseNameBytes(namesBytes: Uint8Array) {\n    let currRefId = 0\n    let currNameStart = 0\n    const refIdToName: string[] = []\n    const refNameToId: Record<string, number> = {}\n    const decoder = new TextDecoder('utf8')\n    for (let i = 0; i < namesBytes.length; i += 1) {\n      if (!namesBytes[i]) {\n        if (currNameStart < i) {\n          const refName = this.renameRefSeq(\n            decoder.decode(namesBytes.subarray(currNameStart, i)),\n          )\n          refIdToName[currRefId] = refName\n          refNameToId[refName] = currRefId\n        }\n        currNameStart = i + 1\n        currRefId += 1\n      }\n    }\n    return {\n      refNameToId,\n      refIdToName,\n    }\n  }\n\n  async blocksForRange(\n    refName: string,\n    min: number,\n    max: number,\n    opts: Options = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    const minOffset = ba.linearIndex.length\n      ? ba.linearIndex[\n          min >> TAD_LIDX_SHIFT >= ba.linearIndex.length\n            ? ba.linearIndex.length - 1\n            : min >> TAD_LIDX_SHIFT\n        ]\n      : new VirtualOffset(0, 0)\n    if (!minOffset) {\n      console.warn('querying outside of possible tabix range')\n    }\n\n    // const { linearIndex, binIndex } = indexes\n\n    const overlappingBins = reg2bins(min, max) // List of bin #s that overlap min, max\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          for (const c of ba.binIndex[bin]) {\n            chunks.push(new Chunk(c.minv, c.maxv, bin))\n          }\n        }\n      }\n    }\n\n    // Use the linear index to find minimum file position of chunks that could\n    // contain alignments in the region\n    const nintv = ba.linearIndex.length\n    let lowest = null\n    const minLin = Math.min(min >> 14, nintv - 1)\n    const maxLin = Math.min(max >> 14, nintv - 1)\n    for (let i = minLin; i <= maxLin; ++i) {\n      const vp = ba.linearIndex[i]\n      if (vp) {\n        if (!lowest || vp.compareTo(lowest) < 0) {\n          lowest = vp\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, lowest)\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\n\nimport VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\nimport { optimizeChunks } from './util'\n\nimport IndexFile, { Options } from './indexFile'\nimport { longFromBytesToUnsigned } from './long'\n\nconst CSI1_MAGIC = 21582659 // CSI\\1\nconst CSI2_MAGIC = 38359875 // CSI\\2\n\nconst formats = {\n  0: 'generic',\n  1: 'SAM',\n  2: 'VCF',\n}\n\nfunction lshift(num: number, bits: number) {\n  return num * 2 ** bits\n}\nfunction rshift(num: number, bits: number) {\n  return Math.floor(num / 2 ** bits)\n}\n\nexport default class CSI extends IndexFile {\n  private maxBinNumber: number\n  private depth: number\n  private minShift: number\n  constructor(args: any) {\n    super(args)\n    this.maxBinNumber = 0\n    this.depth = 0\n    this.minShift = 0\n  }\n  async lineCount(refName: string, opts: Options = {}): Promise<number> {\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return -1\n    }\n    const idx = indexData.indices[refId]\n    if (!idx) {\n      return -1\n    }\n    const { stats } = indexData.indices[refId]\n    if (stats) {\n      return stats.lineCount\n    }\n    return -1\n  }\n\n  indexCov() {\n    throw new Error('CSI indexes do not support indexcov')\n  }\n\n  parseAuxData(bytes: Uint8Array, offset: number) {\n    const dataView = new DataView(bytes.buffer)\n    const formatFlags = dataView.getInt32(offset, true)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const format = formats[(formatFlags & 0xf) as 0 | 1 | 2]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: dataView.getInt32(offset + 4, true),\n      start: dataView.getInt32(offset + 8, true),\n      end: dataView.getInt32(offset + 12, true),\n    }\n    const metaValue = dataView.getInt32(offset + 16, true)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : null\n    const skipLines = dataView.getInt32(offset + 20, true)\n    const nameSectionLength = dataView.getInt32(offset + 24, true)\n\n    const { refIdToName, refNameToId } = this._parseNameBytes(\n      bytes.subarray(offset + 28, offset + 28 + nameSectionLength),\n    )\n\n    return {\n      refIdToName,\n      refNameToId,\n      skipLines,\n      metaChar,\n      columnNumbers,\n      format,\n      coordinateType,\n    }\n  }\n\n  _parseNameBytes(namesBytes: Uint8Array) {\n    let currRefId = 0\n    let currNameStart = 0\n    const refIdToName = []\n    const refNameToId: Record<string, number> = {}\n    const decoder = new TextDecoder('utf8')\n    for (let i = 0; i < namesBytes.length; i += 1) {\n      if (!namesBytes[i]) {\n        if (currNameStart < i) {\n          const refName = this.renameRefSeq(\n            decoder.decode(namesBytes.subarray(currNameStart, i)),\n          )\n          refIdToName[currRefId] = refName\n          refNameToId[refName] = currRefId\n        }\n        currNameStart = i + 1\n        currRefId += 1\n      }\n    }\n    return {\n      refNameToId,\n      refIdToName,\n    }\n  }\n\n  // fetch and parse the index\n\n  async _parse(opts: Options = {}) {\n    const bytes = await unzip(await this.filehandle.readFile(opts))\n    const dataView = new DataView(bytes.buffer)\n\n    // check TBI magic numbers\n    let csiVersion\n    if (dataView.getUint32(0, true) === CSI1_MAGIC) {\n      csiVersion = 1\n    } else if (dataView.getUint32(0, true) === CSI2_MAGIC) {\n      csiVersion = 2\n    } else {\n      throw new Error('Not a CSI file')\n    }\n\n    this.minShift = dataView.getInt32(4, true)\n    this.depth = dataView.getInt32(8, true)\n    this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7\n    const maxRefLength = 2 ** (this.minShift + this.depth * 3)\n    const auxLength = dataView.getInt32(12, true)\n    const aux =\n      auxLength && auxLength >= 30\n        ? this.parseAuxData(bytes, 16)\n        : {\n            refIdToName: [],\n            refNameToId: {},\n            metaChar: null,\n            columnNumbers: { ref: 0, start: 1, end: 2 },\n            coordinateType: 'zero-based-half-open',\n            format: 'generic',\n          }\n    const refCount = dataView.getInt32(16 + auxLength, true)\n\n    // read the indexes for each reference sequence\n    let firstDataLine: VirtualOffset | undefined\n    let currOffset = 16 + auxLength + 4\n    const indices = new Array(refCount).fill(0).map(() => {\n      const binCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const binIndex: Record<string, Chunk[]> = {}\n      let stats\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = dataView.getUint32(currOffset, true)\n        if (bin > this.maxBinNumber) {\n          // this is a fake bin that actually has stats information about the\n          // reference sequence in it\n          stats = this.parsePseudoBin(bytes, currOffset + 4)\n          currOffset += 4 + 8 + 4 + 16 + 16\n        } else {\n          const loffset = fromBytes(bytes, currOffset + 4)\n          firstDataLine = this._findFirstData(firstDataLine, loffset)\n          const chunkCount = dataView.getInt32(currOffset + 12, true)\n          currOffset += 16\n          const chunks = new Array(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, currOffset)\n            const v = fromBytes(bytes, currOffset + 8)\n            currOffset += 16\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      return { binIndex, stats }\n    })\n\n    return {\n      ...aux,\n      csi: true,\n      refCount,\n      maxBlockSize: 1 << 16,\n      firstDataLine,\n      csiVersion,\n      indices,\n      depth: this.depth,\n      maxBinNumber: this.maxBinNumber,\n      maxRefLength,\n    }\n  }\n\n  parsePseudoBin(bytes: Uint8Array, offset: number) {\n    return {\n      lineCount: longFromBytesToUnsigned(bytes, offset + 28),\n    }\n  }\n\n  async blocksForRange(\n    refName: string,\n    min: number,\n    max: number,\n    opts: Options = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    // List of bin #s that overlap min, max\n    const overlappingBins = this.reg2bins(min, max)\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          for (const c of ba.binIndex[bin]) {\n            chunks.push(new Chunk(c.minv, c.maxv, bin))\n          }\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, new VirtualOffset(0, 0))\n  }\n\n  /**\n   * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n   */\n  reg2bins(beg: number, end: number) {\n    beg -= 1 // < convert to 1-based closed\n    if (beg < 1) {\n      beg = 1\n    }\n    if (end > 2 ** 50) {\n      end = 2 ** 34\n    } // 17 GiB ought to be enough for anybody\n    end -= 1\n    let l = 0\n    let t = 0\n    let s = this.minShift + this.depth * 3\n    const bins = []\n    for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n      const b = t + rshift(beg, s)\n      const e = t + rshift(end, s)\n      if (e - b + bins.length > this.maxBinNumber) {\n        throw new Error(\n          `query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`,\n        )\n      }\n      bins.push([b, e] as const)\n    }\n    return bins\n  }\n}\n","import AbortablePromiseCache from '@gmod/abortable-promise-cache'\nimport LRU from 'quick-lru'\nimport { GenericFilehandle, RemoteFile, LocalFile } from 'generic-filehandle2'\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle'\nimport { checkAbortSignal } from './util'\nimport IndexFile, { Options, IndexData } from './indexFile'\n\nimport Chunk from './chunk'\nimport TBI from './tbi'\nimport CSI from './csi'\n\nfunction isASCII(str: string) {\n  // eslint-disable-next-line no-control-regex\n  return /^[\\u0000-\\u007F]*$/.test(str)\n}\n\ntype GetLinesCallback = (line: string, fileOffset: number) => void\n\ninterface GetLinesOpts {\n  [key: string]: unknown\n  signal?: AbortSignal\n  lineCallback: GetLinesCallback\n}\n\ninterface ReadChunk {\n  buffer: Uint8Array\n  cpositions: number[]\n  dpositions: number[]\n}\n\nexport default class TabixIndexedFile {\n  private filehandle: GenericFilehandle\n  private index: IndexFile\n  private renameRefSeq: (n: string) => string\n  private chunkCache: AbortablePromiseCache<Chunk, ReadChunk>\n\n  /**\n   * @param {object} args\n   *\n   * @param {string} [args.path]\n   *\n   * @param {filehandle} [args.filehandle]\n   *\n   * @param {string} [args.tbiPath]\n   *\n   * @param {filehandle} [args.tbiFilehandle]\n   *\n   * @param {string} [args.csiPath]\n   *\n   * @param {filehandle} [args.csiFilehandle]\n   *\n   * @param {url} [args.url]\n   *\n   * @param {csiUrl} [args.csiUrl]\n   *\n   * @param {tbiUrl} [args.tbiUrl]\n   *\n   * @param {function} [args.renameRefSeqs] optional function with sig `string\n   * => string` to transform reference sequence names for the purpose of\n   * indexing and querying. note that the data that is returned is not altered,\n   * just the names of the reference sequences that are used for querying.\n   */\n  constructor({\n    path,\n    filehandle,\n    url,\n    tbiPath,\n    tbiUrl,\n    tbiFilehandle,\n    csiPath,\n    csiUrl,\n    csiFilehandle,\n    renameRefSeqs = n => n,\n    chunkCacheSize = 5 * 2 ** 20,\n  }: {\n    path?: string\n    filehandle?: GenericFilehandle\n    url?: string\n    tbiPath?: string\n    tbiUrl?: string\n    tbiFilehandle?: GenericFilehandle\n    csiPath?: string\n    csiUrl?: string\n    csiFilehandle?: GenericFilehandle\n    renameRefSeqs?: (n: string) => string\n    chunkCacheSize?: number\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else if (url) {\n      this.filehandle = new RemoteFile(url)\n    } else {\n      throw new TypeError('must provide either filehandle or path')\n    }\n\n    if (tbiFilehandle) {\n      this.index = new TBI({\n        filehandle: tbiFilehandle,\n        renameRefSeqs,\n      })\n    } else if (csiFilehandle) {\n      this.index = new CSI({\n        filehandle: csiFilehandle,\n        renameRefSeqs,\n      })\n    } else if (tbiPath) {\n      this.index = new TBI({\n        filehandle: new LocalFile(tbiPath),\n        renameRefSeqs,\n      })\n    } else if (csiPath) {\n      this.index = new CSI({\n        filehandle: new LocalFile(csiPath),\n        renameRefSeqs,\n      })\n    } else if (path) {\n      this.index = new TBI({\n        filehandle: new LocalFile(`${path}.tbi`),\n        renameRefSeqs,\n      })\n    } else if (csiUrl) {\n      this.index = new CSI({\n        filehandle: new RemoteFile(csiUrl),\n      })\n    } else if (tbiUrl) {\n      this.index = new TBI({\n        filehandle: new RemoteFile(tbiUrl),\n      })\n    } else if (url) {\n      this.index = new TBI({\n        filehandle: new RemoteFile(`${url}.tbi`),\n      })\n    } else {\n      throw new TypeError(\n        'must provide one of tbiFilehandle, tbiPath, csiFilehandle, csiPath, tbiUrl, csiUrl',\n      )\n    }\n\n    this.renameRefSeq = renameRefSeqs\n    this.chunkCache = new AbortablePromiseCache<Chunk, ReadChunk>({\n      cache: new LRU({ maxSize: Math.floor(chunkCacheSize / (1 << 16)) }),\n      fill: (args: Chunk, signal?: AbortSignal) =>\n        this.readChunk(args, { signal }),\n    })\n  }\n\n  /**\n   * @param refName name of the reference sequence\n   *\n   * @param start start of the region (in 0-based half-open coordinates)\n   *\n   * @param end end of the region (in 0-based half-open coordinates)\n   *\n   * @param opts callback called for each line in the region. can also pass a\n   * object param containing obj.lineCallback, obj.signal, etc\n   *\n   * @returns promise that is resolved when the whole read is finished,\n   * rejected on error\n   */\n  async getLines(\n    refName: string,\n    s: number | undefined,\n    e: number | undefined,\n    opts: GetLinesOpts | GetLinesCallback,\n  ) {\n    let signal: AbortSignal | undefined\n    let options: Options = {}\n    let callback: (line: string, lineOffset: number) => void\n\n    if (typeof opts === 'function') {\n      callback = opts\n    } else {\n      options = opts\n      callback = opts.lineCallback\n      signal = opts.signal\n    }\n\n    const metadata = await this.index.getMetadata(options)\n    checkAbortSignal(signal)\n    const start = s ?? 0\n    const end = e ?? metadata.maxRefLength\n    if (!(start <= end)) {\n      throw new TypeError(\n        'invalid start and end coordinates. start must be less than or equal to end',\n      )\n    }\n    if (start === end) {\n      return\n    }\n\n    const chunks = await this.index.blocksForRange(refName, start, end, options)\n    checkAbortSignal(signal)\n    const decoder = new TextDecoder('utf8')\n\n    // now go through each chunk and parse and filter the lines out of it\n    for (const c of chunks) {\n      const { buffer, cpositions, dpositions } = await this.chunkCache.get(\n        c.toString(),\n        c,\n        signal,\n      )\n\n      checkAbortSignal(signal)\n      let blockStart = 0\n      let pos = 0\n\n      // fast path, Buffer is just ASCII chars and not gigantor, can be\n      // converted to string and processed directly. if it is not ASCII or\n      // gigantic (chrome max str len is 512Mb), we have to decode line by line\n      const str = decoder.decode(buffer)\n      const strIsASCII = isASCII(str)\n      while (blockStart < str.length) {\n        let line: string\n        let n: number\n        if (strIsASCII) {\n          n = str.indexOf('\\n', blockStart)\n          if (n === -1) {\n            break\n          }\n          line = str.slice(blockStart, n)\n        } else {\n          n = buffer.indexOf('\\n'.charCodeAt(0), blockStart)\n          if (n === -1) {\n            break\n          }\n          const b = buffer.slice(blockStart, n)\n          line = decoder.decode(b)\n        }\n\n        // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n        if (dpositions) {\n          while (blockStart + c.minv.dataPosition >= dpositions[pos++]!) {}\n          pos--\n        }\n\n        // filter the line for whether it is within the requested range\n        const { startCoordinate, overlaps } = this.checkLine(\n          metadata,\n          refName,\n          start,\n          end,\n          line,\n        )\n\n        if (overlaps) {\n          callback(\n            line,\n            // cpositions[pos] refers to actual file offset of a bgzip block\n            // boundaries\n            //\n            // we multiply by (1 <<8) in order to make sure each block has a\n            // \"unique\" address space so that data in that block could never\n            // overlap\n            //\n            // then the blockStart-dpositions is an uncompressed file offset\n            // from that bgzip block boundary, and since the cpositions are\n            // multiplied by (1 << 8) these uncompressed offsets get a unique\n            // space\n            cpositions[pos]! * (1 << 8) +\n              (blockStart - dpositions[pos]!) +\n              c.minv.dataPosition +\n              1,\n          )\n        } else if (startCoordinate !== undefined && startCoordinate >= end) {\n          // the lines were overlapping the region, but now have stopped, so we\n          // must be at the end of the relevant data and we can stop processing\n          // data now\n          return\n        }\n        blockStart = n + 1\n      }\n    }\n  }\n\n  async getMetadata(opts: Options = {}) {\n    return this.index.getMetadata(opts)\n  }\n\n  /**\n   * get a buffer containing the \"header\" region of the file, which are the\n   * bytes up to the first non-meta line\n   */\n  async getHeaderBuffer(opts: Options = {}) {\n    const { firstDataLine, metaChar, maxBlockSize } =\n      await this.getMetadata(opts)\n\n    checkAbortSignal(opts.signal)\n\n    const maxFetch = (firstDataLine?.blockPosition || 0) + maxBlockSize\n    // TODO: what if we don't have a firstDataLine, and the header actually\n    // takes up more than one block? this case is not covered here\n\n    const buf = await this.filehandle.read(maxFetch, 0, opts)\n    const bytes = await unzip(buf)\n\n    // trim off lines after the last non-meta line\n    if (metaChar) {\n      // trim backward from the end\n      let lastNewline = -1\n      const newlineByte = '\\n'.charCodeAt(0)\n      const metaByte = metaChar.charCodeAt(0)\n      for (let i = 0; i < bytes.length; i += 1) {\n        if (i === lastNewline + 1 && bytes[i] !== metaByte) {\n          break\n        }\n        if (bytes[i] === newlineByte) {\n          lastNewline = i\n        }\n      }\n      return bytes.subarray(0, lastNewline + 1)\n    }\n    return bytes\n  }\n\n  /**\n   * get a string containing the \"header\" region of the file, is the portion up\n   * to the first non-meta line\n   *\n   * @returns {Promise} for a string\n   */\n  async getHeader(opts: Options = {}) {\n    const decoder = new TextDecoder('utf8')\n    const bytes = await this.getHeaderBuffer(opts)\n    return decoder.decode(bytes)\n  }\n\n  /**\n   * get an array of reference sequence names, in the order in which they occur\n   * in the file. reference sequence renaming is not applied to these names.\n   */\n  async getReferenceSequenceNames(opts: Options = {}) {\n    const metadata = await this.getMetadata(opts)\n    return metadata.refIdToName\n  }\n\n  /**\n   * @param {object} metadata metadata object from the parsed index, containing\n   * columnNumbers, metaChar, and format\n   *\n   * @param {string} regionRefName\n   *\n   * @param {number} regionStart region start coordinate (0-based-half-open)\n   *\n   * @param {number} regionEnd region end coordinate (0-based-half-open)\n   *\n   * @param {array[string]} line\n   *\n   * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,\n   * true if line is a data line that overlaps the given region\n   */\n  checkLine(\n    metadata: IndexData,\n    regionRefName: string,\n    regionStart: number,\n    regionEnd: number,\n    line: string,\n  ) {\n    const { columnNumbers, metaChar, coordinateType, format } = metadata\n    // skip meta lines\n    if (metaChar && line.startsWith(metaChar)) {\n      return { overlaps: false }\n    }\n\n    // check ref/start/end using column metadata from index\n    let { ref, start, end } = columnNumbers\n    if (!ref) {\n      ref = 0\n    }\n    if (!start) {\n      start = 0\n    }\n    if (!end) {\n      end = 0\n    }\n    if (format === 'VCF') {\n      end = 8\n    }\n    const maxColumn = Math.max(ref, start, end)\n\n    // this code is kind of complex, but it is fairly fast. basically, we want\n    // to avoid doing a split, because if the lines are really long that could\n    // lead to us allocating a bunch of extra memory, which is slow\n\n    let currentColumnNumber = 1 // cols are numbered starting at 1 in the index metadata\n    let currentColumnStart = 0\n    let refSeq = ''\n    let startCoordinate = -Infinity\n    const l = line.length\n    for (let i = 0; i < l + 1; i++) {\n      if (line[i] === '\\t' || i === l) {\n        if (currentColumnNumber === ref) {\n          if (\n            this.renameRefSeq(line.slice(currentColumnStart, i)) !==\n            regionRefName\n          ) {\n            return {\n              overlaps: false,\n            }\n          }\n        } else if (currentColumnNumber === start) {\n          startCoordinate = parseInt(line.slice(currentColumnStart, i), 10)\n          // we convert to 0-based-half-open\n          if (coordinateType === '1-based-closed') {\n            startCoordinate -= 1\n          }\n          if (startCoordinate >= regionEnd) {\n            return {\n              startCoordinate,\n              overlaps: false,\n            }\n          }\n          if (end === 0 || end === start) {\n            // if we have no end, we assume the feature is 1 bp long\n            if (startCoordinate + 1 <= regionStart) {\n              return {\n                startCoordinate,\n                overlaps: false,\n              }\n            }\n          }\n        } else if (format === 'VCF' && currentColumnNumber === 4) {\n          refSeq = line.slice(currentColumnStart, i)\n        } else if (currentColumnNumber === end) {\n          // this will never match if there is no end column\n          const endCoordinate =\n            format === 'VCF'\n              ? this._getVcfEnd(\n                  startCoordinate,\n                  refSeq,\n                  line.slice(currentColumnStart, i),\n                )\n              : Number.parseInt(line.slice(currentColumnStart, i), 10)\n          if (endCoordinate <= regionStart) {\n            return {\n              overlaps: false,\n            }\n          }\n        }\n        currentColumnStart = i + 1\n        currentColumnNumber += 1\n        if (currentColumnNumber > maxColumn) {\n          break\n        }\n      }\n    }\n    return {\n      startCoordinate,\n      overlaps: true,\n    }\n  }\n\n  _getVcfEnd(startCoordinate: number, refSeq: string, info: any) {\n    let endCoordinate = startCoordinate + refSeq.length\n    // ignore TRA features as they specify CHR2 and END as being on a different\n    // chromosome\n    //\n    // if CHR2 is on the same chromosome, still ignore it because there should\n    // be another pairwise feature at the end of this one\n    const isTRA = info.includes('SVTYPE=TRA')\n    if (info[0] !== '.' && !isTRA) {\n      let prevChar = ';'\n      for (let j = 0; j < info.length; j += 1) {\n        if (prevChar === ';' && info.slice(j, j + 4) === 'END=') {\n          let valueEnd = info.indexOf(';', j)\n          if (valueEnd === -1) {\n            valueEnd = info.length\n          }\n          endCoordinate = parseInt(info.slice(j + 4, valueEnd), 10)\n          break\n        }\n        prevChar = info[j]\n      }\n    } else if (isTRA) {\n      return startCoordinate + 1\n    }\n    return endCoordinate\n  }\n\n  /**\n   * return the approximate number of data lines in the given reference\n   * sequence\n   *\n   * @param refSeq reference sequence name\n   *\n   * @returns number of data lines present on that reference sequence\n   */\n  async lineCount(refName: string, opts: Options = {}) {\n    return this.index.lineCount(refName, opts)\n  }\n\n  /**\n   * read and uncompress the data in a chunk (composed of one or more\n   * contiguous bgzip blocks) of the file\n   */\n  async readChunk(c: Chunk, opts: Options = {}) {\n    const ret = await this.filehandle.read(\n      c.fetchedSize(),\n      c.minv.blockPosition,\n      opts,\n    )\n    return unzipChunkSlice(ret, c)\n  }\n}\n","class NullSignal {}\n\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nexport default class AggregateAbortController {\n  signals = new Set()\n  abortController = new AbortController()\n\n  /**\n   * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n   *  will be treated as a null-signal, and this abortcontroller will no\n   *  longer be abortable.\n   */\n  //@ts-ignore\n  addSignal(signal: AbortSignal = new NullSignal()): void {\n    if (this.signal.aborted) {\n      throw new Error('cannot add a signal, already aborted!')\n    }\n\n    // note that a NullSignal will never fire, so if we\n    // have one this thing will never actually abort\n    this.signals.add(signal)\n    if (signal.aborted) {\n      // handle the abort immediately if it is already aborted\n      // for some reason\n      this.handleAborted(signal)\n    } else if (typeof signal.addEventListener === 'function') {\n      signal.addEventListener('abort', () => {\n        this.handleAborted(signal)\n      })\n    }\n  }\n\n  handleAborted(signal: AbortSignal): void {\n    this.signals.delete(signal)\n    if (this.signals.size === 0) {\n      this.abortController.abort()\n    }\n  }\n\n  get signal(): AbortSignal {\n    return this.abortController.signal\n  }\n\n  abort(): void {\n    this.abortController.abort()\n  }\n}\n","export default class AggregateStatusReporter {\n  callbacks = new Set<Function>()\n  currentMessage: unknown\n\n  addCallback(callback: Function = () => {}): void {\n    this.callbacks.add(callback)\n    callback(this.currentMessage)\n  }\n\n  callback(message: unknown) {\n    this.currentMessage = message\n    for (const elt of this.callbacks) {\n      elt(message)\n    }\n  }\n}\n","import AggregateAbortController from './AggregateAbortController'\nimport AggregateStatusReporter from './AggregateStatusReporter'\n\ninterface Cache<U> {\n  delete: (key: string) => void\n  keys: () => Iterator<string>\n  get: (key: string) => U | undefined\n  set: (key: string, value: U) => void\n  has: (key: string) => boolean\n}\ntype FillCallback<T, U> = (\n  data: T,\n  signal?: AbortSignal,\n  statusCallback?: Function,\n) => Promise<U>\n\ninterface Entry<U> {\n  aborter: AggregateAbortController\n  settled: boolean\n  readonly aborted: boolean\n  statusReporter: AggregateStatusReporter\n  promise: Promise<U>\n}\nexport default class AbortablePromiseCache<T, U> {\n  /**\n   * @param {object} args constructor args\n   * @param {Function} args.fill fill callback, will be called with sig `fill(data, signal)`\n   * @param {object} args.cache backing store to use, must implement `get(key)`, `set(key, val)`,\n   *   `delete(key)`, and `keys() -> iterator`\n   */\n\n  private cache: Cache<Entry<U>>\n  private fillCallback: FillCallback<T, U>\n\n  constructor({\n    fill,\n    cache,\n  }: {\n    fill: FillCallback<T, U>\n    cache: Cache<Entry<U>>\n  }) {\n    if (typeof fill !== 'function') {\n      throw new TypeError('must pass a fill function')\n    }\n    if (typeof cache !== 'object') {\n      throw new TypeError('must pass a cache object')\n    }\n    if (\n      typeof cache.get !== 'function' ||\n      typeof cache.set !== 'function' ||\n      typeof cache.delete !== 'function'\n    ) {\n      throw new TypeError(\n        'cache must implement get(key), set(key, val), and and delete(key)',\n      )\n    }\n\n    this.cache = cache\n    this.fillCallback = fill\n  }\n\n  static isAbortException(exception: Error) {\n    return (\n      // DOMException\n      exception.name === 'AbortError' ||\n      // standard-ish non-DOM abort exception\n      //@ts-ignore\n      exception.code === 'ERR_ABORTED' ||\n      // stringified DOMException\n      exception.message === 'AbortError: aborted' ||\n      // stringified standard-ish exception\n      exception.message === 'Error: aborted'\n    )\n  }\n\n  evict(key: string, entry: Entry<U>) {\n    if (this.cache.get(key) === entry) {\n      this.cache.delete(key)\n    }\n  }\n\n  fill(key: string, data: T, signal?: AbortSignal, statusCallback?: Function) {\n    const aborter = new AggregateAbortController()\n    const statusReporter = new AggregateStatusReporter()\n    statusReporter.addCallback(statusCallback)\n    const newEntry: Entry<U> = {\n      aborter: aborter,\n      promise: this.fillCallback(data, aborter.signal, (message: unknown) => {\n        statusReporter.callback(message)\n      }),\n      settled: false,\n      statusReporter,\n      get aborted() {\n        return this.aborter.signal.aborted\n      },\n    }\n    newEntry.aborter.addSignal(signal)\n\n    // remove the fill from the cache when its abortcontroller fires, if still in there\n    newEntry.aborter.signal.addEventListener('abort', () => {\n      if (!newEntry.settled) {\n        this.evict(key, newEntry)\n      }\n    })\n\n    // chain off the cached promise to record when it settles\n    newEntry.promise\n      .then(\n        () => {\n          newEntry.settled = true\n        },\n        () => {\n          newEntry.settled = true\n\n          // if the fill throws an error (including abort) and is still in the cache, remove it\n          this.evict(key, newEntry)\n        },\n      )\n      .catch(error => {\n        // this will only be reached if there is some kind of\n        // bad bug in this library\n        console.error(error)\n        throw error\n      })\n\n    this.cache.set(key, newEntry)\n  }\n\n  static checkSinglePromise<U>(promise: Promise<U>, signal?: AbortSignal) {\n    // check just this signal for having been aborted, and abort the\n    // promise if it was, regardless of what happened with the cached\n    // response\n    function checkForSingleAbort() {\n      if (signal?.aborted) {\n        throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' })\n      }\n    }\n\n    return promise.then(\n      result => {\n        checkForSingleAbort()\n        return result\n      },\n      error => {\n        checkForSingleAbort()\n        throw error\n      },\n    )\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key)\n  }\n\n  /**\n   * Callback for getting status of the pending async\n   *\n   * @callback statusCallback\n   * @param {any} status, current status string or message object\n   */\n\n  /**\n   * @param {any} key cache key to use for this request\n   * @param {any} data data passed as the first argument to the fill callback\n   * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n   * @param {statusCallback} a callback to get the current status of a pending async operation\n   */\n  get(\n    key: string,\n    data: T,\n    signal?: AbortSignal,\n    statusCallback?: Function,\n  ): Promise<U> {\n    if (!signal && data instanceof AbortSignal) {\n      throw new TypeError(\n        'second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?',\n      )\n    }\n    const cacheEntry = this.cache.get(key)\n\n    if (cacheEntry) {\n      if (cacheEntry.aborted && !cacheEntry.settled) {\n        // if it's aborted but has not realized it yet, evict it and redispatch\n        this.evict(key, cacheEntry)\n        return this.get(key, data, signal, statusCallback)\n      }\n\n      if (cacheEntry.settled) {\n        // too late to abort, just return it\n        return cacheEntry.promise\n      }\n\n      // request is in-flight, add this signal to its list of signals,\n      // or if there is no signal, the aborter will become non-abortable\n      cacheEntry.aborter.addSignal(signal)\n      cacheEntry.statusReporter.addCallback(statusCallback)\n\n      return AbortablePromiseCache.checkSinglePromise(\n        cacheEntry.promise,\n        signal,\n      )\n    }\n\n    // if we got here, it is not in the cache. fill.\n    this.fill(key, data, signal, statusCallback)\n    return AbortablePromiseCache.checkSinglePromise(\n      //see https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#non-null-assertion-operator-postfix-\n\n      this.cache.get(key)!.promise,\n      signal,\n    )\n  }\n\n  /**\n   * delete the given entry from the cache. if it exists and its fill request has\n   * not yet settled, the fill will be signaled to abort.\n   *\n   * @param {any} key\n   */\n  delete(key: string) {\n    const cachedEntry = this.cache.get(key)\n    if (cachedEntry) {\n      if (!cachedEntry.settled) {\n        cachedEntry.aborter.abort()\n      }\n      this.cache.delete(key)\n    }\n  }\n\n  /**\n   * Clear all requests from the cache. Aborts any that have not settled.\n   * @returns {number} count of entries deleted\n   */\n  clear() {\n    // iterate without needing regenerator-runtime\n    const keyIter = this.cache.keys()\n    let deleteCount = 0\n    for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n      this.delete(result.value)\n      deleteCount += 1\n    }\n    return deleteCount\n  }\n}\n"],"names":["AbortError","Error","checkAbortSignal","signal","aborted","DOMException","e","code","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","length","sort","c0","c1","dif","minv","blockPosition","dataPosition","forEach","chunk","chunk1","chunk2","maxv","compareTo","push","VirtualOffset","constructor","this","toString","b","fromBytes","bytes","offset","Chunk","bin","fetchedSize","undefined","_fetchedSize","toUniqueString","IndexFile","filehandle","renameRefSeqs","n","renameRefSeq","getMetadata","opts","indices","_indices","rest","parse","_findFirstData","currentFdl","virtualOffset","parseP","_parse","catch","hasRefSeq","seqId","idx","binIndex","longFromBytesToUnsigned","source","i","low","TWO_PWR_16_DBL","TabixIndex","lineCount","refName","indexData","refId","refNameToId","stats","buf","readFile","dataView","DataView","buffer","getUint32","refCount","formatFlags","coordinateType","format","columnNumbers","ref","getInt32","start","end","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","refIdToName","_parseNameBytes","slice","firstDataLine","currOffset","Array","fill","map","binCount","j","maxBinNumber","chunkCount","parsePseudoBin","k","u","v","linearCount","linearIndex","maxRefLength","maxBlockSize","namesBytes","currRefId","currNameStart","decoder","TextDecoder","decode","subarray","blocksForRange","min","max","ba","console","warn","overlappingBins","beg","c","nintv","minLin","Math","maxLin","vp","formats","rshift","num","bits","floor","CSI","args","super","depth","minShift","indexCov","parseAuxData","csiVersion","auxLength","aux","loffset","csi","reg2bins","l","t","s","bins","isASCII","str","test","TabixIndexedFile","path","url","tbiPath","tbiUrl","tbiFilehandle","csiPath","csiUrl","csiFilehandle","chunkCacheSize","TypeError","index","chunkCache","AbortablePromiseCache","A","cache","maxSize","readChunk","getLines","callback","options","lineCallback","metadata","cpositions","dpositions","get","blockStart","pos","strIsASCII","line","indexOf","charCodeAt","startCoordinate","overlaps","checkLine","getHeaderBuffer","maxFetch","read","lastNewline","newlineByte","metaByte","getHeader","getReferenceSequenceNames","regionRefName","regionStart","regionEnd","startsWith","maxColumn","currentColumnNumber","currentColumnStart","refSeq","parseInt","_getVcfEnd","Number","info","endCoordinate","isTRA","includes","prevChar","valueEnd","ret","NullSignal","AggregateAbortController","signals","Set","abortController","AbortController","addSignal","add","handleAborted","addEventListener","delete","size","abort","AggregateStatusReporter","callbacks","addCallback","currentMessage","message","elt","set","fillCallback","isAbortException","exception","name","evict","key","entry","data","statusCallback","aborter","statusReporter","newEntry","promise","settled","then","error","checkSinglePromise","checkForSingleAbort","Object","assign","result","has","AbortSignal","cacheEntry","cachedEntry","clear","keyIter","keys","deleteCount","next","done","value"],"sourceRoot":""}