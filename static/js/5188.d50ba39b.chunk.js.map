{"version":3,"file":"static/js/5188.d50ba39b.chunk.js","mappings":"uIACA,MAAMA,GAMQ,MAAOC,EAArBC,WAAAA,GACE,KAAAC,QAAU,IAAIC,IACd,KAAAC,gBAAkB,IAAIC,eAyCxB,CAjCEC,SAAAA,CAAUC,EAAsB,IAAIR,GAClC,GAAIS,KAAKD,OAAOE,QACd,MAAM,IAAIC,MAAM,yCAKlBF,KAAKN,QAAQS,IAAIJ,GACbA,EAAOE,QAGTD,KAAKI,cAAcL,GACyB,mBAA5BA,EAAOM,kBACvBN,EAAOM,iBAAiB,QAAS,KAC/BL,KAAKI,cAAcL,IAGzB,CAEAK,aAAAA,CAAcL,GACZC,KAAKN,QAAQY,OAAOP,GACM,IAAtBC,KAAKN,QAAQa,MACfP,KAAKJ,gBAAgBY,OAEzB,CAEA,UAAIT,GACF,OAAOC,KAAKJ,gBAAgBG,MAC9B,CAEAS,KAAAA,GACER,KAAKJ,gBAAgBY,OACvB,ECjDY,MAAOC,EAArBhB,WAAAA,GACE,KAAAiB,UAAY,IAAIf,GAgBlB,CAbEgB,WAAAA,CAAYC,EAA6BA,QACvCZ,KAAKU,UAAUP,IAAIS,GACfZ,KAAKa,gBACPD,EAASZ,KAAKa,eAElB,CAEAD,QAAAA,CAASE,GACPd,KAAKa,eAAiBC,EACtB,IAAK,MAAMC,KAAOf,KAAKU,UACrBK,EAAID,EAER,ECOY,MAAOE,EAWnBvB,WAAAA,EAAY,KACVwB,EAAI,MACJC,IAKA,GAAoB,mBAATD,EACT,MAAM,IAAIE,UAAU,6BAEtB,GAAqB,iBAAVD,EACT,MAAM,IAAIC,UAAU,4BAEtB,GACuB,mBAAdD,EAAME,KACQ,mBAAdF,EAAMG,KACW,mBAAjBH,EAAMZ,OAEb,MAAM,IAAIa,UACR,qEAIJnB,KAAKkB,MAAQA,EACblB,KAAKsB,aAAeL,CACtB,CAEA,uBAAOM,CAAiBC,GACtB,MAEqB,eAAnBA,EAAUC,MAGS,gBAAnBD,EAAUE,MAEY,wBAAtBF,EAAUV,SAEY,mBAAtBU,EAAUV,OAEd,CAEAa,KAAAA,CAAMC,EAAaC,GACb7B,KAAKkB,MAAME,IAAIQ,KAASC,GAC1B7B,KAAKkB,MAAMZ,OAAOsB,EAEtB,CAEAX,IAAAA,CACEW,EACAE,EACA/B,EACAgC,GAEA,MAAMC,EAAU,IAAIxC,EACdyC,EAAiB,IAAIxB,EAC3BwB,EAAetB,YAAYoB,GAC3B,MAAMG,EAAwB,CAC5BF,QAASA,EACTG,QAASnC,KAAKsB,aAAaQ,EAAME,EAAQjC,OAASe,IAChDmB,EAAerB,SAASE,KAE1BsB,SAAS,EACTH,iBACA,WAAIhC,GACF,OAAOD,KAAKgC,QAAQjC,OAAOE,OAC7B,GAEFiC,EAASF,QAAQlC,UAAUC,GAG3BmC,EAASF,QAAQjC,OAAOM,iBAAiB,QAAS,KAC3C6B,EAASE,SACZpC,KAAK2B,MAAMC,EAAKM,KAKpBA,EAASC,QACNE,KACC,KACEH,EAASE,SAAU,GAErB,KACEF,EAASE,SAAU,EAGnBpC,KAAK2B,MAAMC,EAAKM,KAGnBI,MAAOC,IAIN,MADAC,QAAQD,MAAMA,GACRA,IAGVvC,KAAKkB,MAAMG,IAAIO,EAAKM,EACtB,CAEA,yBAAOO,CAAsBN,EAAqBpC,GAIhD,SAAS2C,IACP,GAAI3C,GAAQE,QACV,MAAM0C,OAAOC,OAAO,IAAI1C,MAAM,WAAY,CAAEwB,KAAM,eAEtD,CAEA,OAAOS,EAAQE,KACbQ,IACEH,IACOG,GAERN,IAEC,MADAG,IACMH,GAGZ,CAEAO,GAAAA,CAAIlB,GACF,OAAO5B,KAAKkB,MAAM4B,IAAIlB,EACxB,CAeAR,GAAAA,CACEQ,EACAE,EACA/B,EACAgC,GAEA,IAAKhC,GAAU+B,aAAgBiB,YAC7B,MAAM,IAAI5B,UACR,yGAGJ,MAAM6B,EAAahD,KAAKkB,MAAME,IAAIQ,GAElC,OAAIoB,EACEA,EAAW/C,UAAY+C,EAAWZ,SAEpCpC,KAAK2B,MAAMC,EAAKoB,GACThD,KAAKoB,IAAIQ,EAAKE,EAAM/B,EAAQgC,IAGjCiB,EAAWZ,QAENY,EAAWb,SAKpBa,EAAWhB,QAAQlC,UAAUC,GAC7BiD,EAAWf,eAAetB,YAAYoB,GAE/Bf,EAAsByB,mBAC3BO,EAAWb,QACXpC,KAKJC,KAAKiB,KAAKW,EAAKE,EAAM/B,EAAQgC,GACtBf,EAAsByB,mBAE3BzC,KAAKkB,MAAME,IAAIQ,GAAMO,QACrBpC,GAEJ,CAQAO,OAAOsB,GACL,MAAMqB,EAAcjD,KAAKkB,MAAME,IAAIQ,GAC/BqB,IACGA,EAAYb,SACfa,EAAYjB,QAAQxB,QAEtBR,KAAKkB,MAAMZ,OAAOsB,GAEtB,CAMAsB,KAAAA,GAEE,MAAMC,EAAUnD,KAAKkB,MAAMkC,OAC3B,IAAIC,EAAc,EAClB,IAAK,IAAIR,EAASM,EAAQG,QAAST,EAAOU,KAAMV,EAASM,EAAQG,OAC/DtD,KAAKM,OAAOuC,EAAOW,OACnBH,GAAe,EAEjB,OAAOA,CACT,E,2FCnPY,MAAOI,EAMnBhE,WAAAA,CACEiE,EACAC,EACAC,EACAC,GAEA7D,KAAK0D,KAAOA,EACZ1D,KAAK2D,KAAOA,EACZ3D,KAAK4D,IAAMA,EACX5D,KAAK8D,aAAeD,CACtB,CAEAE,cAAAA,GACE,MAAO,GAAG/D,KAAK0D,SAAS1D,KAAK2D,aAC3B3D,KAAK4D,oBACU5D,KAAK6D,gBACxB,CAEAG,QAAAA,GACE,OAAOhE,KAAK+D,gBACd,CAEAE,SAAAA,CAAUC,GACR,OACElE,KAAK0D,KAAKO,UAAUC,EAAER,OACtB1D,KAAK2D,KAAKM,UAAUC,EAAEP,OACtB3D,KAAK4D,IAAMM,EAAEN,GAEjB,CAEAC,WAAAA,GACE,YAA0BM,IAAtBnE,KAAK8D,aACA9D,KAAK8D,aAEP9D,KAAK2D,KAAKS,cAAgB,MAAYpE,KAAK0D,KAAKU,aACzD,ECzBY,MAAgBC,EAK5B5E,WAAAA,EAAY,WACV6E,EAAU,cACVC,EAAiBC,GAAcA,IAK/BxE,KAAKsE,WAAaA,EAClBtE,KAAKyE,aAAeF,CACtB,CAMO,iBAAMG,CAAYC,EAAgB,CAAC,GACxC,MAAQC,QAASC,KAAaC,SAAe9E,KAAK+E,MAAMJ,GACxD,OAAOG,CACT,CASAE,cAAAA,CACEC,EACAC,GAEA,OAAID,EACKA,EAAWhB,UAAUiB,GAAiB,EACzCA,EACAD,EAEGC,CAEX,CAEA,WAAMH,CAAMJ,EAAgB,CAAC,GAO3B,OANK3E,KAAKmF,SACRnF,KAAKmF,OAASnF,KAAKoF,OAAOT,GAAMrC,MAAOC,IAErC,MADAvC,KAAKmF,YAAShB,EACR5B,KAGHvC,KAAKmF,MACd,CAEA,eAAME,CAAUC,EAAeX,EAAgB,CAAC,GAC9C,MAAMY,QAAYvF,KAAK+E,MAAMJ,GAC7B,QAASY,EAAIX,QAAQU,IAAQE,QAC/B,CAEAC,eAAAA,CAAgBC,GACd,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMC,EAAwB,GACxBC,EAAsC,CAAC,EACvCC,EAAU,IAAIC,YAAY,QAChC,IAAK,IAAIC,EAAI,EAAGA,EAAIP,EAAWQ,OAAQD,GAAK,EAC1C,IAAKP,EAAWO,GAAI,CAClB,GAAIL,EAAgBK,EAAG,CACrB,MAAME,EAAUnG,KAAKyE,aACnBsB,EAAQK,OAAOV,EAAWW,SAAST,EAAeK,KAEpDJ,EAAYF,GAAaQ,EACzBL,EAAYK,GAAWR,CACzB,CACAC,EAAgBK,EAAI,EACpBN,GAAa,CACf,CAEF,MAAO,CACLG,cACAD,cAEJ,ECnGI,SAAUS,EAAwBC,EAAoBN,EAAI,GAC9D,MAAMO,EACJD,EAAON,GACNM,EAAON,EAAI,IAAO,EAClBM,EAAON,EAAI,IAAO,GAClBM,EAAON,EAAI,IAAO,GAMrB,OAb4BQ,aAS1BF,EAAON,EAAI,GACVM,EAAON,EAAI,IAAO,EAClBM,EAAON,EAAI,IAAO,GAClBM,EAAON,EAAI,IAAO,MACJ,IAAuBO,IAAQ,EAClD,CCZM,SAAUE,EAAeC,EAAeC,GAC5C,OACEA,EAAOlD,KAAKU,cAAgBuC,EAAOhD,KAAKS,cAAgB,MACxDwC,EAAOjD,KAAKS,cAAgBuC,EAAOjD,KAAKU,cAAgB,GAE5D,CAEM,SAAUyC,EAAeC,EAAiBC,GAC9C,MAAMC,EAAwB,GAC9B,IAAIC,EAEJ,GAAsB,IAAlBH,EAAOZ,OACT,OAAOY,EAGTA,EAAOI,KAAK,SAAUC,EAAIC,GACxB,MAAMC,EAAMF,EAAGzD,KAAKU,cAAgBgD,EAAG1D,KAAKU,cAC5C,OAAe,IAARiD,EAAYF,EAAGzD,KAAK4D,aAAeF,EAAG1D,KAAK4D,aAAeD,CACnE,GAEA,IAAK,MAAME,KAAST,IACbC,GAAUQ,EAAM5D,KAAKM,UAAU8C,GAAU,UAC1B5C,IAAd8C,GACFD,EAAaQ,KAAKD,GAClBN,EAAYM,GAERb,EAAeO,EAAWM,GACxBA,EAAM5D,KAAKM,UAAUgD,EAAUtD,MAAQ,IACzCsD,EAAUtD,KAAO4D,EAAM5D,OAGzBqD,EAAaQ,KAAKD,GAClBN,EAAYM,IAMpB,OAAOP,CACT,CC1Cc,MAAOS,EAGnBhI,WAAAA,CAAY2E,EAAuBkD,GACjCtH,KAAKoE,cAAgBA,EACrBpE,KAAKsH,aAAeA,CACtB,CAEAtD,QAAAA,GACE,MAAO,GAAGhE,KAAKoE,iBAAiBpE,KAAKsH,cACvC,CAEArD,SAAAA,CAAUC,GACR,OACElE,KAAKoE,cAAgBF,EAAEE,eAAiBpE,KAAKsH,aAAepD,EAAEoD,YAElE,EAEI,SAAUI,EAAUC,EAAmBC,EAAS,GACpD,OAAO,IAAIH,EACY,cAArBE,EAAMC,EAAS,GACQ,WAArBD,EAAMC,EAAS,GACM,SAArBD,EAAMC,EAAS,GACM,MAArBD,EAAMC,EAAS,GACM,IAArBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAChBD,EAAMC,EAAS,IAAO,EAAKD,EAAMC,GAEtC,CCpBA,MAGMC,EAAU,CACd,EAAG,UACH,EAAG,MACH,EAAG,OAGL,SAASC,EAAOC,EAAaC,GAC3B,OAAOD,EAAM,GAAKC,CACpB,CACA,SAASC,EAAOF,EAAaC,GAC3B,OAAOE,KAAKC,MAAMJ,EAAM,GAAKC,EAC/B,CAEc,MAAOI,UAAY/D,EAI/B5E,WAAAA,CAAY4I,GACVC,MAAMD,GACNrI,KAAKuI,aAAe,EACpBvI,KAAKwI,MAAQ,EACbxI,KAAKyI,SAAW,CAClB,CACA,eAAMC,CAAUvC,EAAiBxB,EAAgB,CAAC,GAChD,MAAMgE,QAAkB3I,KAAK+E,MAAMJ,GAC7BiE,EAAQD,EAAU7C,YAAYK,GACpC,QAAchC,IAAVyE,EACF,OAAQ,EAGV,IADYD,EAAU/D,QAAQgE,GAE5B,OAAQ,EAEV,MAAM,MAAEC,GAAUF,EAAU/D,QAAQgE,GACpC,OAAIC,EACKA,EAAMH,WAEP,CACV,CAEAI,QAAAA,GACE,MAAM,IAAI5I,MAAM,sCAClB,CAEA6I,YAAAA,CAAapB,EAAmBC,GAC9B,MAAMoB,EAAW,IAAIC,SAAStB,EAAMuB,QAC9BC,EAAcH,EAASI,SAASxB,GAAQ,GACxCyB,EACU,MAAdF,EAAwB,uBAAyB,iBAC7CG,EAASzB,EAAuB,GAAdsB,GACxB,IAAKG,EACH,MAAM,IAAIpJ,MAAM,qCAAqCiJ,KAEvD,MAAMI,EAAgB,CACpBC,IAAKR,EAASI,SAASxB,EAAS,GAAG,GACnC6B,MAAOT,EAASI,SAASxB,EAAS,GAAG,GACrC8B,IAAKV,EAASI,SAASxB,EAAS,IAAI,IAEhC+B,EAAYX,EAASI,SAASxB,EAAS,IAAI,GAC3CgC,EAAWD,EAAYE,OAAOC,aAAaH,QAAaxF,EACxD4F,EAAYf,EAASI,SAASxB,EAAS,IAAI,GAC3CoC,EAAoBhB,EAASI,SAASxB,EAAS,IAAI,IAEnD,YAAE/B,EAAW,YAAEC,GAAgB9F,KAAKyF,gBACxCkC,EAAMtB,SAASuB,EAAS,GAAIA,EAAS,GAAKoC,IAG5C,MAAO,CACLnE,cACAC,cACAiE,YACAH,WACAL,gBACAD,SACAD,iBAEJ,CAEA,YAAMjE,CAAOT,EAAgB,CAAC,GAC5B,MAAMgD,QAAcsC,EAAAA,EAAAA,UAAYjK,KAAKsE,WAAW4F,SAASvF,IACnDqE,EAAW,IAAIC,SAAStB,EAAMuB,QAGpC,IAAIiB,EACJ,GAvFe,WAuFXnB,EAASoB,UAAU,GAAG,GACxBD,EAAa,MACR,IAxFQ,WAwFJnB,EAASoB,UAAU,GAAG,GAG/B,MAAM,IAAIlK,MAAM,kBAFhBiK,EAAa,CAGf,CAEAnK,KAAKyI,SAAWO,EAASI,SAAS,GAAG,GACrCpJ,KAAKwI,MAAQQ,EAASI,SAAS,GAAG,GAClCpJ,KAAKuI,eAAiB,GAAyB,GAAlBvI,KAAKwI,MAAQ,IAAW,GAAK,EAC1D,MAAM6B,EAAe,IAAMrK,KAAKyI,SAAwB,EAAbzI,KAAKwI,OAC1C8B,EAAYtB,EAASI,SAAS,IAAI,GAClCmB,EACJD,GAAaA,GAAa,GACtBtK,KAAK+I,aAAapB,EAAO,IACzB,CACE9B,YAAa,GACbC,YAAa,CAAC,EACd8D,cAAUzF,EACVoF,cAAe,CAAEC,IAAK,EAAGC,MAAO,EAAGC,IAAK,GACxCL,eAAgB,uBAChBC,OAAQ,WAEVkB,EAAWxB,EAASI,SAAS,GAAKkB,GAAW,GAGnD,IAAIG,EACAC,EAAa,GAAKJ,EAAY,EAClC,MAAM1F,EAAU,IAAI+F,MAAMH,GAAUvJ,KAAK,GAAG2J,IAAI,KAC9C,MAAMC,EAAW7B,EAASI,SAASsB,GAAY,GAC/CA,GAAc,EACd,MAAMlF,EAAoC,CAAC,EAC3C,IAAIqD,EACJ,IAAK,IAAIiC,EAAI,EAAGA,EAAID,EAAUC,GAAK,EAAG,CACpC,MAAMlH,EAAMoF,EAASoB,UAAUM,GAAY,GAC3C,GAAI9G,EAAM5D,KAAKuI,aAGbM,EAAQ7I,KAAK+K,eAAepD,EAAO+C,EAAa,GAChDA,GAAc,OACT,CACL,MAAMM,EAAUtD,EAAUC,EAAO+C,EAAa,GAC9CD,EAAgBzK,KAAKgF,eAAeyF,EAAeO,GACnD,MAAMC,EAAajC,EAASI,SAASsB,EAAa,IAAI,GACtDA,GAAc,GACd,MAAM5D,EAAS,IAAI6D,MAAMM,GACzB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACtC,MAAMC,EAAIzD,EAAUC,EAAO+C,GACrBU,EAAI1D,EAAUC,EAAO+C,EAAa,GACxCA,GAAc,GACd5D,EAAOoE,GAAK,IAAIzH,EAAM0H,EAAGC,EAAGxH,EAC9B,CACA4B,EAAS5B,GAAOkD,CAClB,CACF,CAEA,MAAO,CAAEtB,WAAUqD,WAGrB,MAAO,IACF0B,EACHc,KAAK,EACLb,WACAc,aAAc,MACdb,gBACAN,aACAvF,UACA4D,MAAOxI,KAAKwI,MACZD,aAAcvI,KAAKuI,aACnB8B,eAEJ,CAEAU,cAAAA,CAAepD,EAAmBC,GAChC,MAAO,CACLc,UAAWpC,EAAwBqB,EAAOC,EAAS,IAEvD,CAEA,oBAAM2D,CACJpF,EACAqF,EACAC,EACA9G,EAAgB,CAAC,GAEb6G,EAAM,IACRA,EAAM,GAGR,MAAM7C,QAAkB3I,KAAK+E,MAAMJ,GAC7BiE,EAAQD,EAAU7C,YAAYK,GACpC,QAAchC,IAAVyE,EACF,MAAO,GAET,MAAM8C,EAAK/C,EAAU/D,QAAQgE,GAC7B,IAAK8C,EACH,MAAO,GAIT,MAAMC,EAAkB3L,KAAK4L,SAASJ,EAAKC,GACrC3E,EAAkB,GAGxB,IAAK,MAAO2C,EAAOC,KAAQiC,EACzB,IAAK,IAAI/H,EAAM6F,EAAO7F,GAAO8F,EAAK9F,IAChC,GAAI8H,EAAGlG,SAAS5B,GACd,IAAK,MAAMiI,KAAKH,EAAGlG,SAAS5B,GAC1BkD,EAAOU,KAAK,IAAI/D,EAAMoI,EAAEnI,KAAMmI,EAAElI,KAAMC,IAM9C,OAAOiD,EAAeC,EAAQ,IAAIW,EAAc,EAAG,GACrD,CAKAmE,QAAAA,CAASE,EAAapC,IACpBoC,GAAO,GACG,IACRA,EAAM,GAEJpC,EAAM,GAAK,KACbA,EAAM,GAAK,IAEbA,GAAO,EACP,IAAIqC,EAAI,EACJC,EAAI,EACJC,EAAIjM,KAAKyI,SAAwB,EAAbzI,KAAKwI,MAC7B,MAAM0D,EAAO,GACb,KAAOH,GAAK/L,KAAKwI,MAAOyD,GAAK,EAAGD,GAAKlE,EAAO,EAAO,EAAJiE,GAAQA,GAAK,EAAG,CAC7D,MAAM7H,EAAI8H,EAAI/D,EAAO6D,EAAKG,GACpBE,EAAIH,EAAI/D,EAAOyB,EAAKuC,GAC1B,GAAIE,EAAIjI,EAAIgI,EAAKhG,OAASlG,KAAKuI,aAC7B,MAAM,IAAIrI,MACR,SAAS4L,KAAOpC,oDAAsD1J,KAAKyI,mBAAmBzI,KAAKwI,iEAGvG0D,EAAK1E,KAAK,CAACtD,EAAGiI,GAChB,CACA,OAAOD,CACT,ECpNY,MAAOE,UAAmB/H,EACtC,eAAMqE,CAAUvC,EAAiBxB,EAAgB,CAAC,GAChD,MAAMgE,QAAkB3I,KAAK+E,MAAMJ,GAC7BiE,EAAQD,EAAU7C,YAAYK,GACpC,YAAchC,IAAVyE,GACM,EAEED,EAAU/D,QAAQgE,GAIvBD,EAAU/D,QAAQgE,GAAOC,OAAOH,YAAc,GAF3C,CAGZ,CAGA,YAAMtD,CAAOT,EAAgB,CAAC,GAC5B,MAAM0H,QAAYrM,KAAKsE,WAAW4F,SAASvF,GACrCgD,QAAcsC,EAAAA,EAAAA,IAAMoC,GACpBrD,EAAW,IAAIC,SAAStB,EAAMuB,QAGpC,GAzCc,WAwCAF,EAASoB,UAAU,GAAG,GAElC,MAAM,IAAIlK,MAAM,kBAIlB,MAAMsK,EAAWxB,EAASoB,UAAU,GAAG,GACjCjB,EAAcH,EAASoB,UAAU,GAAG,GACpCf,EACU,MAAdF,EAAwB,uBAAyB,iBAM7CG,EALqC,CACzC,EAAG,UACH,EAAG,MACH,EAAG,OAEmC,GAAdH,GAC1B,IAAKG,EACH,MAAM,IAAIpJ,MAAM,qCAAqCiJ,KAEvD,MAAMI,EAAgB,CACpBC,IAAKR,EAASI,SAAS,IAAI,GAC3BK,MAAOT,EAASI,SAAS,IAAI,GAC7BM,IAAKV,EAASI,SAAS,IAAI,IAEvBO,EAAYX,EAASI,SAAS,IAAI,GAIlCQ,EAAWD,EAAYE,OAAOC,aAAaH,QAAaxF,EACxD4F,EAAYf,EAASI,SAAS,IAAI,GAGlCY,EAAoBhB,EAASI,SAAS,IAAI,IAC1C,YAAEtD,EAAW,YAAED,GAAgB7F,KAAKyF,gBACxCkC,EAAM2E,MAAM,GAAI,GAAKtC,IAIvB,IACIS,EADAC,EAAa,GAAKV,EAqDtB,MAAO,CACLpF,QApDc,IAAI+F,MAAMH,GAAUvJ,KAAK,GAAG2J,IAAI,KAE9C,MAAMC,EAAW7B,EAASI,SAASsB,GAAY,GAC/CA,GAAc,EACd,MAAMlF,EAAoC,CAAC,EAC3C,IAAIqD,EACJ,IAAK,IAAIiC,EAAI,EAAGA,EAAID,EAAUC,GAAK,EAAG,CACpC,MAAMlH,EAAMoF,EAASoB,UAAUM,GAAY,GAE3C,GADAA,GAAc,EACV9G,EAAM2E,MACR,MAAM,IAAIrI,MACR,8DAEG,GAAYqI,QAAR3E,EAA0B,CACnC,MAAMqH,EAAajC,EAASI,SAASsB,GAAY,GACjDA,GAAc,EACK,IAAfO,IACFpC,EAAQ7I,KAAK+K,eAAepD,EAAO+C,IAErCA,GAAc,GAAKO,CACrB,KAAO,CACL,MAAMA,EAAajC,EAASI,SAASsB,GAAY,GACjDA,GAAc,EACd,MAAM5D,EAAS,IAAI6D,MAAMM,GACzB,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACtC,MAAMC,EAAIzD,EAAUC,EAAO+C,GACrBU,EAAI1D,EAAUC,EAAO+C,EAAa,GACxCA,GAAc,GACdD,EAAgBzK,KAAKgF,eAAeyF,EAAeU,GACnDrE,EAAOoE,GAAK,IAAIzH,EAAM0H,EAAGC,EAAGxH,EAC9B,CACA4B,EAAS5B,GAAOkD,CAClB,CACF,CAGA,MAAMyF,EAAcvD,EAASI,SAASsB,GAAY,GAClDA,GAAc,EACd,MAAM8B,EAAc,IAAI7B,MAAM4B,GAC9B,IAAK,IAAIrB,EAAI,EAAGA,EAAIqB,EAAarB,GAAK,EACpCsB,EAAYtB,GAAKxD,EAAUC,EAAO+C,GAClCA,GAAc,EACdD,EAAgBzK,KAAKgF,eAAeyF,EAAe+B,EAAYtB,IAEjE,MAAO,CACL1F,WACAgH,cACA3D,WAMFe,WACArB,aApEmB,MAqEnB8B,aApEmB,UAqEnBN,YACAU,gBACAlB,gBACAF,iBACAC,SACAzD,cACAC,cACAwF,aAAc,MAElB,CAEAP,cAAAA,CAAepD,EAAmBC,GAChC,MAAO,CACLc,UAAWpC,EAAwBqB,EAAOC,EAAS,IAEvD,CAEA,oBAAM2D,CACJpF,EACAqF,EACAC,EACA9G,EAAgB,CAAC,GAEb6G,EAAM,IACRA,EAAM,GAGR,MAAM7C,QAAkB3I,KAAK+E,MAAMJ,GAC7BiE,EAAQD,EAAU7C,YAAYK,GACpC,QAAchC,IAAVyE,EACF,MAAO,GAET,MAAM8C,EAAK/C,EAAU/D,QAAQgE,GAC7B,IAAK8C,EACH,MAAO,IAIPA,EAAGc,YAAYtG,OAAS,EACpBwF,EAAGc,YACDhB,GA/KW,IA+KcE,EAAGc,YAAYtG,OACpCwF,EAAGc,YAAYtG,OAAS,EACxBsF,GAjLO,IAmLb,IAAI/D,EAAc,EAAG,KAEzBjF,QAAQiK,KAAK,4CAKf,MAAMd,GApLQG,EAoLmBN,EApLN9B,EAoLW+B,EAjLjC,CACL,CAAC,EAAG,GACJ,CAAC,IAJHK,GAAO,IAIQ,IAAK,IAHpBpC,GAAO,IAGyB,KAC9B,CAAC,GAAKoC,GAAO,IAAK,GAAKpC,GAAO,KAC9B,CAAC,IAAMoC,GAAO,IAAK,IAAMpC,GAAO,KAChC,CAAC,KAAOoC,GAAO,IAAK,KAAOpC,GAAO,KAClC,CAAC,MAAQoC,GAAO,IAAK,MAAQpC,GAAO,OATxC,IAAkBoC,EAAapC,EAqL3B,MAAM5C,EAAkB,GAGxB,IAAK,MAAO2C,EAAOC,KAAQiC,EACzB,IAAK,IAAI/H,EAAM6F,EAAO7F,GAAO8F,EAAK9F,IAChC,GAAI8H,EAAGlG,SAAS5B,GACd,IAAK,MAAMiI,KAAKH,EAAGlG,SAAS5B,GAC1BkD,EAAOU,KAAK,IAAI/D,EAAMoI,EAAEnI,KAAMmI,EAAElI,KAAMC,IAQ9C,MAAM8I,EAAQhB,EAAGc,YAAYtG,OAC7B,IAAIa,EACJ,MAAM4F,EAASzE,KAAKsD,IAAIA,GAAO,GAAIkB,EAAQ,GACrCE,EAAS1E,KAAKsD,IAAIC,GAAO,GAAIiB,EAAQ,GAC3C,IAAK,IAAIzG,EAAI0G,EAAQ1G,GAAK2G,IAAU3G,EAAG,CACrC,MAAM4G,EAAKnB,EAAGc,YAAYvG,GACtB4G,KAAQ9F,GAAU8F,EAAG5I,UAAU8C,GAAU,KAC3CA,EAAS8F,EAEb,CAEA,OAAOhG,EAAeC,EAAQC,EAChC,EChMY,MAAO+F,EAuCnBrN,WAAAA,EAAY,KACVsN,EAAI,WACJzI,EAAU,IACV0I,EAAG,QACHC,EAAO,OACPC,EAAM,cACNC,EAAa,QACbC,EAAO,OACPC,EAAM,cACNC,EACA/I,cAAegJ,EAAgB,eAC/BC,EAAiB,UA5CZ,KAAAtM,MAAQ,IAAIuM,EAAAA,EAGjB,CACAC,QAAS,MAsDT,MAAMnJ,EAAgBgJ,GAAoB,CAACI,GAAOA,GAClD,GAAIrJ,EACFtE,KAAKsE,WAAaA,OACb,GAAIyI,EACT/M,KAAKsE,WAAa,IAAIsJ,EAAAA,GAAUb,OAC3B,KAAIC,EAGT,MAAM,IAAI7L,UAAU,0CAFpBnB,KAAKsE,WAAa,IAAIuJ,EAAAA,EAAWb,EAGnC,CAEA,GAAIG,EACFnN,KAAK8N,MAAQ,IAAIC,EAAI,CACnBzJ,WAAY6I,EACZ5I,uBAEG,GAAI+I,EACTtN,KAAK8N,MAAQ,IAAI1F,EAAI,CACnB9D,WAAYgJ,EACZ/I,uBAEG,GAAI0I,EACTjN,KAAK8N,MAAQ,IAAIC,EAAI,CACnBzJ,WAAY,IAAIsJ,EAAAA,GAAUX,GAC1B1I,uBAEG,GAAI6I,EACTpN,KAAK8N,MAAQ,IAAI1F,EAAI,CACnB9D,WAAY,IAAIsJ,EAAAA,GAAUR,GAC1B7I,uBAEG,GAAIwI,EACT/M,KAAK8N,MAAQ,IAAIC,EAAI,CACnBzJ,WAAY,IAAIsJ,EAAAA,GAAU,GAAGb,SAC7BxI,uBAEG,GAAI8I,EACTrN,KAAK8N,MAAQ,IAAI1F,EAAI,CACnB9D,WAAY,IAAIuJ,EAAAA,EAAWR,UAExB,GAAIH,EACTlN,KAAK8N,MAAQ,IAAIC,EAAI,CACnBzJ,WAAY,IAAIuJ,EAAAA,EAAWX,SAExB,KAAIF,EAKT,MAAM,IAAI7L,UACR,sFALFnB,KAAK8N,MAAQ,IAAIC,EAAI,CACnBzJ,WAAY,IAAIuJ,EAAAA,EAAW,GAAGb,UAMlC,CAEAhN,KAAKyE,aAAeF,EACpBvE,KAAKgO,2BAA6C7J,IAArBoJ,EAC7BvN,KAAKiO,WAAa,IAAIjN,EAAAA,EAAwC,CAC5DE,MAAO,IAAIuM,EAAAA,EAAI,CAAEC,QAASxF,KAAKC,MAAMqF,EAAiB,SACtDvM,KAAMA,CAACoH,EAAatI,IAClBC,KAAKkO,UAAU7F,EAAM,CAAEtI,YAE7B,CAeQoO,mBAAAA,CACNC,EACAC,EACAC,EACAC,EACAC,GAEA,OACqB,IAAnBJ,EAAWE,IACVC,EAAaF,EAAWC,IACzBE,EACA,CAEJ,CAEA,cAAMC,CACJtI,EACA8F,EACAE,EACAxH,GAEA,IAAI5E,EAEAa,EADA8N,EAAmB,CAAC,EAGJ,mBAAT/J,EACT/D,EAAW+D,GAEX+J,EAAU/J,EACV/D,EAAW+D,EAAKgK,aAChB5O,EAAS4E,EAAK5E,QAGhB,MAAM6O,QAAiB5O,KAAK8N,MAAMpJ,YAAYgK,GACxCjF,EAAQwC,GAAK,EACbvC,EAAMyC,GAAKyC,EAASvE,aAC1B,KAAMZ,GAASC,GACb,MAAM,IAAIvI,UACR,8EAGJ,GAAIsI,IAAUC,EACZ,OAGF,MAAM5C,QAAe9G,KAAK8N,MAAMvC,eAAepF,EAASsD,EAAOC,EAAKgF,GAC9D3I,EAAU,IAAIC,YAAY,QAE1B6I,EAA4B,QAApBD,EAAStF,OACjBwF,EAAyB,CAC7BtF,IAAKoF,EAASrF,cAAcC,KAAO,EACnCC,MAAOmF,EAASrF,cAAcE,OAAS,EACvCC,IAAKmF,EAAQ,EAAID,EAASrF,cAAcG,KAAO,GAE3CqF,EAAY7G,KAAKuD,IACrBqD,EAAuBtF,IACvBsF,EAAuBrF,MACvBqF,EAAuBpF,KAEnBsF,EAAeJ,EAAShF,UAAUqF,WAAW,GAC7CC,EACwB,mBAA5BN,EAASvF,gBAAuC,EAAI,EAChD8F,GAAoBnP,KAAKgO,sBAG/B,IAAK,MAAMnC,KAAK/E,EAAQ,CACtB,MAAM,OAAEoC,EAAM,WAAEkF,EAAU,WAAEC,SAAqBrO,KAAKiO,WAAW7M,IAC/DyK,EAAE7H,WACF6H,EACA9L,GAGF,IAAIwO,EAAa,EACbD,EAAM,EAUV,MAAMc,EAAMrJ,EAAQK,OAAO8C,GAE3B,GADmBA,EAAOhD,QAAUkJ,EAAIlJ,OAEtC,KAAOqI,EAAaa,EAAIlJ,QAAQ,CAC9B,MAAM1B,EAAI4K,EAAIC,QAAQ,KAAMd,GAC5B,IAAW,IAAP/J,EACF,MAEF,MAAM8K,EAAOF,EAAI9C,MAAMiC,EAAY/J,GAGnC,GAAI6J,EAAY,CACd,MAAMkB,EAAShB,EAAa1C,EAAEnI,KAAK4D,aACnC,KAAOgH,EAAMD,EAAWnI,QAAUqJ,GAAUlB,EAAWC,IACrDA,GAEJ,CAGA,MAAMzL,EAAS7C,KAAKwP,UAClBrJ,EACAsD,EACAC,EACA4F,EACAR,EAAuBtF,IACvBsF,EAAuBrF,MACvBqF,EAAuBpF,IACvBqF,EACAC,EACAE,EACAL,EACAM,GAGF,GAAe,OAAXtM,EACF,YACoBsB,IAAXtB,GACTjC,EACE0O,EACAtP,KAAKmO,oBACHC,EACAC,EACAC,EACAC,EACA1C,EAAEnI,KAAK4D,cAETzE,EAAO4G,MACP5G,EAAO6G,KAGX6E,EAAa/J,EAAI,CACnB,MAEA,KAAO+J,EAAarF,EAAOhD,QAAQ,CACjC,MAAM1B,EAAI0E,EAAOmG,QAAQ,KAAKJ,WAAW,GAAIV,GAC7C,IAAW,IAAP/J,EACF,MAEF,MAAMN,EAAIgF,EAAOoD,MAAMiC,EAAY/J,GAC7B8K,EAAOvJ,EAAQK,OAAOlC,GAG5B,GAAImK,EAAY,CACd,MAAMkB,EAAShB,EAAa1C,EAAEnI,KAAK4D,aACnC,KAAOgH,EAAMD,EAAWnI,QAAUqJ,GAAUlB,EAAWC,IACrDA,GAEJ,CAGA,MAAMzL,EAAS7C,KAAKwP,UAClBrJ,EACAsD,EACAC,EACA4F,EACAR,EAAuBtF,IACvBsF,EAAuBrF,MACvBqF,EAAuBpF,IACvBqF,EACAC,EACAE,EACAL,EACAM,GAGF,GAAe,OAAXtM,EACF,YACoBsB,IAAXtB,GACTjC,EACE0O,EACAtP,KAAKmO,oBACHC,EACAC,EACAC,EACAC,EACA1C,EAAEnI,KAAK4D,cAETzE,EAAO4G,MACP5G,EAAO6G,KAGX6E,EAAa/J,EAAI,CACnB,CAEJ,CACF,CAEA,iBAAME,CAAYC,EAAgB,CAAC,GACjC,OAAO3E,KAAK8N,MAAMpJ,YAAYC,EAChC,CAMA,qBAAM8K,CAAgB9K,EAAgB,CAAC,GACrC,MAAM,cAAE8F,EAAa,SAAEb,EAAQ,aAAE0B,SACzBtL,KAAK0E,YAAYC,GAEnB+K,GAAYjF,GAAerG,eAAiB,GAAKkH,EAIjDe,QAAYrM,KAAKsE,WAAWqL,KAAKD,EAAU,EAAG/K,GAC9CgD,QAAcsC,EAAAA,EAAAA,IAAMoC,GAG1B,GAAIzC,EAAU,CAEZ,IAAIgG,GAAe,EACnB,MAAMC,EAAc,KAAKZ,WAAW,GAC9Ba,EAAWlG,EAASqF,WAAW,GAErC,IAAK,IAAIhJ,EAAI,EAAG8F,EAAIpE,EAAMzB,OAAQD,EAAI8F,EAAG9F,IAAK,CAC5C,MAAM8J,EAAOpI,EAAM1B,GACnB,GAAIA,IAAM2J,EAAc,GAAKG,IAASD,EACpC,MAEEC,IAASF,IACXD,EAAc3J,EAElB,CACA,OAAO0B,EAAMtB,SAAS,EAAGuJ,EAAc,EACzC,CACA,OAAOjI,CACT,CAMA,eAAMqI,CAAUrL,EAAgB,CAAC,GAC/B,MAAMoB,EAAU,IAAIC,YAAY,QAC1B2B,QAAc3H,KAAKyP,gBAAgB9K,GACzC,OAAOoB,EAAQK,OAAOuB,EACxB,CAMA,+BAAMsI,CAA0BtL,EAAgB,CAAC,GAE/C,aADuB3E,KAAK0E,YAAYC,IACxBkB,WAClB,CA6BA2J,SAAAA,CACEU,EACAC,EACAC,EACAd,EACAe,EACAC,EACAC,EACAxB,EACAC,EACAE,EACAL,EACAM,GAEA,QAAqBhL,IAAjB6K,GAA8BM,EAAKL,WAAW,KAAOD,EACvD,OAKF,GAAIM,EAAKpJ,OAAS,IAAK,CACrB,MAAMsK,EAASlB,EAAKmB,MAAM,MACpBjH,EAAMgH,EAAOH,EAAY,GAI/B,KAHiBlB,EACb3F,IAAQ0G,EACRlQ,KAAKyE,aAAa+E,KAAS0G,GAE7B,OAGF,MAAMQ,GAAmBF,EAAOF,EAAc,GAAMpB,EACpD,GAAIwB,GAAmBN,EACrB,OAAO,KAGT,IAAIO,EAaJ,GAXEA,EADgB,IAAdJ,GAAmBA,IAAcD,EACnBI,EAAkB,EACzB7B,EACO7O,KAAK4Q,WACnBF,EACAF,EAAO,GACPA,EAAOD,EAAY,KAGJC,EAAOD,EAAY,GAGlCI,GAAiBR,EACnB,OAEF,MAAO,CAAE1G,MAAOiH,EAAiBhH,IAAKiH,EACxC,CAGA,IAAIE,GAAQ,EACZ,MAAMC,EAAO,EAAE,GACf,IAAK,IAAI7K,EAAI,EAAGA,EAAI8I,EAAW9I,IAAK,CAClC,MAAMqI,EAAMgB,EAAKD,QAAQ,KAAMwB,EAAO,GACtC,IAAa,IAATvC,EAAY,CACdwC,EAAKtJ,KAAK8H,EAAKpJ,QACf,KACF,CACA4K,EAAKtJ,KAAK8G,GACVuC,EAAOvC,CACT,CAEA,MAAM9E,EAAM8F,EAAKhD,MAAMwE,EAAKT,EAAY,GAAM,EAAGS,EAAKT,IAItD,KAHiBlB,EACb3F,IAAQ0G,EACRlQ,KAAKyE,aAAa+E,KAAS0G,GAE7B,OAGF,MAAMQ,GACHpB,EAAKhD,MAAMwE,EAAKR,EAAc,GAAM,EAAGQ,EAAKR,IAC7CpB,EACF,GAAIwB,GAAmBN,EACrB,OAAO,KAGT,IAAIO,EAaJ,OAXEA,EADgB,IAAdJ,GAAmBA,IAAcD,EACnBI,EAAkB,EACzB7B,EACO7O,KAAK4Q,WACnBF,EACApB,EAAKhD,MAAMwE,EAAK,GAAM,EAAGA,EAAK,IAC9BxB,EAAKhD,MAAMwE,EAAKP,EAAY,GAAM,EAAGO,EAAKP,MAG3BjB,EAAKhD,MAAMwE,EAAKP,EAAY,GAAM,EAAGO,EAAKP,IAGzDI,GAAiBR,OAArB,EAIO,CAAE1G,MAAOiH,EAAiBhH,IAAKiH,EACxC,CAEAC,UAAAA,CAAWF,EAAyBK,EAAgBC,GAClD,IAAIL,EAAgBD,EAAkBK,EAAO7K,OAE7C,GADc8K,EAAKC,SAAS,cAE1B,OAAOP,EAAkB,EAG3B,GAAgB,MAAZM,EAAK,GAAY,CACnB,MAAME,EAASF,EAAK3B,QAAQ,QAC5B,IAAgB,IAAZ6B,IAA6B,IAAXA,GAAqC,MAArBF,EAAKE,EAAS,IAAa,CAC/D,MAAMzH,EAAQyH,EAAS,EACvB,IAAIxH,EAAMsH,EAAK3B,QAAQ,IAAK5F,IACf,IAATC,IACFA,EAAMsH,EAAK9K,QAEbyK,EAAgBQ,OAAOC,SAASJ,EAAK1E,MAAM7C,EAAOC,GAAM,GAC1D,CACF,CACA,OAAOiH,CACT,CAUA,eAAMjI,CAAUvC,EAAiBxB,EAAgB,CAAC,GAChD,OAAO3E,KAAK8N,MAAMpF,UAAUvC,EAASxB,EACvC,CAMA,eAAMuJ,CAAUrC,EAAUlH,EAAgB,CAAC,GACzC,MAAM0M,QAAYrR,KAAKsE,WAAWqL,KAChC9D,EAAEhI,cACFgI,EAAEnI,KAAKU,cACPO,GAEF,OAAO2M,EAAAA,EAAAA,IAAgBD,EAAKxF,EAAG7L,KAAKkB,MACtC,E","sources":["webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+abortable-promise-cache@3.0.4/node_modules/@gmod/abortable-promise-cache/src/AggregateAbortController.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+abortable-promise-cache@3.0.4/node_modules/@gmod/abortable-promise-cache/src/AggregateStatusReporter.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+abortable-promise-cache@3.0.4/node_modules/@gmod/abortable-promise-cache/src/AbortablePromiseCache.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/chunk.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/indexFile.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/long.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/util.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/virtualOffset.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/csi.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/tbi.ts","webpack://@jbrowse/web/../../node_modules/.pnpm/@gmod+tabix@3.2.2/node_modules/@gmod/tabix/src/tabixIndexedFile.ts"],"sourcesContent":["// eslint-disable-next-line @typescript-eslint/no-extraneous-class\nclass NullSignal {}\n\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nexport default class AggregateAbortController {\n  signals = new Set()\n  abortController = new AbortController()\n\n  /**\n   * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n   *  will be treated as a null-signal, and this abortcontroller will no\n   *  longer be abortable.\n   */\n  //@ts-ignore\n  addSignal(signal: AbortSignal = new NullSignal()): void {\n    if (this.signal.aborted) {\n      throw new Error('cannot add a signal, already aborted!')\n    }\n\n    // note that a NullSignal will never fire, so if we\n    // have one this thing will never actually abort\n    this.signals.add(signal)\n    if (signal.aborted) {\n      // handle the abort immediately if it is already aborted\n      // for some reason\n      this.handleAborted(signal)\n    } else if (typeof signal.addEventListener === 'function') {\n      signal.addEventListener('abort', () => {\n        this.handleAborted(signal)\n      })\n    }\n  }\n\n  handleAborted(signal: AbortSignal): void {\n    this.signals.delete(signal)\n    if (this.signals.size === 0) {\n      this.abortController.abort()\n    }\n  }\n\n  get signal(): AbortSignal {\n    return this.abortController.signal\n  }\n\n  abort(): void {\n    this.abortController.abort()\n  }\n}\n","export default class AggregateStatusReporter<V> {\n  callbacks = new Set<(arg: V) => void>()\n  currentMessage?: V\n\n  addCallback(callback: (arg: V) => void = () => {}): void {\n    this.callbacks.add(callback)\n    if (this.currentMessage) {\n      callback(this.currentMessage)\n    }\n  }\n\n  callback(message: V) {\n    this.currentMessage = message\n    for (const elt of this.callbacks) {\n      elt(message)\n    }\n  }\n}\n","import AggregateAbortController from './AggregateAbortController.ts'\nimport AggregateStatusReporter from './AggregateStatusReporter.ts'\n\ninterface Cache<U> {\n  delete: (key: string) => void\n  keys: () => Iterator<string>\n  get: (key: string) => U | undefined\n  set: (key: string, value: U) => void\n  has: (key: string) => boolean\n}\ntype FillCallback<T, U, V> = (\n  data: T,\n  signal?: AbortSignal,\n  statusCallback?: (arg: V) => void,\n) => Promise<U>\n\ninterface Entry<U, V> {\n  aborter: AggregateAbortController\n  settled: boolean\n  readonly aborted: boolean\n  statusReporter: AggregateStatusReporter<V>\n  promise: Promise<U>\n}\nexport default class AbortablePromiseCache<T, U, V = string> {\n  /**\n   * @param {object} args constructor args\n   * @param {Function} args.fill fill callback, will be called with sig `fill(data, signal)`\n   * @param {object} args.cache backing store to use, must implement `get(key)`, `set(key, val)`,\n   *   `delete(key)`, and `keys() -> iterator`\n   */\n\n  private cache: Cache<Entry<U, V>>\n  private fillCallback: FillCallback<T, U, V>\n\n  constructor({\n    fill,\n    cache,\n  }: {\n    fill: FillCallback<T, U, V>\n    cache: Cache<Entry<U, V>>\n  }) {\n    if (typeof fill !== 'function') {\n      throw new TypeError('must pass a fill function')\n    }\n    if (typeof cache !== 'object') {\n      throw new TypeError('must pass a cache object')\n    }\n    if (\n      typeof cache.get !== 'function' ||\n      typeof cache.set !== 'function' ||\n      typeof cache.delete !== 'function'\n    ) {\n      throw new TypeError(\n        'cache must implement get(key), set(key, val), and and delete(key)',\n      )\n    }\n\n    this.cache = cache\n    this.fillCallback = fill\n  }\n\n  static isAbortException(exception: Error) {\n    return (\n      // DOMException\n      exception.name === 'AbortError' ||\n      // standard-ish non-DOM abort exception\n      //@ts-ignore\n      exception.code === 'ERR_ABORTED' ||\n      // stringified DOMException\n      exception.message === 'AbortError: aborted' ||\n      // stringified standard-ish exception\n      exception.message === 'Error: aborted'\n    )\n  }\n\n  evict(key: string, entry: Entry<U, V>) {\n    if (this.cache.get(key) === entry) {\n      this.cache.delete(key)\n    }\n  }\n\n  fill(\n    key: string,\n    data: T,\n    signal?: AbortSignal,\n    statusCallback?: (arg: V) => void,\n  ) {\n    const aborter = new AggregateAbortController()\n    const statusReporter = new AggregateStatusReporter<V>()\n    statusReporter.addCallback(statusCallback)\n    const newEntry: Entry<U, V> = {\n      aborter: aborter,\n      promise: this.fillCallback(data, aborter.signal, (message: V) => {\n        statusReporter.callback(message)\n      }),\n      settled: false,\n      statusReporter,\n      get aborted() {\n        return this.aborter.signal.aborted\n      },\n    }\n    newEntry.aborter.addSignal(signal)\n\n    // remove the fill from the cache when its abortcontroller fires, if still in there\n    newEntry.aborter.signal.addEventListener('abort', () => {\n      if (!newEntry.settled) {\n        this.evict(key, newEntry)\n      }\n    })\n\n    // chain off the cached promise to record when it settles\n    newEntry.promise\n      .then(\n        () => {\n          newEntry.settled = true\n        },\n        () => {\n          newEntry.settled = true\n\n          // if the fill throws an error (including abort) and is still in the cache, remove it\n          this.evict(key, newEntry)\n        },\n      )\n      .catch((error: unknown) => {\n        // this will only be reached if there is some kind of\n        // bad bug in this library\n        console.error(error)\n        throw error\n      })\n\n    this.cache.set(key, newEntry)\n  }\n\n  static checkSinglePromise<U>(promise: Promise<U>, signal?: AbortSignal) {\n    // check just this signal for having been aborted, and abort the\n    // promise if it was, regardless of what happened with the cached\n    // response\n    function checkForSingleAbort() {\n      if (signal?.aborted) {\n        throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' })\n      }\n    }\n\n    return promise.then(\n      result => {\n        checkForSingleAbort()\n        return result\n      },\n      (error: unknown) => {\n        checkForSingleAbort()\n        throw error\n      },\n    )\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key)\n  }\n\n  /**\n   * Callback for getting status of the pending async\n   *\n   * @callback statusCallback\n   * @param {any} status, current status string or message object\n   */\n\n  /**\n   * @param {any} key cache key to use for this request\n   * @param {any} data data passed as the first argument to the fill callback\n   * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n   * @param {statusCallback} a callback to get the current status of a pending async operation\n   */\n  get(\n    key: string,\n    data: T,\n    signal?: AbortSignal,\n    statusCallback?: (arg: V) => void,\n  ): Promise<U> {\n    if (!signal && data instanceof AbortSignal) {\n      throw new TypeError(\n        'second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?',\n      )\n    }\n    const cacheEntry = this.cache.get(key)\n\n    if (cacheEntry) {\n      if (cacheEntry.aborted && !cacheEntry.settled) {\n        // if it's aborted but has not realized it yet, evict it and redispatch\n        this.evict(key, cacheEntry)\n        return this.get(key, data, signal, statusCallback)\n      }\n\n      if (cacheEntry.settled) {\n        // too late to abort, just return it\n        return cacheEntry.promise\n      }\n\n      // request is in-flight, add this signal to its list of signals,\n      // or if there is no signal, the aborter will become non-abortable\n      cacheEntry.aborter.addSignal(signal)\n      cacheEntry.statusReporter.addCallback(statusCallback)\n\n      return AbortablePromiseCache.checkSinglePromise(\n        cacheEntry.promise,\n        signal,\n      )\n    }\n\n    // if we got here, it is not in the cache. fill.\n    this.fill(key, data, signal, statusCallback)\n    return AbortablePromiseCache.checkSinglePromise(\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n      this.cache.get(key)!.promise,\n      signal,\n    )\n  }\n\n  /**\n   * delete the given entry from the cache. if it exists and its fill request has\n   * not yet settled, the fill will be signaled to abort.\n   *\n   * @param {any} key\n   */\n  delete(key: string) {\n    const cachedEntry = this.cache.get(key)\n    if (cachedEntry) {\n      if (!cachedEntry.settled) {\n        cachedEntry.aborter.abort()\n      }\n      this.cache.delete(key)\n    }\n  }\n\n  /**\n   * Clear all requests from the cache. Aborts any that have not settled.\n   * @returns {number} count of entries deleted\n   */\n  clear() {\n    // iterate without needing regenerator-runtime\n    const keyIter = this.cache.keys()\n    let deleteCount = 0\n    for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n      this.delete(result.value)\n      deleteCount += 1\n    }\n    return deleteCount\n  }\n}\n","import VirtualOffset from './virtualOffset.ts'\n\n// little class representing a chunk in the index\nexport default class Chunk {\n  public minv: VirtualOffset\n  public maxv: VirtualOffset\n  public bin: number\n  public _fetchedSize?: number\n\n  constructor(\n    minv: VirtualOffset,\n    maxv: VirtualOffset,\n    bin: number,\n    fetchedSize?: number,\n  ) {\n    this.minv = minv\n    this.maxv = maxv\n    this.bin = bin\n    this._fetchedSize = fetchedSize\n  }\n\n  toUniqueString() {\n    return `${this.minv}..${this.maxv} (bin ${\n      this.bin\n    }, fetchedSize ${this.fetchedSize()})`\n  }\n\n  toString() {\n    return this.toUniqueString()\n  }\n\n  compareTo(b: Chunk) {\n    return (\n      this.minv.compareTo(b.minv) ||\n      this.maxv.compareTo(b.maxv) ||\n      this.bin - b.bin\n    )\n  }\n\n  fetchedSize() {\n    if (this._fetchedSize !== undefined) {\n      return this._fetchedSize\n    }\n    return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition\n  }\n}\n","import Chunk from './chunk.ts'\nimport VirtualOffset from './virtualOffset.ts'\n\nimport type { GenericFilehandle } from 'generic-filehandle2'\n\nexport interface Options {\n  signal?: AbortSignal\n}\n\nexport interface IndexData {\n  refNameToId: Record<string, number>\n  refIdToName: string[]\n  metaChar: string | undefined\n  columnNumbers: { ref: number; start: number; end: number }\n  coordinateType: string\n  format: string\n  [key: string]: any\n}\n\nexport default abstract class IndexFile {\n  public filehandle: GenericFilehandle\n  public renameRefSeq: (arg0: string) => string\n  private parseP?: Promise<IndexData>\n\n  constructor({\n    filehandle,\n    renameRefSeqs = (n: string) => n,\n  }: {\n    filehandle: GenericFilehandle\n    renameRefSeqs?: (a: string) => string\n  }) {\n    this.filehandle = filehandle\n    this.renameRefSeq = renameRefSeqs\n  }\n\n  public abstract lineCount(refName: string, args: Options): Promise<number>\n\n  protected abstract _parse(opts: Options): Promise<IndexData>\n\n  public async getMetadata(opts: Options = {}) {\n    const { indices: _indices, ...rest } = await this.parse(opts)\n    return rest\n  }\n\n  public abstract blocksForRange(\n    refName: string,\n    start: number,\n    end: number,\n    opts: Options,\n  ): Promise<Chunk[]>\n\n  _findFirstData(\n    currentFdl: VirtualOffset | undefined,\n    virtualOffset: VirtualOffset,\n  ) {\n    if (currentFdl) {\n      return currentFdl.compareTo(virtualOffset) > 0\n        ? virtualOffset\n        : currentFdl\n    } else {\n      return virtualOffset\n    }\n  }\n\n  async parse(opts: Options = {}) {\n    if (!this.parseP) {\n      this.parseP = this._parse(opts).catch((error: unknown) => {\n        this.parseP = undefined\n        throw error\n      })\n    }\n    return this.parseP\n  }\n\n  async hasRefSeq(seqId: number, opts: Options = {}) {\n    const idx = await this.parse(opts)\n    return !!idx.indices[seqId]?.binIndex\n  }\n\n  _parseNameBytes(namesBytes: Uint8Array) {\n    let currRefId = 0\n    let currNameStart = 0\n    const refIdToName: string[] = []\n    const refNameToId: Record<string, number> = {}\n    const decoder = new TextDecoder('utf8')\n    for (let i = 0; i < namesBytes.length; i += 1) {\n      if (!namesBytes[i]) {\n        if (currNameStart < i) {\n          const refName = this.renameRefSeq(\n            decoder.decode(namesBytes.subarray(currNameStart, i)),\n          )\n          refIdToName[currRefId] = refName\n          refNameToId[refName] = currRefId\n        }\n        currNameStart = i + 1\n        currRefId += 1\n      }\n    }\n    return {\n      refNameToId,\n      refIdToName,\n    }\n  }\n}\n","export const TWO_PWR_16_DBL = 1 << 16\nexport const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL\n\nexport function longFromBytesToUnsigned(source: Uint8Array, i = 0) {\n  const low =\n    source[i]! |\n    (source[i + 1]! << 8) |\n    (source[i + 2]! << 16) |\n    (source[i + 3]! << 24)\n  const high =\n    source[i + 4]! |\n    (source[i + 5]! << 8) |\n    (source[i + 6]! << 16) |\n    (source[i + 7]! << 24)\n  return (high >>> 0) * TWO_PWR_32_DBL + (low >>> 0)\n}\n","import Chunk from './chunk.ts'\nimport VirtualOffset from './virtualOffset.ts'\n\nexport function canMergeBlocks(chunk1: Chunk, chunk2: Chunk) {\n  return (\n    chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n    chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000\n  )\n}\n\nexport function optimizeChunks(chunks: Chunk[], lowest?: VirtualOffset) {\n  const mergedChunks: Chunk[] = []\n  let lastChunk: Chunk | undefined\n\n  if (chunks.length === 0) {\n    return chunks\n  }\n\n  chunks.sort(function (c0, c1) {\n    const dif = c0.minv.blockPosition - c1.minv.blockPosition\n    return dif === 0 ? c0.minv.dataPosition - c1.minv.dataPosition : dif\n  })\n\n  for (const chunk of chunks) {\n    if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n      if (lastChunk === undefined) {\n        mergedChunks.push(chunk)\n        lastChunk = chunk\n      } else {\n        if (canMergeBlocks(lastChunk, chunk)) {\n          if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n            lastChunk.maxv = chunk.maxv\n          }\n        } else {\n          mergedChunks.push(chunk)\n          lastChunk = chunk\n        }\n      }\n    }\n  }\n\n  return mergedChunks\n}\n","export default class VirtualOffset {\n  public blockPosition: number\n  public dataPosition: number\n  constructor(blockPosition: number, dataPosition: number) {\n    this.blockPosition = blockPosition // < offset of the compressed data block\n    this.dataPosition = dataPosition // < offset into the uncompressed data\n  }\n\n  toString() {\n    return `${this.blockPosition}:${this.dataPosition}`\n  }\n\n  compareTo(b: VirtualOffset) {\n    return (\n      this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition\n    )\n  }\n}\nexport function fromBytes(bytes: Uint8Array, offset = 0) {\n  return new VirtualOffset(\n    bytes[offset + 7]! * 0x10000000000 +\n      bytes[offset + 6]! * 0x100000000 +\n      bytes[offset + 5]! * 0x1000000 +\n      bytes[offset + 4]! * 0x10000 +\n      bytes[offset + 3]! * 0x100 +\n      bytes[offset + 2]!,\n    (bytes[offset + 1]! << 8) | bytes[offset]!,\n  )\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\n\nimport Chunk from './chunk.ts'\nimport IndexFile, { Options } from './indexFile.ts'\nimport { longFromBytesToUnsigned } from './long.ts'\nimport { optimizeChunks } from './util.ts'\nimport VirtualOffset, { fromBytes } from './virtualOffset.ts'\n\nconst CSI1_MAGIC = 21582659 // CSI\\1\nconst CSI2_MAGIC = 38359875 // CSI\\2\n\nconst formats = {\n  0: 'generic',\n  1: 'SAM',\n  2: 'VCF',\n}\n\nfunction lshift(num: number, bits: number) {\n  return num * 2 ** bits\n}\nfunction rshift(num: number, bits: number) {\n  return Math.floor(num / 2 ** bits)\n}\n\nexport default class CSI extends IndexFile {\n  private maxBinNumber: number\n  private depth: number\n  private minShift: number\n  constructor(args: any) {\n    super(args)\n    this.maxBinNumber = 0\n    this.depth = 0\n    this.minShift = 0\n  }\n  async lineCount(refName: string, opts: Options = {}): Promise<number> {\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return -1\n    }\n    const idx = indexData.indices[refId]\n    if (!idx) {\n      return -1\n    }\n    const { stats } = indexData.indices[refId]\n    if (stats) {\n      return stats.lineCount\n    }\n    return -1\n  }\n\n  indexCov() {\n    throw new Error('CSI indexes do not support indexcov')\n  }\n\n  parseAuxData(bytes: Uint8Array, offset: number) {\n    const dataView = new DataView(bytes.buffer)\n    const formatFlags = dataView.getInt32(offset, true)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const format = formats[(formatFlags & 0xf) as 0 | 1 | 2]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: dataView.getInt32(offset + 4, true),\n      start: dataView.getInt32(offset + 8, true),\n      end: dataView.getInt32(offset + 12, true),\n    }\n    const metaValue = dataView.getInt32(offset + 16, true)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : undefined\n    const skipLines = dataView.getInt32(offset + 20, true)\n    const nameSectionLength = dataView.getInt32(offset + 24, true)\n\n    const { refIdToName, refNameToId } = this._parseNameBytes(\n      bytes.subarray(offset + 28, offset + 28 + nameSectionLength),\n    )\n\n    return {\n      refIdToName,\n      refNameToId,\n      skipLines,\n      metaChar,\n      columnNumbers,\n      format,\n      coordinateType,\n    }\n  }\n\n  async _parse(opts: Options = {}) {\n    const bytes = await unzip(await this.filehandle.readFile(opts))\n    const dataView = new DataView(bytes.buffer)\n\n    // check TBI magic numbers\n    let csiVersion\n    if (dataView.getUint32(0, true) === CSI1_MAGIC) {\n      csiVersion = 1\n    } else if (dataView.getUint32(0, true) === CSI2_MAGIC) {\n      csiVersion = 2\n    } else {\n      throw new Error('Not a CSI file')\n    }\n\n    this.minShift = dataView.getInt32(4, true)\n    this.depth = dataView.getInt32(8, true)\n    this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7\n    const maxRefLength = 2 ** (this.minShift + this.depth * 3)\n    const auxLength = dataView.getInt32(12, true)\n    const aux =\n      auxLength && auxLength >= 30\n        ? this.parseAuxData(bytes, 16)\n        : {\n            refIdToName: [],\n            refNameToId: {},\n            metaChar: undefined,\n            columnNumbers: { ref: 0, start: 1, end: 2 },\n            coordinateType: 'zero-based-half-open',\n            format: 'generic',\n          }\n    const refCount = dataView.getInt32(16 + auxLength, true)\n\n    // read the indexes for each reference sequence\n    let firstDataLine: VirtualOffset | undefined\n    let currOffset = 16 + auxLength + 4\n    const indices = new Array(refCount).fill(0).map(() => {\n      const binCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const binIndex: Record<string, Chunk[]> = {}\n      let stats\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = dataView.getUint32(currOffset, true)\n        if (bin > this.maxBinNumber) {\n          // this is a fake bin that actually has stats information about the\n          // reference sequence in it\n          stats = this.parsePseudoBin(bytes, currOffset + 4)\n          currOffset += 4 + 8 + 4 + 16 + 16\n        } else {\n          const loffset = fromBytes(bytes, currOffset + 4)\n          firstDataLine = this._findFirstData(firstDataLine, loffset)\n          const chunkCount = dataView.getInt32(currOffset + 12, true)\n          currOffset += 16\n          const chunks = new Array(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, currOffset)\n            const v = fromBytes(bytes, currOffset + 8)\n            currOffset += 16\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      return { binIndex, stats }\n    })\n\n    return {\n      ...aux,\n      csi: true,\n      refCount,\n      maxBlockSize: 1 << 16,\n      firstDataLine,\n      csiVersion,\n      indices,\n      depth: this.depth,\n      maxBinNumber: this.maxBinNumber,\n      maxRefLength,\n    }\n  }\n\n  parsePseudoBin(bytes: Uint8Array, offset: number) {\n    return {\n      lineCount: longFromBytesToUnsigned(bytes, offset + 28),\n    }\n  }\n\n  async blocksForRange(\n    refName: string,\n    min: number,\n    max: number,\n    opts: Options = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    // List of bin #s that overlap min, max\n    const overlappingBins = this.reg2bins(min, max)\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          for (const c of ba.binIndex[bin]) {\n            chunks.push(new Chunk(c.minv, c.maxv, bin))\n          }\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, new VirtualOffset(0, 0))\n  }\n\n  /**\n   * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n   */\n  reg2bins(beg: number, end: number) {\n    beg -= 1 // < convert to 1-based closed\n    if (beg < 1) {\n      beg = 1\n    }\n    if (end > 2 ** 50) {\n      end = 2 ** 34\n    } // 17 GiB ought to be enough for anybody\n    end -= 1\n    let l = 0\n    let t = 0\n    let s = this.minShift + this.depth * 3\n    const bins = []\n    for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n      const b = t + rshift(beg, s)\n      const e = t + rshift(end, s)\n      if (e - b + bins.length > this.maxBinNumber) {\n        throw new Error(\n          `query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`,\n        )\n      }\n      bins.push([b, e] as const)\n    }\n    return bins\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\n\nimport Chunk from './chunk.ts'\nimport IndexFile, { Options } from './indexFile.ts'\nimport { longFromBytesToUnsigned } from './long.ts'\nimport { optimizeChunks } from './util.ts'\nimport VirtualOffset, { fromBytes } from './virtualOffset.ts'\n\nconst TBI_MAGIC = 21578324 // TBI\\1\nconst TAD_LIDX_SHIFT = 14\n\n/**\n * calculate the list of bins that may overlap with region [beg,end)\n * (zero-based half-open)\n */\nfunction reg2bins(beg: number, end: number) {\n  beg += 1 // < convert to 1-based closed\n  end -= 1\n  return [\n    [0, 0],\n    [1 + (beg >> 26), 1 + (end >> 26)],\n    [9 + (beg >> 23), 9 + (end >> 23)],\n    [73 + (beg >> 20), 73 + (end >> 20)],\n    [585 + (beg >> 17), 585 + (end >> 17)],\n    [4681 + (beg >> 14), 4681 + (end >> 14)],\n  ] as const\n}\n\nexport default class TabixIndex extends IndexFile {\n  async lineCount(refName: string, opts: Options = {}) {\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return -1\n    }\n    const idx = indexData.indices[refId]\n    if (!idx) {\n      return -1\n    }\n    return indexData.indices[refId].stats?.lineCount ?? -1\n  }\n\n  // fetch and parse the index\n  async _parse(opts: Options = {}) {\n    const buf = await this.filehandle.readFile(opts)\n    const bytes = await unzip(buf)\n    const dataView = new DataView(bytes.buffer)\n\n    const magic = dataView.getUint32(0, true)\n    if (magic !== TBI_MAGIC /* \"TBI\\1\" */) {\n      throw new Error('Not a TBI file')\n    }\n\n    // number of reference sequences in the index\n    const refCount = dataView.getUint32(4, true)\n    const formatFlags = dataView.getUint32(8, true)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const formatOpts: Record<number, string> = {\n      0: 'generic',\n      1: 'SAM',\n      2: 'VCF',\n    }\n    const format = formatOpts[formatFlags & 0xf]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: dataView.getInt32(12, true),\n      start: dataView.getInt32(16, true),\n      end: dataView.getInt32(20, true),\n    }\n    const metaValue = dataView.getInt32(24, true)\n    const depth = 5\n    const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7\n    const maxRefLength = 2 ** (14 + depth * 3)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : undefined\n    const skipLines = dataView.getInt32(28, true)\n\n    // read sequence dictionary\n    const nameSectionLength = dataView.getInt32(32, true)\n    const { refNameToId, refIdToName } = this._parseNameBytes(\n      bytes.slice(36, 36 + nameSectionLength),\n    )\n\n    // read the indexes for each reference sequence\n    let currOffset = 36 + nameSectionLength\n    let firstDataLine: VirtualOffset | undefined\n    const indices = new Array(refCount).fill(0).map(() => {\n      // the binning index\n      const binCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const binIndex: Record<number, Chunk[]> = {}\n      let stats\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = dataView.getUint32(currOffset, true)\n        currOffset += 4\n        if (bin > maxBinNumber + 1) {\n          throw new Error(\n            'tabix index contains too many bins, please use a CSI index',\n          )\n        } else if (bin === maxBinNumber + 1) {\n          const chunkCount = dataView.getInt32(currOffset, true)\n          currOffset += 4\n          if (chunkCount === 2) {\n            stats = this.parsePseudoBin(bytes, currOffset)\n          }\n          currOffset += 16 * chunkCount\n        } else {\n          const chunkCount = dataView.getInt32(currOffset, true)\n          currOffset += 4\n          const chunks = new Array(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, currOffset)\n            const v = fromBytes(bytes, currOffset + 8)\n            currOffset += 16\n            firstDataLine = this._findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      // the linear index\n      const linearCount = dataView.getInt32(currOffset, true)\n      currOffset += 4\n      const linearIndex = new Array(linearCount)\n      for (let k = 0; k < linearCount; k += 1) {\n        linearIndex[k] = fromBytes(bytes, currOffset)\n        currOffset += 8\n        firstDataLine = this._findFirstData(firstDataLine, linearIndex[k])\n      }\n      return {\n        binIndex,\n        linearIndex,\n        stats,\n      }\n    })\n\n    return {\n      indices,\n      metaChar,\n      maxBinNumber,\n      maxRefLength,\n      skipLines,\n      firstDataLine,\n      columnNumbers,\n      coordinateType,\n      format,\n      refIdToName,\n      refNameToId,\n      maxBlockSize: 1 << 16,\n    }\n  }\n\n  parsePseudoBin(bytes: Uint8Array, offset: number) {\n    return {\n      lineCount: longFromBytesToUnsigned(bytes, offset + 16),\n    }\n  }\n\n  async blocksForRange(\n    refName: string,\n    min: number,\n    max: number,\n    opts: Options = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const refId = indexData.refNameToId[refName]\n    if (refId === undefined) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    const minOffset =\n      ba.linearIndex.length > 0\n        ? ba.linearIndex[\n            min >> TAD_LIDX_SHIFT >= ba.linearIndex.length\n              ? ba.linearIndex.length - 1\n              : min >> TAD_LIDX_SHIFT\n          ]\n        : new VirtualOffset(0, 0)\n    if (!minOffset) {\n      console.warn('querying outside of possible tabix range')\n    }\n\n    // const { linearIndex, binIndex } = indexes\n\n    const overlappingBins = reg2bins(min, max) // List of bin #s that overlap min, max\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          for (const c of ba.binIndex[bin]) {\n            chunks.push(new Chunk(c.minv, c.maxv, bin))\n          }\n        }\n      }\n    }\n\n    // Use the linear index to find minimum file position of chunks that could\n    // contain alignments in the region\n    const nintv = ba.linearIndex.length\n    let lowest: VirtualOffset | undefined\n    const minLin = Math.min(min >> 14, nintv - 1)\n    const maxLin = Math.min(max >> 14, nintv - 1)\n    for (let i = minLin; i <= maxLin; ++i) {\n      const vp = ba.linearIndex[i]\n      if (vp && (!lowest || vp.compareTo(lowest) < 0)) {\n        lowest = vp\n      }\n    }\n\n    return optimizeChunks(chunks, lowest)\n  }\n}\n","import AbortablePromiseCache from '@gmod/abortable-promise-cache'\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle'\nimport LRU from '@jbrowse/quick-lru'\nimport { LocalFile, RemoteFile } from 'generic-filehandle2'\n\nimport Chunk from './chunk.ts'\nimport CSI from './csi.ts'\nimport IndexFile, { Options } from './indexFile.ts'\nimport TBI from './tbi.ts'\n\nimport type { GenericFilehandle } from 'generic-filehandle2'\n\ntype GetLinesCallback = (\n  line: string,\n  fileOffset: number,\n  start: number,\n  end: number,\n) => void\n\ninterface GetLinesOpts {\n  [key: string]: unknown\n  signal?: AbortSignal\n  lineCallback: GetLinesCallback\n}\n\ninterface ReadChunk {\n  buffer: Uint8Array\n  cpositions: number[]\n  dpositions: number[]\n}\n\nexport default class TabixIndexedFile {\n  private filehandle: GenericFilehandle\n  private index: IndexFile\n  private renameRefSeq: (n: string) => string\n  private hasCustomRenameRefSeq: boolean\n  private chunkCache: AbortablePromiseCache<Chunk, ReadChunk>\n  public cache = new LRU<\n    string,\n    { bytesRead: number; buffer: Uint8Array; nextIn: number }\n  >({\n    maxSize: 1000,\n  })\n\n  /**\n   * @param {object} args\n   *\n   * @param {string} [args.path]\n   *\n   * @param {filehandle} [args.filehandle]\n   *\n   * @param {string} [args.tbiPath]\n   *\n   * @param {filehandle} [args.tbiFilehandle]\n   *\n   * @param {string} [args.csiPath]\n   *\n   * @param {filehandle} [args.csiFilehandle]\n   *\n   * @param {url} [args.url]\n   *\n   * @param {csiUrl} [args.csiUrl]\n   *\n   * @param {tbiUrl} [args.tbiUrl]\n   *\n   * @param {function} [args.renameRefSeqs] optional function with sig `string\n   * => string` to transform reference sequence names for the purpose of\n   * indexing and querying. note that the data that is returned is not altered,\n   * just the names of the reference sequences that are used for querying.\n   */\n  constructor({\n    path,\n    filehandle,\n    url,\n    tbiPath,\n    tbiUrl,\n    tbiFilehandle,\n    csiPath,\n    csiUrl,\n    csiFilehandle,\n    renameRefSeqs: renameRefSeqsPre,\n    chunkCacheSize = 5 * 2 ** 20,\n  }: {\n    path?: string\n    filehandle?: GenericFilehandle\n    url?: string\n    tbiPath?: string\n    tbiUrl?: string\n    tbiFilehandle?: GenericFilehandle\n    csiPath?: string\n    csiUrl?: string\n    csiFilehandle?: GenericFilehandle\n    renameRefSeqs?: (n: string) => string\n    chunkCacheSize?: number\n  }) {\n    const renameRefSeqs = renameRefSeqsPre ?? (arg => arg)\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else if (url) {\n      this.filehandle = new RemoteFile(url)\n    } else {\n      throw new TypeError('must provide either filehandle or path')\n    }\n\n    if (tbiFilehandle) {\n      this.index = new TBI({\n        filehandle: tbiFilehandle,\n        renameRefSeqs,\n      })\n    } else if (csiFilehandle) {\n      this.index = new CSI({\n        filehandle: csiFilehandle,\n        renameRefSeqs,\n      })\n    } else if (tbiPath) {\n      this.index = new TBI({\n        filehandle: new LocalFile(tbiPath),\n        renameRefSeqs,\n      })\n    } else if (csiPath) {\n      this.index = new CSI({\n        filehandle: new LocalFile(csiPath),\n        renameRefSeqs,\n      })\n    } else if (path) {\n      this.index = new TBI({\n        filehandle: new LocalFile(`${path}.tbi`),\n        renameRefSeqs,\n      })\n    } else if (csiUrl) {\n      this.index = new CSI({\n        filehandle: new RemoteFile(csiUrl),\n      })\n    } else if (tbiUrl) {\n      this.index = new TBI({\n        filehandle: new RemoteFile(tbiUrl),\n      })\n    } else if (url) {\n      this.index = new TBI({\n        filehandle: new RemoteFile(`${url}.tbi`),\n      })\n    } else {\n      throw new TypeError(\n        'must provide one of tbiFilehandle, tbiPath, csiFilehandle, csiPath, tbiUrl, csiUrl',\n      )\n    }\n\n    this.renameRefSeq = renameRefSeqs\n    this.hasCustomRenameRefSeq = renameRefSeqsPre !== undefined\n    this.chunkCache = new AbortablePromiseCache<Chunk, ReadChunk>({\n      cache: new LRU({ maxSize: Math.floor(chunkCacheSize / (1 << 16)) }),\n      fill: (args: Chunk, signal?: AbortSignal) =>\n        this.readChunk(args, { signal }),\n    })\n  }\n\n  /**\n   * @param refName name of the reference sequence\n   *\n   * @param start start of the region (in 0-based half-open coordinates)\n   *\n   * @param end end of the region (in 0-based half-open coordinates)\n   *\n   * @param opts callback called for each line in the region. can also pass a\n   * object param containing obj.lineCallback, obj.signal, etc\n   *\n   * @returns promise that is resolved when the whole read is finished,\n   * rejected on error\n   */\n  private calculateFileOffset(\n    cpositions: number[],\n    dpositions: number[],\n    pos: number,\n    blockStart: number,\n    minvDataPosition: number,\n  ) {\n    return (\n      cpositions[pos]! * (1 << 8) +\n      (blockStart - dpositions[pos]!) +\n      minvDataPosition +\n      1\n    )\n  }\n\n  async getLines(\n    refName: string,\n    s: number | undefined,\n    e: number | undefined,\n    opts: GetLinesOpts | GetLinesCallback,\n  ) {\n    let signal: AbortSignal | undefined\n    let options: Options = {}\n    let callback: GetLinesCallback\n\n    if (typeof opts === 'function') {\n      callback = opts\n    } else {\n      options = opts\n      callback = opts.lineCallback\n      signal = opts.signal\n    }\n\n    const metadata = await this.index.getMetadata(options)\n    const start = s ?? 0\n    const end = e ?? metadata.maxRefLength\n    if (!(start <= end)) {\n      throw new TypeError(\n        'invalid start and end coordinates. start must be less than or equal to end',\n      )\n    }\n    if (start === end) {\n      return\n    }\n\n    const chunks = await this.index.blocksForRange(refName, start, end, options)\n    const decoder = new TextDecoder('utf8')\n\n    const isVCF = metadata.format === 'VCF'\n    const columnNumbersEffective = {\n      ref: metadata.columnNumbers.ref || 0,\n      start: metadata.columnNumbers.start || 0,\n      end: isVCF ? 8 : metadata.columnNumbers.end || 0,\n    }\n    const maxColumn = Math.max(\n      columnNumbersEffective.ref,\n      columnNumbersEffective.start,\n      columnNumbersEffective.end,\n    )\n    const metaCharCode = metadata.metaChar?.charCodeAt(0)\n    const coordinateOffset =\n      metadata.coordinateType === '1-based-closed' ? -1 : 0\n    const isIdentityRename = !this.hasCustomRenameRefSeq\n\n    // now go through each chunk and parse and filter the lines out of it\n    for (const c of chunks) {\n      const { buffer, cpositions, dpositions } = await this.chunkCache.get(\n        c.toString(),\n        c,\n        signal,\n      )\n\n      let blockStart = 0\n      let pos = 0\n\n      // fast path, Buffer is just ASCII chars and not gigantor, can be\n      // converted to string and processed directly.\n      //\n      // if it is not ASCII or, we have to decode line by line, as it is\n      // otherwise hard to get the right 'fileOffset' based feature IDs\n      //\n      // we use a basic check for isASCII: string length equals buffer length\n      // if it is ASCII...no multi-byte decodings\n      const str = decoder.decode(buffer)\n      const strIsASCII = buffer.length == str.length\n      if (strIsASCII) {\n        while (blockStart < str.length) {\n          const n = str.indexOf('\\n', blockStart)\n          if (n === -1) {\n            break\n          }\n          const line = str.slice(blockStart, n)\n\n          // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n          if (dpositions) {\n            const target = blockStart + c.minv.dataPosition\n            while (pos < dpositions.length && target >= dpositions[pos]!) {\n              pos++\n            }\n          }\n\n          // filter the line for whether it is within the requested range\n          const result = this.checkLine(\n            refName,\n            start,\n            end,\n            line,\n            columnNumbersEffective.ref,\n            columnNumbersEffective.start,\n            columnNumbersEffective.end,\n            maxColumn,\n            metaCharCode,\n            coordinateOffset,\n            isVCF,\n            isIdentityRename,\n          )\n\n          if (result === null) {\n            return\n          } else if (result !== undefined) {\n            callback(\n              line,\n              this.calculateFileOffset(\n                cpositions,\n                dpositions,\n                pos,\n                blockStart,\n                c.minv.dataPosition,\n              ),\n              result.start,\n              result.end,\n            )\n          }\n          blockStart = n + 1\n        }\n      } else {\n        while (blockStart < buffer.length) {\n          const n = buffer.indexOf('\\n'.charCodeAt(0), blockStart)\n          if (n === -1) {\n            break\n          }\n          const b = buffer.slice(blockStart, n)\n          const line = decoder.decode(b)\n\n          // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n          if (dpositions) {\n            const target = blockStart + c.minv.dataPosition\n            while (pos < dpositions.length && target >= dpositions[pos]!) {\n              pos++\n            }\n          }\n\n          // filter the line for whether it is within the requested range\n          const result = this.checkLine(\n            refName,\n            start,\n            end,\n            line,\n            columnNumbersEffective.ref,\n            columnNumbersEffective.start,\n            columnNumbersEffective.end,\n            maxColumn,\n            metaCharCode,\n            coordinateOffset,\n            isVCF,\n            isIdentityRename,\n          )\n\n          if (result === null) {\n            return\n          } else if (result !== undefined) {\n            callback(\n              line,\n              this.calculateFileOffset(\n                cpositions,\n                dpositions,\n                pos,\n                blockStart,\n                c.minv.dataPosition,\n              ),\n              result.start,\n              result.end,\n            )\n          }\n          blockStart = n + 1\n        }\n      }\n    }\n  }\n\n  async getMetadata(opts: Options = {}) {\n    return this.index.getMetadata(opts)\n  }\n\n  /**\n   * get a buffer containing the \"header\" region of the file, which are the\n   * bytes up to the first non-meta line\n   */\n  async getHeaderBuffer(opts: Options = {}) {\n    const { firstDataLine, metaChar, maxBlockSize } =\n      await this.getMetadata(opts)\n\n    const maxFetch = (firstDataLine?.blockPosition || 0) + maxBlockSize\n    // TODO: what if we don't have a firstDataLine, and the header actually\n    // takes up more than one block? this case is not covered here\n\n    const buf = await this.filehandle.read(maxFetch, 0, opts)\n    const bytes = await unzip(buf)\n\n    // trim off lines after the last non-meta line\n    if (metaChar) {\n      // trim backward from the end\n      let lastNewline = -1\n      const newlineByte = '\\n'.charCodeAt(0)\n      const metaByte = metaChar.charCodeAt(0)\n\n      for (let i = 0, l = bytes.length; i < l; i++) {\n        const byte = bytes[i]\n        if (i === lastNewline + 1 && byte !== metaByte) {\n          break\n        }\n        if (byte === newlineByte) {\n          lastNewline = i\n        }\n      }\n      return bytes.subarray(0, lastNewline + 1)\n    }\n    return bytes\n  }\n\n  /**\n   * get a string containing the \"header\" region of the file, is the portion up\n   * to the first non-meta line\n   */\n  async getHeader(opts: Options = {}) {\n    const decoder = new TextDecoder('utf8')\n    const bytes = await this.getHeaderBuffer(opts)\n    return decoder.decode(bytes)\n  }\n\n  /**\n   * get an array of reference sequence names, in the order in which they occur\n   * in the file. reference sequence renaming is not applied to these names.\n   */\n  async getReferenceSequenceNames(opts: Options = {}) {\n    const metadata = await this.getMetadata(opts)\n    return metadata.refIdToName\n  }\n\n  /**\n   * @param {string} regionRefName\n   *\n   * @param {number} regionStart region start coordinate (0-based-half-open)\n   *\n   * @param {number} regionEnd region end coordinate (0-based-half-open)\n   *\n   * @param {string} line\n   *\n   * @param {number} refColumn column number for ref\n   *\n   * @param {number} startColumn column number for start\n   *\n   * @param {number} endColumn column number for end\n   *\n   * @param {number} maxColumn pre-calculated max column\n   *\n   * @param {number} metaCharCode pre-calculated metaChar code\n   *\n   * @param {number} coordinateOffset 0 or -1 for coordinate adjustment\n   *\n   * @param {boolean} isVCF whether this is VCF format\n   *\n   * @param {boolean} isIdentityRename whether renameRefSeq is the identity function\n   *\n   * @returns {{ start: number, end: number } | null | undefined} coordinates if overlapping, null if should stop processing, undefined otherwise\n   */\n  checkLine(\n    regionRefName: string,\n    regionStart: number,\n    regionEnd: number,\n    line: string,\n    refColumn: number,\n    startColumn: number,\n    endColumn: number,\n    maxColumn: number,\n    metaCharCode: number | undefined,\n    coordinateOffset: number,\n    isVCF: boolean,\n    isIdentityRename: boolean,\n  ): { start: number; end: number } | null | undefined {\n    if (metaCharCode !== undefined && line.charCodeAt(0) === metaCharCode) {\n      return\n    }\n\n    // Length-based fast path: split for short lines, indexOf for long lines\n    // Split is faster for short lines, but slow for long lines with big attribute columns\n    if (line.length < 500) {\n      const fields = line.split('\\t')\n      const ref = fields[refColumn - 1]!\n      const refMatch = isIdentityRename\n        ? ref === regionRefName\n        : this.renameRefSeq(ref) === regionRefName\n      if (!refMatch) {\n        return\n      }\n\n      const startCoordinate = +fields[startColumn - 1]! + coordinateOffset\n      if (startCoordinate >= regionEnd) {\n        return null\n      }\n\n      let endCoordinate: number\n      if (endColumn === 0 || endColumn === startColumn) {\n        endCoordinate = startCoordinate + 1\n      } else if (isVCF) {\n        endCoordinate = this._getVcfEnd(\n          startCoordinate,\n          fields[3]!,\n          fields[endColumn - 1]!,\n        )\n      } else {\n        endCoordinate = +fields[endColumn - 1]!\n      }\n\n      if (endCoordinate <= regionStart) {\n        return\n      }\n      return { start: startCoordinate, end: endCoordinate }\n    }\n\n    // Long lines - use indexOf chain (avoids parsing long attribute column)\n    let prev = -1\n    const tabs = [-1]\n    for (let i = 0; i < maxColumn; i++) {\n      const pos = line.indexOf('\\t', prev + 1)\n      if (pos === -1) {\n        tabs.push(line.length)\n        break\n      }\n      tabs.push(pos)\n      prev = pos\n    }\n\n    const ref = line.slice(tabs[refColumn - 1]! + 1, tabs[refColumn])\n    const refMatch = isIdentityRename\n      ? ref === regionRefName\n      : this.renameRefSeq(ref) === regionRefName\n    if (!refMatch) {\n      return\n    }\n\n    const startCoordinate =\n      +line.slice(tabs[startColumn - 1]! + 1, tabs[startColumn]) +\n      coordinateOffset\n    if (startCoordinate >= regionEnd) {\n      return null\n    }\n\n    let endCoordinate: number\n    if (endColumn === 0 || endColumn === startColumn) {\n      endCoordinate = startCoordinate + 1\n    } else if (isVCF) {\n      endCoordinate = this._getVcfEnd(\n        startCoordinate,\n        line.slice(tabs[3]! + 1, tabs[4]),\n        line.slice(tabs[endColumn - 1]! + 1, tabs[endColumn]),\n      )\n    } else {\n      endCoordinate = +line.slice(tabs[endColumn - 1]! + 1, tabs[endColumn])\n    }\n\n    if (endCoordinate <= regionStart) {\n      return\n    }\n\n    return { start: startCoordinate, end: endCoordinate }\n  }\n\n  _getVcfEnd(startCoordinate: number, refSeq: string, info: any) {\n    let endCoordinate = startCoordinate + refSeq.length\n    const isTRA = info.includes('SVTYPE=TRA')\n    if (isTRA) {\n      return startCoordinate + 1\n    }\n\n    if (info[0] !== '.') {\n      const endIdx = info.indexOf('END=')\n      if (endIdx !== -1 && (endIdx === 0 || info[endIdx - 1] === ';')) {\n        const start = endIdx + 4\n        let end = info.indexOf(';', start)\n        if (end === -1) {\n          end = info.length\n        }\n        endCoordinate = Number.parseInt(info.slice(start, end), 10)\n      }\n    }\n    return endCoordinate\n  }\n\n  /**\n   * return the approximate number of data lines in the given reference\n   * sequence\n   *\n   * @param refSeq reference sequence name\n   *\n   * @returns number of data lines present on that reference sequence\n   */\n  async lineCount(refName: string, opts: Options = {}) {\n    return this.index.lineCount(refName, opts)\n  }\n\n  /**\n   * read and uncompress the data in a chunk (composed of one or more\n   * contiguous bgzip blocks) of the file\n   */\n  async readChunk(c: Chunk, opts: Options = {}) {\n    const ret = await this.filehandle.read(\n      c.fetchedSize(),\n      c.minv.blockPosition,\n      opts,\n    )\n    return unzipChunkSlice(ret, c, this.cache)\n  }\n}\n"],"names":["NullSignal","AggregateAbortController","constructor","signals","Set","abortController","AbortController","addSignal","signal","this","aborted","Error","add","handleAborted","addEventListener","delete","size","abort","AggregateStatusReporter","callbacks","addCallback","callback","currentMessage","message","elt","AbortablePromiseCache","fill","cache","TypeError","get","set","fillCallback","isAbortException","exception","name","code","evict","key","entry","data","statusCallback","aborter","statusReporter","newEntry","promise","settled","then","catch","error","console","checkSinglePromise","checkForSingleAbort","Object","assign","result","has","AbortSignal","cacheEntry","cachedEntry","clear","keyIter","keys","deleteCount","next","done","value","Chunk","minv","maxv","bin","fetchedSize","_fetchedSize","toUniqueString","toString","compareTo","b","undefined","blockPosition","IndexFile","filehandle","renameRefSeqs","n","renameRefSeq","getMetadata","opts","indices","_indices","rest","parse","_findFirstData","currentFdl","virtualOffset","parseP","_parse","hasRefSeq","seqId","idx","binIndex","_parseNameBytes","namesBytes","currRefId","currNameStart","refIdToName","refNameToId","decoder","TextDecoder","i","length","refName","decode","subarray","longFromBytesToUnsigned","source","low","TWO_PWR_16_DBL","canMergeBlocks","chunk1","chunk2","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","sort","c0","c1","dif","dataPosition","chunk","push","VirtualOffset","fromBytes","bytes","offset","formats","lshift","num","bits","rshift","Math","floor","CSI","args","super","maxBinNumber","depth","minShift","lineCount","indexData","refId","stats","indexCov","parseAuxData","dataView","DataView","buffer","formatFlags","getInt32","coordinateType","format","columnNumbers","ref","start","end","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","unzip","readFile","csiVersion","getUint32","maxRefLength","auxLength","aux","refCount","firstDataLine","currOffset","Array","map","binCount","j","parsePseudoBin","loffset","chunkCount","k","u","v","csi","maxBlockSize","blocksForRange","min","max","ba","overlappingBins","reg2bins","c","beg","l","t","s","bins","e","TabixIndex","buf","slice","linearCount","linearIndex","warn","nintv","minLin","maxLin","vp","TabixIndexedFile","path","url","tbiPath","tbiUrl","tbiFilehandle","csiPath","csiUrl","csiFilehandle","renameRefSeqsPre","chunkCacheSize","LRU","maxSize","arg","LocalFile","RemoteFile","index","TBI","hasCustomRenameRefSeq","chunkCache","readChunk","calculateFileOffset","cpositions","dpositions","pos","blockStart","minvDataPosition","getLines","options","lineCallback","metadata","isVCF","columnNumbersEffective","maxColumn","metaCharCode","charCodeAt","coordinateOffset","isIdentityRename","str","indexOf","line","target","checkLine","getHeaderBuffer","maxFetch","read","lastNewline","newlineByte","metaByte","byte","getHeader","getReferenceSequenceNames","regionRefName","regionStart","regionEnd","refColumn","startColumn","endColumn","fields","split","startCoordinate","endCoordinate","_getVcfEnd","prev","tabs","refSeq","info","includes","endIdx","Number","parseInt","ret","unzipChunkSlice"],"sourceRoot":""}