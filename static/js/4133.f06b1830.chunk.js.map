{"version":3,"file":"static/js/4133.f06b1830.chunk.js","mappings":"0IAAA,MAAMA,GAMS,MAAMC,EAArB,cACE,KAAAC,QAAU,IAAIC,IACd,KAAAC,gBAAkB,IAAIC,eAyCxB,CAjCE,SAAAC,CAAUC,EAAsB,IAAIP,GAClC,GAAIQ,KAAKD,OAAOE,QACd,MAAM,IAAIC,MAAM,yCAKlBF,KAAKN,QAAQS,IAAIJ,GACbA,EAAOE,QAGTD,KAAKI,cAAcL,GACyB,mBAA5BA,EAAOM,kBACvBN,EAAOM,iBAAiB,SAAS,KAC/BL,KAAKI,cAAcL,EAAO,GAGhC,CAEA,aAAAK,CAAcL,GACZC,KAAKN,QAAQY,OAAOP,GACM,IAAtBC,KAAKN,QAAQa,MACfP,KAAKJ,gBAAgBY,OAEzB,CAEA,UAAIT,GACF,OAAOC,KAAKJ,gBAAgBG,MAC9B,CAEA,KAAAS,GACER,KAAKJ,gBAAgBY,OACvB,EChDa,MAAMC,EAArB,cACE,KAAAC,UAAY,IAAIf,GAclB,CAXE,WAAAgB,CAAYC,EAAqB,QAC/BZ,KAAKU,UAAUP,IAAIS,GACnBA,EAASZ,KAAKa,eAChB,CAEA,QAAAD,CAASE,GACPd,KAAKa,eAAiBC,EACtB,IAAK,MAAMC,KAAOf,KAAKU,UACrBK,EAAID,EAER,ECSa,MAAME,EAWnB,WAAAC,EAAY,KACVC,EAAI,MACJC,IAKA,GAAoB,mBAATD,EACT,MAAM,IAAIE,UAAU,6BAEtB,GAAqB,iBAAVD,EACT,MAAM,IAAIC,UAAU,4BAEtB,GACuB,mBAAdD,EAAME,KACQ,mBAAdF,EAAMG,KACW,mBAAjBH,EAAMb,OAEb,MAAM,IAAIc,UACR,qEAIJpB,KAAKmB,MAAQA,EACbnB,KAAKuB,aAAeL,CACtB,CAEA,uBAAOM,CAAiBC,GACtB,MAEqB,eAAnBA,EAAUC,MAGS,gBAAnBD,EAAUE,MAEY,wBAAtBF,EAAUX,SAEY,mBAAtBW,EAAUX,OAEd,CAEA,KAAAc,CAAMC,EAAaC,GACb9B,KAAKmB,MAAME,IAAIQ,KAASC,GAC1B9B,KAAKmB,MAAMb,OAAOuB,EAEtB,CAEA,IAAAX,CAAKW,EAAaE,EAAShC,EAAsBiC,GAC/C,MAAMC,EAAU,IAAIxC,EACdyC,EAAiB,IAAIzB,EAC3ByB,EAAevB,YAAYqB,GAC3B,MAAMG,EAAqB,CACzBF,QAASA,EACTG,QAASpC,KAAKuB,aAAaQ,EAAME,EAAQlC,QAASe,IAChDoB,EAAetB,SAASE,EAAQ,IAElCuB,SAAS,EACTH,iBACA,WAAIjC,GACF,OAAOD,KAAKiC,QAAQlC,OAAOE,OAC7B,GAEFkC,EAASF,QAAQnC,UAAUC,GAG3BoC,EAASF,QAAQlC,OAAOM,iBAAiB,SAAS,KAC3C8B,EAASE,SACZrC,KAAK4B,MAAMC,EAAKM,EAClB,IAIFA,EAASC,QACNE,MACC,KACEH,EAASE,SAAU,CAAI,IAEzB,KACEF,EAASE,SAAU,EAGnBrC,KAAK4B,MAAMC,EAAKM,EAAS,IAG5BI,OAAMC,IAIL,MADAC,QAAQD,MAAMA,GACRA,CAAK,IAGfxC,KAAKmB,MAAMG,IAAIO,EAAKM,EACtB,CAEA,yBAAOO,CAAsBN,EAAqBrC,GAIhD,SAAS4C,IACP,GAAI5C,aAAM,EAANA,EAAQE,QACV,MAAM2C,OAAOC,OAAO,IAAI3C,MAAM,WAAY,CAAEyB,KAAM,eAEtD,CAEA,OAAOS,EAAQE,MACbQ,IACEH,IACOG,KAETN,IAEE,MADAG,IACMH,CAAK,GAGjB,CAEA,GAAAO,CAAIlB,GACF,OAAO7B,KAAKmB,MAAM4B,IAAIlB,EACxB,CAeA,GAAAR,CACEQ,EACAE,EACAhC,EACAiC,GAEA,IAAKjC,GAAUgC,aAAgBiB,YAC7B,MAAM,IAAI5B,UACR,yGAGJ,MAAM6B,EAAajD,KAAKmB,MAAME,IAAIQ,GAElC,OAAIoB,EACEA,EAAWhD,UAAYgD,EAAWZ,SAEpCrC,KAAK4B,MAAMC,EAAKoB,GACTjD,KAAKqB,IAAIQ,EAAKE,EAAMhC,EAAQiC,IAGjCiB,EAAWZ,QAENY,EAAWb,SAKpBa,EAAWhB,QAAQnC,UAAUC,GAC7BkD,EAAWf,eAAevB,YAAYqB,GAE/BhB,EAAsB0B,mBAC3BO,EAAWb,QACXrC,KAKJC,KAAKkB,KAAKW,EAAKE,EAAMhC,EAAQiC,GACtBhB,EAAsB0B,mBAG3B1C,KAAKmB,MAAME,IAAIQ,GAAMO,QACrBrC,GAEJ,CAQA,OAAO8B,GACL,MAAMqB,EAAclD,KAAKmB,MAAME,IAAIQ,GAC/BqB,IACGA,EAAYb,SACfa,EAAYjB,QAAQzB,QAEtBR,KAAKmB,MAAMb,OAAOuB,GAEtB,CAMA,KAAAsB,GAEE,MAAMC,EAAUpD,KAAKmB,MAAMkC,OAC3B,IAAIC,EAAc,EAClB,IAAK,IAAIR,EAASM,EAAQG,QAAST,EAAOU,KAAMV,EAASM,EAAQG,OAC/DvD,KAAKM,OAAOwC,EAAOW,OACnBH,GAAe,EAEjB,OAAOA,CACT,E,6CClPa,MAAMI,EAGnB,WAAAzC,CAAY0C,EAAuBC,GACjC5D,KAAK2D,cAAgBA,EACrB3D,KAAK4D,aAAeA,CACtB,CAEA,QAAAC,GACE,MAAO,GAAG7D,KAAK2D,iBAAiB3D,KAAK4D,cACvC,CAEA,SAAAE,CAAUC,GACR,OACE/D,KAAK2D,cAAgBI,EAAEJ,eAAiB3D,KAAK4D,aAAeG,EAAEH,YAElE,CAEA,UAAOI,IAAOC,GACZ,IAAID,EACAE,EAAI,EACR,MAAQF,EAAKE,GAAK,EAChBF,EAAMC,EAAKC,GAEb,KAAOA,EAAID,EAAKE,OAAQD,GAAK,EACvBF,EAAIF,UAAUG,EAAKC,IAAM,IAC3BF,EAAMC,EAAKC,IAGf,OAAOF,CACT,EAEK,SAASI,EAAUC,EAAeC,EAAS,EAAGC,GAAY,GAC/D,GAAIA,EACF,MAAM,IAAIrE,MAAM,mDAGlB,OAAO,IAAIwD,EACW,cAApBW,EAAMC,EAAS,GACO,WAApBD,EAAMC,EAAS,GACK,SAApBD,EAAMC,EAAS,GACK,MAApBD,EAAMC,EAAS,GACK,IAApBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAChBD,EAAMC,EAAS,IAAM,EAAKD,EAAMC,GAErC,CC3Ce,MAAME,EAGnB,WAAAvD,CACSwD,EACAC,EACAC,EACAC,GAHA,KAAAH,KAAAA,EACA,KAAAC,KAAAA,EACA,KAAAC,IAAAA,EACA,KAAAC,aAAAA,CACN,CAEH,cAAAC,GACE,MAAO,GAAG7E,KAAKyE,KAAKZ,eAAe7D,KAAK0E,KAAKb,mBAC3C7D,KAAK2E,oBACU3E,KAAK8E,gBACxB,CAEA,QAAAjB,GACE,OAAO7D,KAAK6E,gBACd,CAEA,SAAAf,CAAUC,GACR,OACE/D,KAAKyE,KAAKX,UAAUC,EAAEU,OACtBzE,KAAK0E,KAAKZ,UAAUC,EAAEW,OACtB1E,KAAK2E,IAAMZ,EAAEY,GAEjB,CAEA,WAAAG,GACE,YAA0BC,IAAtB/E,KAAK4E,aACA5E,KAAK4E,aAEP5E,KAAK0E,KAAKf,cAAgB,MAAY3D,KAAKyE,KAAKd,aACzD,E,wBChCK,SAASqB,EAAQC,GACtB,OAAO,IAAIC,SAAQC,GAAWC,WAAWD,EAASF,IACpD,CA0EO,SAASI,EAAeC,EAAiBC,GAC9C,MAAMC,EAAwB,GAC9B,IAAIC,EAEJ,GAAsB,IAAlBH,EAAOnB,OACT,OAAOmB,EAGTA,EAAOI,MAAK,CAACC,EAAIC,KACf,MAAMC,EAAMF,EAAGlB,KAAKd,cAAgBiC,EAAGnB,KAAKd,cAC5C,OAAe,IAARkC,EAAYF,EAAGlB,KAAKb,aAAegC,EAAGnB,KAAKb,aAAeiC,CAAG,IAGtE,IAAK,MAAMC,KAASR,IACbC,GAAUO,EAAMpB,KAAKZ,UAAUyB,GAAU,UAC1BR,IAAdU,GACFD,EAAaO,KAAKD,GAClBL,EAAYK,IAvCWE,EAyCJP,GAzCmBQ,EAyCRH,GAvC3BrB,KAAKd,cAAgBqC,EAAOtB,KAAKf,cAAgB,MACxDsC,EAAOvB,KAAKf,cAAgBqC,EAAOvB,KAAKd,cAAgB,IAuC9CmC,EAAMpB,KAAKZ,UAAU2B,EAAUf,MAAQ,IACzCe,EAAUf,KAAOoB,EAAMpB,OAGzBc,EAAaO,KAAKD,GAClBL,EAAYK,KA/Cf,IAAwBE,EAAeC,EAqD5C,OAAOT,CACT,CAEO,SAASU,EAAe7B,EAAeC,GAO5C,MAAO,CAAE6B,UAjHJ,SAAsBC,GAC3B,GACEA,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAIvG,MAAM,oBAElB,OAAOkG,EAAKM,UACd,CAmGoBC,CAChB,gBACEC,MAAMC,UAAUC,MAAMC,KAAK1C,EAAOC,EAAQA,EAAS,IACnD,IAIN,CAEO,SAAS0C,EACdC,EACAC,GAEA,OAAOD,EACHA,EAAcnD,UAAUoD,GAAiB,EACvCA,EACAD,EACFC,CACN,CAEO,SAASC,EACdC,EACAC,EAAwCC,GAAKA,GAE7C,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMC,EAAc,GACdC,EAAsC,CAAC,EAC7C,IAAK,IAAIxD,EAAI,EAAGA,EAAIkD,EAAWjD,OAAQD,GAAK,EAC1C,IAAKkD,EAAWlD,GAAI,CAClB,GAAIsD,EAAgBtD,EAAG,CACrB,IAAIyD,EAAUP,EAAWvD,SAAS,OAAQ2D,EAAetD,GACzDyD,EAAUN,EAAaM,GACvBF,EAAYF,GAAaI,EACzBD,EAAYC,GAAWJ,CACzB,CACAC,EAAgBtD,EAAI,EACpBqD,GAAa,CACf,CAEF,MAAO,CAAEG,cAAaD,cACxB,CCxJe,MAAeG,EAQ5B,WAAA3G,EAAY,WACV4G,EAAU,aACVR,EAAgBS,GAAcA,IAK9B9H,KAAK6H,WAAaA,EAClB7H,KAAKqH,aAAeA,CACtB,ECMa,MAAMU,UAAYH,EAG/B,eAAMzB,CAAU6B,EAAeC,G,QAE7B,OAAsC,QAA/B,EAAwB,QAAxB,SADiBjI,KAAKkI,MAAMD,IAClBE,QAAQH,UAAM,eAAEI,aAAK,eAAEjC,YAAa,CACvD,CAGA,YAAMkC,CAAOJ,GACX,MAAM5D,QAAerE,KAAK6H,WAAWS,SAASL,GAG9C,GAlCc,WAkCV5D,EAAMkE,aAAa,GACrB,MAAM,IAAIrI,MAAM,kBAGlB,MAAMsI,EAAWnE,EAAMoE,YAAY,GAKnC,IACIxB,EADAyB,EAAO,EAKX,MAAMP,EAAU,IAAIvB,MAIjB4B,GACH,IAAK,IAAItE,EAAI,EAAGA,EAAIsE,EAAUtE,IAAK,CAEjC,MAAMyE,EAAWtE,EAAMoE,YAAYC,GACnC,IAAIN,EAEJM,GAAQ,EACR,MAAME,EAAoC,CAAC,EAE3C,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CACpC,MAAMlE,EAAMN,EAAMkE,aAAaG,GAE/B,GADAA,GAAQ,EACII,QAARnE,EACF+D,GAAQ,EACRN,EAAQlC,EAAe7B,EAAOqE,EAAO,IACrCA,GAAQ,OACH,IAAI/D,EAAMmE,MACf,MAAM,IAAI5I,MAAM,oDACX,CACL,MAAM6I,EAAa1E,EAAMoE,YAAYC,GACrCA,GAAQ,EACR,MAAMpD,EAAS,IAAIsB,MAAamC,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,IAAK,CACnC,MAAMC,EAAI7E,EAAUC,EAAOqE,GAC3BA,GAAQ,EACR,MAAMQ,EAAI9E,EAAUC,EAAOqE,GAC3BA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAegC,GAC7C3D,EAAO0D,GAAK,IAAIxE,EAAMyE,EAAGC,EAAGvE,EAC9B,CACAiE,EAASjE,GAAOW,CAClB,EACF,CAEA,MAAM6D,EAAc9E,EAAMoE,YAAYC,GACtCA,GAAQ,EAIR,MAAMU,EAAc,IAAIxC,MAAqBuC,GAC7C,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAaN,IAAK,CACpC,MAAMvE,EAASF,EAAUC,EAAOqE,GAChCA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAe3C,GAC7C8E,EAAYP,GAAKvE,CACnB,CAEA6D,EAAQjE,GAAK,CAAE0E,WAAUQ,cAAahB,QACxC,CAEA,MAAO,CACLiB,KAAK,EACLpC,gBACAqC,aAAc,MACdnB,UACAK,WAEJ,CAEA,cAAMe,CACJC,EACAC,EACAC,EACAzB,EAAiB,CAAC,GAElB,MAAMiB,EAAI,MACJS,OAAkB5E,IAAV0E,EAERG,SADkB5J,KAAKkI,MAAMD,IACVE,QAAQqB,GACjC,IAAKI,EACH,MAAO,GAET,MAAM,YAAER,EAAc,GAAE,MAAEhB,GAAUwB,EACpC,GAA2B,IAAvBR,EAAYjF,OACd,MAAO,GAET,MAAM0F,OAAY9E,IAAR2E,GAAqBN,EAAYjF,OAAS,GAAK+E,GA3H5CpB,EA2HwD4B,GA1H3D5B,EA0HgEoB,QA3H9E,IAAiBpB,EA4Hb,MAAMR,OAAcvC,IAAV0E,EAAsB,EA/HpC,SAAmB3B,GACjB,OAAOA,EAAKA,EA8H2CoB,KA7HzD,CA6HwCY,CAAUL,GACxCM,EACF,IAAInD,MADO+C,GACAE,EAAIvC,GAAK4B,EACVE,EAAYjF,OAAS,GAC7B6F,EAAYZ,EAAYA,EAAYjF,OAAS,GAAGR,cACtD,GAAIkG,GAAKT,EAAYjF,OAAS,GAAK+E,EACjC,MAAM,IAAIhJ,MAAM,0CAElB,IAAI+J,EAAab,EAAY9B,EAAI4B,GAAGvF,cACpC,IAAK,IAAIO,EAAIoD,EAAI4B,EAAGL,EAAI,EAAG3E,EAAI2F,EAAIX,EAAGhF,IAAK2E,IACzCkB,EAAOlB,GAAK,CACVqB,MAAOd,EAAYlF,EAAI,GAAGP,cAAgBsG,EAC1CR,MAAOvF,EAAIgF,EACXQ,IAAKxF,EAAIgF,EAAIA,GAEfe,EAAab,EAAYlF,EAAI,GAAGP,cAElC,OAAOoG,EAAOI,KAAIC,IAAK,IAClBA,EACHF,MAAQE,EAAEF,QAAS9B,aAAK,EAALA,EAAOjC,YAAa,GAAM6D,KAEjD,CAEA,oBAAMK,CACJrC,EACAhE,EACAsG,EACArC,EAAiB,CAAC,GAEdjE,EAAM,IACRA,EAAM,GAGR,MAAMuG,QAAkBvK,KAAKkI,MAAMD,GACnC,IAAKsC,EACH,MAAO,GAET,MAAMC,EAAKD,EAAUpC,QAAQH,GAC7B,IAAKwC,EACH,MAAO,GAIT,MAAMC,GAnKqBf,EAmKWY,EAjKjC,CACL,CAAC,EAAG,GACJ,CAAC,IAJaI,EAmKmB1G,IA/JpB,IAAK,IAHpB0F,GAAO,IAGyB,KAC9B,CAAC,GAAKgB,GAAO,IAAK,GAAKhB,GAAO,KAC9B,CAAC,IAAMgB,GAAO,IAAK,IAAMhB,GAAO,KAChC,CAAC,KAAOgB,GAAO,IAAK,KAAOhB,GAAO,KAClC,CAAC,MAAQgB,GAAO,IAAK,MAAQhB,GAAO,OARxC,IAAkBgB,EAAahB,EAoK3B,MAAMpE,EAAkB,GAGxB,IAAK,MAAOmE,EAAOC,KAAQe,EACzB,IAAK,IAAI9F,EAAM8E,EAAO9E,GAAO+E,EAAK/E,IAChC,GAAI6F,EAAG5B,SAASjE,GAAM,CACpB,MAAMgG,EAAYH,EAAG5B,SAASjE,GAC9B,IAAK,MAAMiG,KAAYD,EACrBrF,EAAOS,KAAK6E,EAEhB,CAMJ,MAAMC,EAAQL,EAAGpB,YAAYjF,OAC7B,IAAIoB,EACJ,MAAMuF,EAASC,KAAK/G,IAAIA,GAAO,GAAI6G,EAAQ,GACrCG,EAASD,KAAK/G,IAAIsG,GAAO,GAAIO,EAAQ,GAC3C,IAAK,IAAI3G,EAAI4G,EAAQ5G,GAAK8G,IAAU9G,EAAG,CACrC,MAAM+G,EAAKT,EAAGpB,YAAYlF,GACtB+G,KAAQ1F,GAAU0F,EAAGnH,UAAUyB,GAAU,KAC3CA,EAAS0F,EAEb,CAEA,OAAO5F,EAAeC,EAAQC,EAChC,CAEA,WAAM2C,CAAMD,EAAiB,CAAC,GAO5B,OANKjI,KAAKkL,SACRlL,KAAKkL,OAASlL,KAAKqI,OAAOJ,GAAM1F,OAAMsH,IAEpC,MADA7J,KAAKkL,YAASnG,EACR8E,CAAC,KAGJ7J,KAAKkL,MACd,CAEA,eAAMC,CAAU3B,EAAevB,EAAiB,CAAC,G,MAE/C,SAA8B,QAArB,SADYjI,KAAKkI,MAAMD,IAChBE,QAAQqB,UAAM,eAAEZ,SAClC,E,8EC3MF,SAASwC,EAAOC,EAAaC,GAC3B,OAAOP,KAAKQ,MAAMF,EAAM,GAAKC,EAC/B,CAEe,MAAME,UAAY5D,EAAjC,c,oBACU,KAAA6D,aAAe,EACf,KAAAC,MAAQ,EACR,KAAAC,SAAW,CA6MrB,CAzME,eAAMxF,CAAU6B,EAAeC,G,QAE7B,OAAsC,QAA/B,EAAwB,QAAxB,SADiBjI,KAAKkI,MAAMD,IAClBE,QAAQH,UAAM,eAAEI,aAAK,eAAEjC,YAAa,CACvD,CAEA,cAAMoD,GACJ,MAAO,EACT,CAEA,YAAAqC,CAAavH,EAAeC,GAC1B,MAAMuH,EAAcxH,EAAMoE,YAAYnE,GAChCwH,EACU,MAAdD,EAAwB,uBAAyB,iBAC7CE,EACJ,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,OACf,GAAdF,GACF,IAAKE,EACH,MAAM,IAAI7L,MAAM,qCAAqC2L,KAEvD,MAAMG,EAAgB,CACpBC,IAAK5H,EAAMoE,YAAYnE,EAAS,GAChCmF,MAAOpF,EAAMoE,YAAYnE,EAAS,GAClCoF,IAAKrF,EAAMoE,YAAYnE,EAAS,KAE5B4H,EAAY7H,EAAMoE,YAAYnE,EAAS,IACvC6H,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,GACxDI,EAAYjI,EAAMoE,YAAYnE,EAAS,IACvCiI,EAAoBlI,EAAMoE,YAAYnE,EAAS,IAErD,MAAO,CACL0H,gBACAF,iBACAI,YACAC,WACAG,YACAP,SACAF,iBACG1E,EACD9C,EAAMmI,SAASlI,EAAS,GAAIA,EAAS,GAAKiI,GAC1CvM,KAAKqH,cAGX,CAGA,YAAMgB,CAAOJ,GACX,MAAMwE,QAAezM,KAAK6H,WAAWS,SAASL,GACxC5D,QAAc,IAAAqI,OAAMD,GAE1B,IAAIE,EAEJ,GApEe,WAoEXtI,EAAMkE,aAAa,GACrBoE,EAAa,MACR,IArEQ,WAqEJtI,EAAMkE,aAAa,GAG5B,MAAM,IAAIrI,MAAM,kBAFhByM,EAAa,CAIf,CAEA3M,KAAK2L,SAAWtH,EAAMoE,YAAY,GAClCzI,KAAK0L,MAAQrH,EAAMoE,YAAY,GAC/BzI,KAAKyL,eAAiB,GAAyB,GAAlBzL,KAAK0L,MAAQ,IAAW,GAAK,EAC1D,MAAMkB,EAAYvI,EAAMoE,YAAY,IAC9BoE,EAAMD,GAAa,GAAK5M,KAAK4L,aAAavH,EAAO,SAAMU,EACvDyD,EAAWnE,EAAMoE,YAAY,GAAKmE,GAKxC,IACI3F,EADAyB,EAAO,GAAKkE,EAAY,EAE5B,MAAMzE,EAAU,IAAIvB,MAGjB4B,GACH,IAAK,IAAItE,EAAI,EAAGA,EAAIsE,EAAUtE,IAAK,CAEjC,MAAMyE,EAAWtE,EAAMoE,YAAYC,GACnCA,GAAQ,EACR,MAAME,EAAoC,CAAC,EAC3C,IAAIR,EACJ,IAAK,IAAIS,EAAI,EAAGA,EAAIF,EAAUE,IAAK,CACjC,MAAMlE,EAAMN,EAAMkE,aAAaG,GAE/B,GADAA,GAAQ,EACJ/D,EAAM3E,KAAKyL,aACbrD,EAAQlC,EAAe7B,EAAOqE,EAAO,IACrCA,GAAQ,OACH,CACLzB,EAAgBD,EAAcC,EAAe7C,EAAUC,EAAOqE,IAC9DA,GAAQ,EACR,MAAMK,EAAa1E,EAAMoE,YAAYC,GACrCA,GAAQ,EACR,MAAMpD,EAAS,IAAIsB,MAAamC,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACtC,MAAMC,EAAI7E,EAAUC,EAAOqE,GAC3BA,GAAQ,EACR,MAAMQ,EAAI9E,EAAUC,EAAOqE,GAC3BA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAegC,GAC7C3D,EAAO0D,GAAK,IAAIxE,EAAMyE,EAAGC,EAAGvE,EAC9B,CACAiE,EAASjE,GAAOW,CAClB,CACF,CAEA6C,EAAQjE,GAAK,CAAE0E,WAAUR,QAC3B,CAEA,MAAO,CACLuE,aACA1F,gBACAkB,UACAK,WACAsE,KAAK,EACLxD,aAAc,SACXuD,EAEP,CAEA,oBAAMxC,CACJrC,EACAhE,EACAsG,EACArC,EAAiB,CAAC,GAEdjE,EAAM,IACRA,EAAM,GAGR,MAAMuG,QAAkBvK,KAAKkI,MAAMD,GAC7BuC,EAAKD,aAAS,EAATA,EAAWpC,QAAQH,GAC9B,IAAKwC,EACH,MAAO,GAET,MAAMC,EAAkBzK,KAAK+M,SAAS/I,EAAKsG,GAE3C,GAA+B,IAA3BG,EAAgBtG,OAClB,MAAO,GAGT,MAAMmB,EAAS,GAEf,IAAK,MAAOmE,EAAOC,KAAQe,EACzB,IAAK,IAAI9F,EAAM8E,EAAO9E,GAAO+E,EAAK/E,IAChC,GAAI6F,EAAG5B,SAASjE,GAAM,CACpB,MAAMgG,EAAYH,EAAG5B,SAASjE,GAC9B,IAAK,MAAMqI,KAAKrC,EACdrF,EAAOS,KAAKiH,EAEhB,CAIJ,OAAO3H,EAAeC,EAAQ,IAAI5B,EAAc,EAAG,GACrD,CAMA,QAAAqJ,CAASrC,EAAahB,IACpBgB,GAAO,GACG,IACRA,EAAM,GAEJhB,EAAM,GAAK,KACbA,EAAM,GAAK,IAEbA,GAAO,EACP,IAAIuD,EAAI,EACJC,EAAI,EACJ5F,EAAItH,KAAK2L,SAAwB,EAAb3L,KAAK0L,MAC7B,MAAMyB,EAAO,GACb,KAAOF,GAAKjN,KAAK0L,MAAOpE,GAAK,EAAG4F,GAAY,EA3LjC,IA2LwC,EAAJD,GAAQA,GAAK,EAAG,CAC7D,MAAMlJ,EAAImJ,EAAI9B,EAAOV,EAAKpD,GACpBuC,EAAIqD,EAAI9B,EAAO1B,EAAKpC,GAC1B,GAAIuC,EAAI9F,EAAIoJ,EAAKhJ,OAASnE,KAAKyL,aAC7B,MAAM,IAAIvL,MACR,SAASwK,KAAOhB,oDAAsD1J,KAAK2L,mBAAmB3L,KAAK0L,iEAGvGyB,EAAKpH,KAAK,CAAChC,EAAG8F,GAChB,CACA,OAAOsD,CACT,CAEA,WAAMjF,CAAMD,EAAiB,CAAC,GAO5B,OANKjI,KAAKkL,SACRlL,KAAKkL,OAASlL,KAAKqI,OAAOJ,GAAM1F,OAAMsH,IAEpC,MADA7J,KAAKkL,YAASnG,EACR8E,CAAC,KAGJ7J,KAAKkL,MACd,CAEA,eAAMC,CAAU3B,EAAevB,EAAiB,CAAC,G,MAE/C,SAA8B,QAArB,SADYjI,KAAKkI,MAAMD,IAChBE,QAAQqB,UAAM,eAAEZ,SAClC,ECtOF,MCEMwE,EAAiB,mBAAmBC,MAAM,IAC1CC,EAAgB,mBAAmBD,MAAM,IAKhC,MAAME,EAUnB,WAAAtM,CAAYgD,GATJ,KAAAlC,KAAO,CAAC,EAIR,KAAAyL,SAAqB,GACrB,KAAAC,gBAAiB,EAKvB,MAAM,MAAEpJ,EAAK,WAAEqJ,GAAezJ,GACxB,UAAE0J,EAAS,MAAElE,GAAUpF,EAC7BrE,KAAK+B,KAAO,CAAE0H,MAAOkE,EAAUlF,YAAYgB,EAAQ,IACnDzJ,KAAKqE,MAAQA,EACbrE,KAAK4N,IAAMF,EACX1N,KAAK6N,OAASF,EAAUlF,YAAYgB,EAAQ,GAC5CzJ,KAAK8N,OAA6C,WAApCH,EAAUlF,YAAYgB,EAAQ,MAAqB,EACnE,CAEA,GAAApI,CAAI0M,GAEF,OAAI/N,KAAK+N,IAEH/N,KAAK+B,KAAKgM,KAId/N,KAAK+B,KAAKgM,GAAS/N,KAAK+N,MAHf/N,KAAK+B,KAAKgM,IAMd/N,KAAKgO,KAAKD,EAAME,cACzB,CAEA,GAAAvE,GACE,OAAO1J,KAAKqB,IAAI,SAAWrB,KAAKqB,IAAI,gBACtC,CAEA,MAAA6M,GACE,OAAOlO,KAAK6N,MACd,CAIA,IAAAG,CAAKD,GACH,OAAIA,KAAS/N,KAAK+B,OAGlB/B,KAAK+B,KAAKgM,GAAS/N,KAAKmO,UAAUJ,IAFzB/N,KAAK+B,KAAKgM,EAIrB,CAEA,KAAAK,GACEpO,KAAKqO,gBAEL,IAAIC,EAAO,CAAC,OAEPtO,KAAKuO,qBACRD,EAAKvI,KACH,QACA,MACA,SACA,QACA,OACA,KACA,QACA,gBACA,mBAGA/F,KAAKwO,YACPF,EAAKvI,KAAK,wBAAyB,oBAErCuI,EAAOA,EAAKG,OAAOzO,KAAKwN,UAAY,IAEpC,IAAK,MAAMxE,KAAKpG,OAAOS,KAAKrD,KAAK+B,MAC1BiH,EAAE0F,WAAW,MAAc,gBAAN1F,GACxBsF,EAAKvI,KAAKiD,GAId,MAAM2F,EAAgC,CAAC,EACvC,OAAOL,EAAKM,QAAO1B,IACjB,GACGA,KAAKlN,KAAK+B,WAAyBgD,IAAjB/E,KAAK+B,KAAKmL,IACvB,OAANA,GACM,OAANA,EAEA,OAAO,EAGT,MAAM2B,EAAK3B,EAAEe,cACP3G,EAAIqH,EAAKE,GAEf,OADAF,EAAKE,IAAM,GACHvH,CAAC,GAEb,CAEA,MAAAwH,GAEA,CAEA,QAAAC,GACE,OAAO/O,KAAKqB,IAAI,cAClB,CAEA,EAAA2N,GACE,OAAOhP,KAAK4N,GACd,CAMA,EAAAqB,GACE,MAAMA,GAA+B,MAAzBjP,KAAKqB,IAAI,gBAA2B,EAChD,OAAc,MAAP4N,OAAalK,EAAYkK,CAClC,CAEA,KAAA/E,GACE,OAAOlK,KAAKqB,IAAI,KAClB,CAEA,IAAA6N,G,MACE,OAAqB,QAAd,EAAAlP,KAAKmP,iBAAS,eAAEC,KAAK,IAC9B,CAEA,OAAAD,GACE,GAAInP,KAAKuO,oBACP,OAGF,MAAM,MAAE9E,EAAK,UAAEkE,GAAc3N,KAAKqE,MAC5BgL,EACJ5F,EACA,GACAzJ,KAAKqB,IAAI,gBACiB,EAA1BrB,KAAKqB,IAAI,eACTrB,KAAKqB,IAAI,cACLiO,EAAOtP,KAAKqB,IAAI,cACtB,OAAOsM,EAAUnB,SAAS6C,EAAGA,EAAIC,EACnC,CAEA,MAAAC,GACE,OAAOvP,KAAKwP,yBAA2B,EAAI,CAC7C,CAEA,iCAAAC,GACE,IAAIzP,KAAK0P,iBAGT,OAAO1P,KAAK2P,6BAA+B,EAAI,CACjD,CAEA,IAAAjO,GACE,OAAO1B,KAAKqB,IAAI,aAClB,CAEA,UAAAuO,GACE,MAAMC,EAAK7P,KAAKqB,IAAI,iBACd,UAAEsM,EAAS,MAAElE,GAAUzJ,KAAKqE,MAClC,OAAOsJ,EAAU9J,SAAS,QAAS4F,EAAQ,GAAIA,EAAQ,GAAKoG,EAAK,EACnE,CAMA,SAAA1B,CAAU2B,GAIR,GAAI9P,KAAKyN,eACP,OAGF,MAAM,UAAEE,EAAS,MAAElE,GAAUzJ,KAAKqE,MAClC,IAAIgL,EACFrP,KAAK+P,YACLtG,EACE,GACAzJ,KAAKqB,IAAI,gBACiB,EAA1BrB,KAAKqB,IAAI,eACTrB,KAAKqB,IAAI,cACTrB,KAAKqB,IAAI,cAEb,MAAM2O,EAAWhQ,KAAKqE,MAAMqF,IAC5B,IAAIuG,EACJ,KAAOZ,EAAIW,GAAYC,IAAUH,GAAS,CACxC,MAAMI,EAAM9D,OAAOC,aAAasB,EAAU0B,GAAI1B,EAAU0B,EAAI,IAC5DY,EAAQC,EAAIjC,cACZ,MAAMkC,EAAO/D,OAAOC,aAAasB,EAAU0B,EAAI,IAG/C,IAAI5L,EACJ,OAHA4L,GAAK,EAGGc,GACN,IAAK,IACH1M,EAAQ2I,OAAOC,aAAasB,EAAU0B,IACtCA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAUlF,YAAY4G,GAC9BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAUpF,aAAa8G,GAC/BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAUyC,SAASf,GAC3BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAU0C,UAAUhB,GAC5BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAU2C,YAAYjB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAU4C,aAAalB,GAC/BA,GAAK,EACL,MAEF,IAAK,IACH5L,EAAQkK,EAAU6C,YAAYnB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACL,IAAK,IAEH,IADA5L,EAAQ,GACD4L,GAAKW,GAAU,CACpB,MAAMS,EAAK9C,EAAU0B,KACrB,GAAW,IAAPoB,EACF,MAEAhN,GAAS2I,OAAOC,aAAaoE,EAEjC,CACA,MAEF,IAAK,IAAK,CACRhN,EAAQ,GACR,MAAMgN,EAAK9C,EAAU0B,KACfqB,EAAQtE,OAAOC,aAAaoE,GAC5BE,EAAQhD,EAAUlF,YAAY4G,GAEpC,GADAA,GAAK,EACS,MAAVqB,EACF,GAAY,OAARR,EACF,IAAK,IAAIlH,EAAI,EAAGA,EAAI2H,EAAO3H,IAAK,CAC9B,MAAM4H,EAAQjD,EAAUlF,YAAY4G,GAGpC5L,IAFYmN,GAAS,GACVtD,EAAsB,GAARsD,GAEzBvB,GAAK,CACP,MAEA,IAAK,IAAIrG,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAUlF,YAAY4G,GAC3BrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAIX,GAAc,MAAVqB,EACF,GAAY,OAARR,EACF,IAAK,IAAIlH,EAAI,EAAGA,EAAI2H,EAAO3H,IAAK,CAC9B,MAAM4H,EAAQjD,EAAUpF,aAAa8G,GAGrC5L,IAFYmN,GAAS,GACVtD,EAAsB,GAARsD,GAEzBvB,GAAK,CACP,MAEA,IAAK,IAAIrG,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAUpF,aAAa8G,GAC5BrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAIX,GAAc,MAAVqB,EACF,IAAK,IAAI1H,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAU2C,YAAYjB,GAC3BrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAGT,GAAc,MAAVqB,EACF,IAAK,IAAI1H,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAU4C,aAAalB,GAC5BrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAGT,GAAc,MAAVqB,EACF,IAAK,IAAI1H,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAUyC,SAASf,GACxBrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAGT,GAAc,MAAVqB,EACF,IAAK,IAAI1H,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAU0C,UAAUhB,GACzBrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAGT,GAAc,MAAVqB,EACF,IAAK,IAAI1H,EAAI,EAAGA,EAAI2H,EAAO3H,IACzBvF,GAASkK,EAAU6C,YAAYnB,GAC3BrG,EAAI,EAAI2H,IACVlN,GAAS,KAEX4L,GAAK,EAGT,KACF,CACA,QACE5M,QAAQoO,KAAK,yBAAyBV,8BACtC1M,OAAQsB,EACRsK,EAAIW,EAOR,GAHAhQ,KAAK+P,WAAaV,EAElBrP,KAAKwN,SAASzH,KAAKmK,GACfD,IAAUH,EACZ,OAAOrM,EAGTzD,KAAK+B,KAAKkO,GAASxM,CACrB,CACAzD,KAAKyN,gBAAiB,CAExB,CAEA,aAAAY,GACErO,KAAKmO,UAAU,GACjB,CAEA,WAAA2C,CAAYC,GACV,OAEEA,EACGC,MAAM,UAEN7G,KAAI8G,GAAM,CAAC,KAAKC,KAAKD,GAAI,GAAGE,cAAe7K,OAAO8K,SAASH,EAAI,MAEtE,CAMA,QAAAzC,GACE,SDjYW,ECiYDxO,KAAK8N,MACjB,CAGA,gBAAAuD,GACE,SDpYgB,ECoYNrR,KAAK8N,MACjB,CAGA,iBAAAS,GACE,SDvYU,ECuYAvO,KAAK8N,MACjB,CAGA,cAAA4B,GACE,SD1YW,EC0YD1P,KAAK8N,MACjB,CAGA,qBAAA0B,GACE,SD7YY,GC6YFxP,KAAK8N,MACjB,CAGA,yBAAA6B,GACE,SDhZa,GCgZH3P,KAAK8N,MACjB,CAGA,OAAAwD,GACE,SDnZU,GCmZAtR,KAAK8N,MACjB,CAGA,OAAAyD,GACE,SDtZU,ICsZAvR,KAAK8N,MACjB,CAGA,WAAA0D,GACE,SDzZc,ICyZJxR,KAAK8N,MACjB,CAGA,UAAA2D,GACE,SD5ZW,IC4ZDzR,KAAK8N,MACjB,CAGA,WAAA4D,GACE,SD/ZQ,KC+ZE1R,KAAK8N,MACjB,CAGA,eAAA6D,GACE,SDlakB,KCkaR3R,KAAK8N,MACjB,CAEA,KAAAiD,GACE,GAAI/Q,KAAKuO,oBACP,OAGF,MAAM,UAAEZ,EAAS,MAAElE,GAAUzJ,KAAKqE,MAC5BuN,EAAc5R,KAAKqB,IAAI,eAC7B,IAAIgO,EAAI5F,EAAQ,GAAKzJ,KAAKqB,IAAI,gBAC9B,MAAMwQ,EAAS7R,KAAKqB,IAAI,cACxB,IAAI0P,EAAQ,GACRe,EAAO,EAIPlB,EAAQjD,EAAUlF,YAAY4G,GAC9B0C,EAAMnB,GAAS,EACfK,EAAK3D,EAAsB,GAARsD,GACvB,GAAW,MAAPK,GAAcc,IAAQF,EAWxB,OARAxC,GAAK,EACLuB,EAAQjD,EAAUlF,YAAY4G,GAC9B0C,EAAMnB,GAAS,EACfK,EAAK3D,EAAsB,GAARsD,GACR,MAAPK,GACFxO,QAAQoO,KAAK,wBAEf7Q,KAAK+B,KAAKiQ,cAAgBD,EACnB/R,KAAKqB,IAAI,MAEhB,IAAK,IAAI2L,EAAI,EAAGA,EAAI4E,IAAe5E,EACjC4D,EAAQjD,EAAUlF,YAAY4G,GAC9B0C,EAAMnB,GAAS,EACfK,EAAK3D,EAAsB,GAARsD,GACnBG,GAASgB,EAAMd,EAIJ,MAAPA,GAAqB,MAAPA,GAAqB,MAAPA,IAC9Ba,GAAQC,GAGV1C,GAAK,EAIP,OADArP,KAAK+B,KAAKiQ,cAAgBF,EACnBf,CAEX,CAEA,aAAAiB,GACE,OAAIhS,KAAK+B,KAAKiQ,eAGZhS,KAAKqB,IAAI,SAFFrB,KAAK+B,KAAKiQ,aAKrB,CAEA,WAAAC,GACE,OAA8B,MAAvBjS,KAAKqB,IAAI,WAClB,CAEA,YAAA6Q,GACE,OAAgC,IAAzBlS,KAAKqB,IAAI,aAClB,CAKA,UAAA8Q,GACE,OAAQnS,KAAKqB,IAAI,cAAgB,GAAM,CACzC,CAEA,YAAA+Q,GACE,OAAOpS,KAAKqS,KACd,CAEA,GAAAA,GACE,MAAM,UAAE1E,EAAS,MAAElE,GAAUzJ,KAAKqE,MAC5BgL,EACJ5F,EAAQ,GAAKzJ,KAAKqB,IAAI,gBAA4C,EAA1BrB,KAAKqB,IAAI,eAC7CiR,EAAWtS,KAAKqB,IAAI,cACpBkR,EAAMvS,KAAKqB,IAAI,cACrB,IAAImR,EAAM,GACNtO,EAAI,EACR,IAAK,IAAI2E,EAAI,EAAGA,EAAIyJ,IAAYzJ,EAAG,CACjC,MAAM4J,EAAK9E,EAAU0B,EAAIxG,GACzB2J,GAAOpF,GAAqB,IAALqF,IAAc,GACrCvO,IACIA,EAAIqO,IACNC,GAAOpF,EAAoB,GAALqF,GACtBvO,IAEJ,CACA,OAAOsO,CACT,CAGA,kBAAAE,GACE,IACG1S,KAAKuO,sBACLvO,KAAK0P,kBACN1P,KAAK6N,SAAW7N,KAAK2S,cACrB,CACA,MAAMC,EAAK5S,KAAKwP,wBAA0B,IAAM,IAC1CqD,EAAK7S,KAAK2P,4BAA8B,IAAM,IACpD,IAAImD,EAAK,IACLC,EAAK,IACL/S,KAAKsR,WACPwB,EAAK,IACLC,EAAK,KACI/S,KAAKuR,YACduB,EAAK,IACLC,EAAK,KAGP,MAAMC,EAAM,GAaZ,OAZchT,KAAKiT,kBACP,GACVD,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,IAETC,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,GAEJC,EAAI5D,KAAK,GAClB,CACA,MAAO,EACT,CAEA,UAAA8D,GACE,OAAOlT,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,QAAA0J,GACE,OAAOnT,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,UAAA2J,GACE,OAAOpT,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,WAAAkJ,GACE,OAAO3S,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,SAAA4J,GACE,OAAOrT,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,eAAAwJ,GACE,OAAOjT,KAAKqE,MAAMsJ,UAAUlF,YAAYzI,KAAKqE,MAAMoF,MAAQ,GAC7D,CAEA,MAAA6J,GACE,MAAMvR,EAA4B,CAAC,EACnC,IAAK,MAAMiH,KAAKpG,OAAOS,KAAKrD,MACtBgJ,EAAE0F,WAAW,MAAc,UAAN1F,IAIzBjH,EAAKiH,GAAKhJ,KAAKgJ,IAGjB,OAAOjH,CACT,ECvmBK,SAASwR,EAAgBC,GAC9B,MAAMC,EAAQD,EAAKnG,MAAM,SACnBtL,EAAkE,GACxE,IAAK,MAAM2R,KAAQD,EAAO,CACxB,MAAOvD,KAAQyD,GAAUD,EAAKrG,MAAM,MAChC6C,GACFnO,EAAKgE,KAAK,CACRmK,IAAKA,EAAIpJ,MAAM,GACf/E,KAAM4R,EAAOxJ,KAAIyJ,IACf,MAAMC,EAAID,EAAEE,QAAQ,KAGpB,MAAO,CAAE5D,IAFQ0D,EAAE9M,MAAM,EAAG+M,GAEJpQ,MADVmQ,EAAE9M,MAAM+M,EAAI,GACK,KAIvC,CACA,OAAO9R,CACT,CCHO,MAAMgS,EAAY,SAiBzB,MAAMC,EACG,IAAAC,GACL,MAAM,IAAI/T,MAAM,eAClB,CACO,IAAAgU,GACL,MAAM,IAAIhU,MAAM,eAClB,CAEO,QAAAoI,GACL,MAAM,IAAIpI,MAAM,eAClB,CAEO,KAAAiU,GACL,MAAM,IAAIjU,MAAM,eAClB,EAEa,MAAMkU,EAyBnB,WAAAnT,EAAY,cACVoT,EAAa,QACbC,EAAO,OACPC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,OACNC,EAAM,gBACNC,EAAkB,IAAG,cACrBC,EAAgBlN,GAAKA,IAiBrB,GA9CK,KAAAgN,QAAS,EAGR,KAAAG,aAAe,IAAIjU,EAAAkU,EAA0C,CACnE/T,MAAO,IAAI,IAAJ,CAAa,CAClBgU,QAAS,KAEXjU,KAAMkU,MAAOnR,EAAYlE,KACvB,MAAM,MAAE+F,EAAK,KAAEmC,GAAShE,GAClB,KAAElC,EAAI,WAAEsT,EAAU,WAAEC,SAAqBtV,KAAKuV,WAAW,CAC7DzP,QACAmC,KAAM,IAAKA,EAAMlI,YAEnB,OAAOC,KAAKwV,gBAAgBzT,EAAMsT,EAAYC,EAAYxP,EAAM,IA+BlE9F,KAAKqH,aAAe2N,EAEhBX,EACFrU,KAAKyV,IAAMpB,OACN,GAAIC,EACTtU,KAAKyV,IAAM,IAAI,KAAUnB,QACpB,GAAIC,EACTvU,KAAKyV,IAAM,IAAI,KAAWlB,OACrB,KAAIO,EAIT,MAAM,IAAI5U,MAAM,4BAHhBF,KAAK8U,QAAS,EACd9U,KAAKyV,IAAM,IAAIzB,CAGjB,CACA,GAAIY,EACF5U,KAAK0V,MAAQ,IAAIlK,EAAI,CAAE3D,WAAY+M,SAC9B,GAAID,EACT3U,KAAK0V,MAAQ,IAAIlK,EAAI,CAAE3D,WAAY,IAAI,KAAU8M,UAC5C,GAAIE,EACT7U,KAAK0V,MAAQ,IAAIlK,EAAI,CAAE3D,WAAY,IAAI,KAAWgN,UAC7C,GAAIJ,EACTzU,KAAK0V,MAAQ,IAAI3N,EAAI,CAAEF,WAAY4M,SAC9B,GAAID,EACTxU,KAAK0V,MAAQ,IAAI3N,EAAI,CAAEF,WAAY,IAAI,KAAU2M,UAC5C,GAAIE,EACT1U,KAAK0V,MAAQ,IAAI3N,EAAI,CAAEF,WAAY,IAAI,KAAW6M,UAC7C,GAAIJ,EACTtU,KAAK0V,MAAQ,IAAI3N,EAAI,CAAEF,WAAY,IAAI,KAAU,GAAGyM,gBAC/C,GAAIC,EACTvU,KAAK0V,MAAQ,IAAI3N,EAAI,CAAEF,WAAY,IAAI,KAAW,GAAG0M,eAChD,KAAIO,EAGT,MAAM,IAAI5U,MAAM,gCAFhBF,KAAK8U,QAAS,CAGhB,CACA9U,KAAK+U,gBAAkBA,CACzB,CAEA,kBAAMY,CAAaC,GACjB,MAAM3N,EP/DH,SAAkB4N,EAA8B,CAAC,GACtD,MAAO,YAAaA,EAAO,CAAE9V,OAAQ8V,GAAqBA,CAC5D,CO6DiBC,CAASF,GACtB,IAAK5V,KAAK0V,MACR,OAEF,MAAMnL,QAAkBvK,KAAK0V,MAAMxN,MAAMD,GACnC8N,EAAMxL,EAAUtD,cAClBsD,EAAUtD,cAActD,cAAgB,WACxCoB,EACJ,IAAI0H,EACJ,GAAIsJ,EAAK,CACP,MAAMzO,EAAIyO,EApIC,MAqILC,QAAYhW,KAAKyV,IAAIxB,KAAK,EAAAgC,OAAOC,MAAM5O,GAAI,EAAGA,EAAG,EAAGW,GAC1D,IAAK+N,EAAIG,UACP,MAAM,IAAIjW,MAAM,wBAElBuM,EAASuJ,EAAIvJ,OAAOD,SAAS,EAAGzB,KAAK/G,IAAIgS,EAAIG,UAAWJ,GAC1D,MACEtJ,QAAezM,KAAKyV,IAAInN,SAASL,GAGnC,MAAMmO,QAAc,IAAA1J,OAAMD,GAE1B,GAAI2J,EAAM3N,YAAY,KAAOsL,EAC3B,MAAM,IAAI7T,MAAM,kBAElB,MAAMmW,EAAUD,EAAM3N,YAAY,GAElCzI,KAAKsW,OAASF,EAAMvS,SAAS,OAAQ,EAAG,EAAIwS,GAC5C,MAAM,WAAEE,EAAU,WAAEC,SAAqBxW,KAAKyW,aAC5CJ,EAAU,EACV,MACApO,GAKF,OAHAjI,KAAKuW,WAAaA,EAClBvW,KAAKwW,WAAaA,EAEXjD,EAAgBvT,KAAKsW,OAC9B,CAEA,SAAAI,CAAUzO,GAOR,OANKjI,KAAK2W,UACR3W,KAAK2W,QAAU3W,KAAK2V,aAAa1N,GAAM1F,OAAMsH,IAE3C,MADA7J,KAAK2W,aAAU5R,EACT8E,CAAC,KAGJ7J,KAAK2W,OACd,CAEA,mBAAMC,CAAc3O,EAAiB,CAAC,GAEpC,aADMjI,KAAK0W,UAAUzO,GACdjI,KAAKsW,MACd,CAIA,kBAAMG,CACJhN,EACAoN,EACA5O,GAKA,GAAIwB,EAAQoN,EACV,OAAO7W,KAAKyW,aAAahN,EAAqB,EAAdoN,EAAiB5O,GAEnD,MAAM1H,EAAOsW,EA7LA,OA8LP,UAAEV,EAAS,OAAE1J,SAAiBzM,KAAKyV,IAAIxB,KAC3C,EAAAgC,OAAOC,MAAM3V,GACb,EACAsW,EACA,EACA5O,GAEF,IAAKkO,EACH,MAAM,IAAIjW,MAAM,qCAElB,MAAMkW,QAAc,IAAA1J,OAClBD,EAAOD,SAAS,EAAGzB,KAAK/G,IAAImS,EAAWU,KAEnCC,EAAOV,EAAM3N,YAAYgB,GAC/B,IAAI4F,EAAI5F,EAAQ,EAChB,MAAM8M,EAAqC,CAAC,EACtCC,EAAoD,GAC1D,IAAK,IAAItS,EAAI,EAAGA,EAAI4S,EAAM5S,GAAK,EAAG,CAChC,MAAM6S,EAAQX,EAAM3N,YAAY4G,GAC1B1H,EAAU3H,KAAKqH,aACnB+O,EAAMvS,SAAS,OAAQwL,EAAI,EAAGA,EAAI,EAAI0H,EAAQ,IAE1CC,EAAOZ,EAAM3N,YAAY4G,EAAI0H,EAAQ,GAM3C,GAJAR,EAAW5O,GAAWzD,EACtBsS,EAAWzQ,KAAK,CAAE4B,UAASxD,OAAQ6S,IAEnC3H,EAAIA,EAAI,EAAI0H,EACR1H,EAAI+G,EAAMjS,OAIZ,OAHA1B,QAAQoO,KACN,wCAAwCgG,YAEnC7W,KAAKyW,aAAahN,EAAqB,EAAdoN,EAAiB5O,EAErD,CACA,MAAO,CAAEsO,aAAYC,aACvB,CAEA,wBAAMS,CACJC,EACAlT,EACAsG,EACArC,GAEA,OAxOJmN,eAA4B+B,GAC1B,IAAIC,EAAW,GACf,UAAW,MAAMC,KAAKF,EACpBC,EAAMA,EAAI3I,OAAO4I,GAEnB,OAAOD,CACT,CAkOWE,CAAUtX,KAAKuX,sBAAsBL,EAAKlT,EAAKsG,EAAKrC,GAC7D,CAEA,2BAAOsP,CACLL,EACAlT,EACAsG,EACArC,G,YAEMjI,KAAK0W,UAAUzO,GACrB,MAAMuP,EAAuB,QAAf,EAAAxX,KAAKuW,kBAAU,eAAGW,GAChC,QAAcnS,IAAVyS,GAAwBxX,KAAK0V,MAE1B,CACL,MAAMpQ,QAAetF,KAAK0V,MAAMrL,eAAemN,EAAOxT,EAAM,EAAGsG,EAAKrC,SAC7DjI,KAAKyX,oBAAoBnS,EAAQkS,EAAOxT,EAAKsG,EAAKrC,EAC3D,WAJQ,EAKV,CAEA,yBAAOwP,CACLnS,EACAkS,EACAxT,EACAsG,EACArC,EAAgB,CAAC,GAEjB,MAAM,YAAEyP,GAAgBzP,EAClB0P,EAAQ,GACd,IAAInU,GAAO,EAEX,IAAK,MAAMsC,KAASR,EAAQ,CAC1B,MAAMsS,QAAgB5X,KAAKiV,aAAa5T,IACtCyE,EAAMjC,WACN,CAAEiC,QAAOmC,QACTA,EAAKlI,QAGD8X,EAAO,GACb,IAAK,MAAMC,KAAWF,EACpB,GAAIE,EAAQ5J,WAAasJ,EAAO,CAC9B,GAAIM,EAAQzW,IAAI,UAAYiJ,EAAK,CAE/B9G,GAAO,EACP,KACF,CAAWsU,EAAQzW,IAAI,QAAU2C,GAE/B6T,EAAK9R,KAAK+R,EAEd,CAIF,GAFAH,EAAM5R,KAAK8R,SACLA,EACFrU,EACF,KAEJ,EPrRG,SAA0BzD,GAC/B,GAAKA,GAIDA,EAAOE,QAAS,CAElB,GAA4B,oBAAjB8X,aAA8B,CACvC,MAAMlO,EAAI,IAAI3J,MAAM,WAGpB,MADA2J,EAAElI,KAAO,cACHkI,CACR,CACE,MAAM,IAAIkO,aAAa,UAAW,aAEtC,CACF,EOuQIC,CAAiB/P,EAAKlI,QAClB2X,UACI1X,KAAKiY,WAAWT,EAAOG,EAAO1P,GAExC,CAEA,gBAAMgQ,CAAWT,EAAeG,EAAuB1P,GACrD,MAAM,cAAEiQ,EAAa,cAAEC,EAAgB,KAAWlQ,EAC5CmQ,EAAwC,CAAC,EACzCC,EAAkC,CAAC,EACzCV,EAAMxN,KAAI4L,IACR,MAAMuC,EAAoC,CAAC,EAC3C,IAAK,MAAMC,KAAWxC,EAAK,CACzB,MAAMrU,EAAO6W,EAAQ7W,OACfsN,EAAKuJ,EAAQvJ,KACdsJ,EAAU5W,KACb4W,EAAU5W,GAAQ,GAEpB4W,EAAU5W,KACV2W,EAAQrJ,GAAM,CAChB,CACA,IAAK,MAAOhG,EAAGE,KAAMtG,OAAO4V,QAAQF,GACxB,IAANpP,IACFkP,EAAapP,IAAK,EAEtB,IAGF,MAAMyP,EAAmC,GACzCd,EAAMxN,KAAI4L,IACR,IAAK,MAAMnC,KAAKmC,EAAK,CACnB,MAAMrU,EAAOkS,EAAElS,OACT+H,EAAQmK,EAAEvS,IAAI,SACdqX,EAAQ9E,EAAEP,YACVsF,EAAQ/E,EAAEjB,cAEd3S,KAAK0V,OACL0C,EAAa1W,KACZwW,GACES,IAAUnB,GAASzM,KAAK6N,IAAInP,EAAQiP,GAASP,IAEhDM,EAAa1S,KACX/F,KAAK0V,MAAMrL,eAAesO,EAAOD,EAAOA,EAAQ,EAAGzQ,GAGzD,KAKF,MAAMkC,EAAM,IAAI0O,IACV7C,QAAY9Q,QAAQ4T,IAAIL,GAC9B,IAAK,MAAMM,KAAK/C,EAAIgD,OACb7O,EAAIpH,IAAIgW,EAAElV,aACbsG,EAAI7I,IAAIyX,EAAElV,WAAYkV,GAwB1B,aApB+B7T,QAAQ4T,IACrC,IAAI3O,EAAI8O,UAAU9O,KAAIiL,MAAMpI,IAC1B,MAAM,KAAEjL,EAAI,WAAEsT,EAAU,WAAEC,EAAU,MAAExP,SAAgB9F,KAAKuV,WAAW,CACpEzP,MAAOkH,EACP/E,SAEIiR,EAAW,GACjB,IAAK,MAAMpB,WAAiB9X,KAAKwV,gBAC/BzT,EACAsT,EACAC,EACAxP,GAEIsS,EAAaN,EAAQzW,IAAI,WAAagX,EAAQP,EAAQ9I,OACxDkK,EAASnT,KAAK+R,GAGlB,OAAOoB,CAAQ,MAGKF,MAC1B,CAEA,iBAAMG,CAAYC,EAAkB7Y,EAAc0H,EAAiB,CAAC,GAClE,MAAM,UAAEkO,EAAS,OAAE1J,SAAiBzM,KAAKyV,IAAIxB,KAC3C,EAAAgC,OAAOC,MAAM3V,GACb,EACAA,EACA6Y,EACAnR,GAGF,OAAOwE,EAAOD,SAAS,EAAGzB,KAAK/G,IAAImS,EAAW5V,GAChD,CAEA,gBAAMgV,EAAW,MAAEzP,EAAK,KAAEmC,IACxB,MAAMwE,QAAezM,KAAKmZ,YACxBrT,EAAMrB,KAAKd,cACXmC,EAAMhB,cACNmD,IAIAwE,OAAQ1K,EAAI,WACZsT,EAAU,WACVC,SACQ,QAAgB7I,EAAQ3G,GAClC,MAAO,CAAE/D,OAAMsT,aAAYC,aAAYxP,QACzC,CAEA,qBAAM0P,CACJhL,EACA6K,EACAC,EACAxP,GAEA,IAAIuT,EAAa,EACjB,MAAMC,EAAO,GACb,IAAIC,EAAM,EACNC,GAAQC,KAAKC,MAEjB,KAAOL,EAAa,EAAI7O,EAAGrG,QAAQ,CACjC,MACM6L,EAAWqJ,EAAa,EADZ7O,EAAG/B,YAAY4Q,GACa,EAG9C,GAAI/D,EAAY,CACd,KAAO+D,EAAavT,EAAMrB,KAAKb,cAAgB0R,EAAWiE,OAC1DA,GACF,CAGA,GAAIvJ,EAAWxF,EAAGrG,OAAQ,CACxB,MAAM2T,EAAU,IAAI,EAAW,CAC7BzT,MAAO,CACLsJ,UAAWnD,EACXf,MAAO4P,EACP3P,IAAKsG,GAsBPtC,WACE2H,EAAWlR,OAAS,EACE,IAAlBkR,EAAWkE,IACVF,EAAa/D,EAAWiE,IACzBzT,EAAMrB,KAAKb,aACX,EAEA+V,EAAA,EAAMC,OAAOpP,EAAG1D,MAAMuS,EAAYrJ,MAG1CsJ,EAAKvT,KAAK+R,GACN9X,KAAK+U,kBAAoB0E,KAAKC,MAAQF,EAAOxZ,KAAK+U,wBAC9C/P,EAAQ,GACdwU,GAAQC,KAAKC,MAEjB,CAEAL,EAAarJ,EAAW,CAC1B,CACA,OAAOsJ,CACT,CAEA,eAAMnO,CAAU0O,G,QACd,MAAMrQ,EAAuB,QAAf,EAAAxJ,KAAKuW,kBAAU,eAAGsD,GAChC,YAAiB9U,IAAVyE,IAAwC,QAAV,EAAAxJ,KAAK0V,aAAK,eAAEvK,UAAU3B,GAC7D,CAEA,eAAMrD,CAAU0T,G,MACd,MAAMrQ,EAAuB,QAAf,EAAAxJ,KAAKuW,kBAAU,eAAGsD,GAChC,YAAiB9U,IAAVyE,GAAwBxJ,KAAK0V,MAAY1V,KAAK0V,MAAMvP,UAAUqD,GAAzB,CAC9C,CAEA,cAAMD,CAASsQ,EAAiBpQ,EAAgBC,G,MAC9C,IAAK1J,KAAK0V,MACR,MAAO,SAEH1V,KAAK0V,MAAMxN,QACjB,MAAMsB,EAAuB,QAAf,EAAAxJ,KAAKuW,kBAAU,eAAGsD,GAChC,YAAiB9U,IAAVyE,EAAsB,GAAKxJ,KAAK0V,MAAMnM,SAASC,EAAOC,EAAOC,EACtE,CAEA,oBAAMW,CACJwP,EACApQ,EACAC,EACAzB,G,MAEA,IAAKjI,KAAK0V,MACR,MAAO,SAEH1V,KAAK0V,MAAMxN,QACjB,MAAMsB,EAAuB,QAAf,EAAAxJ,KAAKuW,kBAAU,eAAGsD,GAChC,YAAiB9U,IAAVyE,EACH,GACAxJ,KAAK0V,MAAMrL,eAAeb,EAAOC,EAAOC,EAAKzB,EACnD,EC7fFmN,eAAe3G,EAAOqL,EAAoB7R,GACxC,MAAM+N,QAAY9Q,QAAQ4T,IACxBgB,EAAI3P,KAAIiL,MAAMtP,IACZ,MAAM,IAAEiU,EAAG,QAAEC,GAAYlU,EACzB,GAAIiU,EAAIrL,WAAW,SACjB,OAAO,EAAAuH,OAAOgE,KAAKF,EAAI1M,MAAM,KAAK,GAAI,UACjC,CAIL,MAAM,QAAE6M,KAAYC,GAASH,EACvBhE,QAAYoE,MAAML,EAAK,IACxB9R,EACH+R,QAAS,IAAK/R,aAAI,EAAJA,EAAM+R,WAAYG,KAElC,IAAKnE,EAAIqE,GACP,MAAM,IAAIna,MACR,QAAQ8V,EAAIsE,mBAAmBP,YAAc/D,EAAIxC,UAGrD,OAAO,EAAAyC,OAAOgE,WAAWjE,EAAIuE,cAC/B,MAIJ,OAAO,EAAAtE,OAAOxH,aAAavJ,QAAQ4T,IAAI9C,EAAI7L,KAAIpJ,IAAO,IAAA2L,OAAM3L,MAC9D,CAEe,MAAMyZ,UAAmBpG,EAKtC,WAAAnT,CAAYgD,GACVwW,MAAM,CAAE3F,QAAQ,IAChB9U,KAAK0a,QAAUzW,EAAKyW,QACpB1a,KAAK2a,QAAU1W,EAAK0W,OACtB,CAEA,2BAAOpD,CACLL,EACAlT,EACAsG,EACArC,G,MAEA,MACM8R,EAAM,GADI/Z,KAAK0a,WAAW1a,KAAK2a,yBACAzD,WAAalT,SAAWsG,eACvDkN,EAAuB,QAAf,EAAAxX,KAAKuW,kBAAU,eAAGW,GAChC,QAAcnS,IAAVyS,OACI,OACD,CACL,MAAM1U,QAAesX,MAAML,EAAK,IAAK9R,IACrC,IAAKnF,EAAOuX,GACV,MAAM,IAAIna,MACR,QAAQ4C,EAAOwX,mBAAmBP,YAAcjX,EAAO0Q,UAG3D,MAAMzR,QAAae,EAAO8X,OACpBxE,QAAc3H,EAAO1M,EAAK+S,OAAO+F,KAAK/T,MAAM,GAAImB,SAE/CjI,KAAKyX,oBACV,CAEE,CACEhL,OAAQ2J,EACRxR,kBAAcG,EACdJ,IAAK,EACLb,UAAS,IACA,EAETe,eAAc,IACL,GAAGqS,KAAOlT,KAAOsG,IAE1BxF,YAAW,IACF,EAETL,KAAM,CACJb,aAAc,EACdD,cAAe,EACfG,UAAW,IAAM,GAEnBY,KAAM,CACJd,aAAc0C,OAAOC,iBACrB5C,cAAe,EACfG,UAAW,IAAM,GAEnBD,SAAQ,IACC,GAAGqT,KAAOlT,KAAOsG,MAI9BkN,EACAxT,EACAsG,EACArC,EAEJ,CACF,CAEA,gBAAMsN,EAAW,MAAEzP,IACjB,IAAKA,EAAM2G,OACT,MAAM,IAAIvM,MAAM,mCAElB,MAAO,CAAE6B,KAAM+D,EAAM2G,OAAQ4I,WAAY,GAAIC,WAAY,GAAIxP,QAC/D,CAEA,eAAM4Q,CAAUzO,EAAiB,CAAC,GAChC,MAAM8R,EAAM,GAAG/Z,KAAK0a,WAAW1a,KAAK2a,wCAC9B7X,QAAesX,MAAML,EAAK9R,GAChC,IAAKnF,EAAOuX,GACV,MAAM,IAAIna,MACR,QAAQ4C,EAAOwX,mBAAmBP,YAAcjX,EAAO0Q,UAG3D,MAAMzR,QAAae,EAAO8X,OACpBxE,QAAc3H,EAAO1M,EAAK+S,OAAO+F,KAAM5S,GAE7C,GAAImO,EAAM3N,YAAY,KAAOsL,EAC3B,MAAM,IAAI7T,MAAM,kBAElB,MAAMmW,EAAUD,EAAM3N,YAAY,GAE5BqS,EAAYvH,EADC6C,EAAMvS,SAAS,OAAQ,EAAG,EAAIwS,IAK3C0E,EAAkD,GAClDC,EAAmC,CAAC,EACpCC,EAAUH,EAAUlM,QAAO3B,GAAe,OAAVA,EAAEiD,MACxC,IAAK,MAAOlI,EAAOkT,KAAWD,EAAQzC,UAAW,CAC/C,IAAI7Q,EAAU,GACVxD,EAAS,EACb,IAAK,MAAMgX,KAAQD,EAAOnZ,KACP,OAAboZ,EAAKjL,IACPvI,EAAUwT,EAAK1X,MACO,OAAb0X,EAAKjL,MACd/L,GAAUgX,EAAK1X,OAGnBuX,EAASrT,GAAWK,EACpB+S,EAAS/S,GAAS,CAAEL,UAASxD,SAC/B,CAGA,OAFAnE,KAAKuW,WAAayE,EAClBhb,KAAKwW,WAAauE,EACXD,CACT,E","sources":["../../../node_modules/@gmod/abortable-promise-cache/src/AggregateAbortController.ts","../../../node_modules/@gmod/abortable-promise-cache/src/AggregateStatusReporter.ts","../../../node_modules/@gmod/abortable-promise-cache/src/AbortablePromiseCache.ts","../../../node_modules/@gmod/bam/src/virtualOffset.ts","../../../node_modules/@gmod/bam/src/chunk.ts","../../../node_modules/@gmod/bam/src/util.ts","../../../node_modules/@gmod/bam/src/indexFile.ts","../../../node_modules/@gmod/bam/src/bai.ts","../../../node_modules/@gmod/bam/src/csi.ts","../../../node_modules/@gmod/bam/src/constants.ts","../../../node_modules/@gmod/bam/src/record.ts","../../../node_modules/@gmod/bam/src/sam.ts","../../../node_modules/@gmod/bam/src/bamFile.ts","../../../node_modules/@gmod/bam/src/htsget.ts"],"sourcesContent":["class NullSignal {}\n\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nexport default class AggregateAbortController {\n  signals = new Set()\n  abortController = new AbortController()\n\n  /**\n   * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n   *  will be treated as a null-signal, and this abortcontroller will no\n   *  longer be abortable.\n   */\n  //@ts-ignore\n  addSignal(signal: AbortSignal = new NullSignal()): void {\n    if (this.signal.aborted) {\n      throw new Error('cannot add a signal, already aborted!')\n    }\n\n    // note that a NullSignal will never fire, so if we\n    // have one this thing will never actually abort\n    this.signals.add(signal)\n    if (signal.aborted) {\n      // handle the abort immediately if it is already aborted\n      // for some reason\n      this.handleAborted(signal)\n    } else if (typeof signal.addEventListener === 'function') {\n      signal.addEventListener('abort', () => {\n        this.handleAborted(signal)\n      })\n    }\n  }\n\n  handleAborted(signal: AbortSignal): void {\n    this.signals.delete(signal)\n    if (this.signals.size === 0) {\n      this.abortController.abort()\n    }\n  }\n\n  get signal(): AbortSignal {\n    return this.abortController.signal\n  }\n\n  abort(): void {\n    this.abortController.abort()\n  }\n}\n","export default class AggregateStatusReporter {\n  callbacks = new Set<Function>()\n  currentMessage: unknown\n\n  addCallback(callback: Function = () => {}): void {\n    this.callbacks.add(callback)\n    callback(this.currentMessage)\n  }\n\n  callback(message: unknown) {\n    this.currentMessage = message\n    for (const elt of this.callbacks) {\n      elt(message)\n    }\n  }\n}\n","import AggregateAbortController from './AggregateAbortController'\nimport AggregateStatusReporter from './AggregateStatusReporter'\n\ninterface Cache<U> {\n  delete: (key: string) => void\n  keys: () => Iterator<string>\n  get: (key: string) => U | undefined\n  set: (key: string, value: U) => void\n  has: (key: string) => boolean\n}\ntype FillCallback<T, U> = (\n  data: T,\n  signal?: AbortSignal,\n  statusCallback?: Function,\n) => Promise<U>\n\ninterface Entry<U> {\n  aborter: AggregateAbortController\n  settled: boolean\n  readonly aborted: boolean\n  statusReporter: AggregateStatusReporter\n  promise: Promise<U>\n}\nexport default class AbortablePromiseCache<T, U> {\n  /**\n   * @param {object} args constructor args\n   * @param {Function} args.fill fill callback, will be called with sig `fill(data, signal)`\n   * @param {object} args.cache backing store to use, must implement `get(key)`, `set(key, val)`,\n   *   `delete(key)`, and `keys() -> iterator`\n   */\n\n  private cache: Cache<Entry<U>>\n  private fillCallback: FillCallback<T, U>\n\n  constructor({\n    fill,\n    cache,\n  }: {\n    fill: FillCallback<T, U>\n    cache: Cache<Entry<U>>\n  }) {\n    if (typeof fill !== 'function') {\n      throw new TypeError('must pass a fill function')\n    }\n    if (typeof cache !== 'object') {\n      throw new TypeError('must pass a cache object')\n    }\n    if (\n      typeof cache.get !== 'function' ||\n      typeof cache.set !== 'function' ||\n      typeof cache.delete !== 'function'\n    ) {\n      throw new TypeError(\n        'cache must implement get(key), set(key, val), and and delete(key)',\n      )\n    }\n\n    this.cache = cache\n    this.fillCallback = fill\n  }\n\n  static isAbortException(exception: Error) {\n    return (\n      // DOMException\n      exception.name === 'AbortError' ||\n      // standard-ish non-DOM abort exception\n      //@ts-ignore\n      exception.code === 'ERR_ABORTED' ||\n      // stringified DOMException\n      exception.message === 'AbortError: aborted' ||\n      // stringified standard-ish exception\n      exception.message === 'Error: aborted'\n    )\n  }\n\n  evict(key: string, entry: Entry<U>) {\n    if (this.cache.get(key) === entry) {\n      this.cache.delete(key)\n    }\n  }\n\n  fill(key: string, data: T, signal?: AbortSignal, statusCallback?: Function) {\n    const aborter = new AggregateAbortController()\n    const statusReporter = new AggregateStatusReporter()\n    statusReporter.addCallback(statusCallback)\n    const newEntry: Entry<U> = {\n      aborter: aborter,\n      promise: this.fillCallback(data, aborter.signal, (message: unknown) => {\n        statusReporter.callback(message)\n      }),\n      settled: false,\n      statusReporter,\n      get aborted() {\n        return this.aborter.signal.aborted\n      },\n    }\n    newEntry.aborter.addSignal(signal)\n\n    // remove the fill from the cache when its abortcontroller fires, if still in there\n    newEntry.aborter.signal.addEventListener('abort', () => {\n      if (!newEntry.settled) {\n        this.evict(key, newEntry)\n      }\n    })\n\n    // chain off the cached promise to record when it settles\n    newEntry.promise\n      .then(\n        () => {\n          newEntry.settled = true\n        },\n        () => {\n          newEntry.settled = true\n\n          // if the fill throws an error (including abort) and is still in the cache, remove it\n          this.evict(key, newEntry)\n        },\n      )\n      .catch(error => {\n        // this will only be reached if there is some kind of\n        // bad bug in this library\n        console.error(error)\n        throw error\n      })\n\n    this.cache.set(key, newEntry)\n  }\n\n  static checkSinglePromise<U>(promise: Promise<U>, signal?: AbortSignal) {\n    // check just this signal for having been aborted, and abort the\n    // promise if it was, regardless of what happened with the cached\n    // response\n    function checkForSingleAbort() {\n      if (signal?.aborted) {\n        throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' })\n      }\n    }\n\n    return promise.then(\n      result => {\n        checkForSingleAbort()\n        return result\n      },\n      error => {\n        checkForSingleAbort()\n        throw error\n      },\n    )\n  }\n\n  has(key: string): boolean {\n    return this.cache.has(key)\n  }\n\n  /**\n   * Callback for getting status of the pending async\n   *\n   * @callback statusCallback\n   * @param {any} status, current status string or message object\n   */\n\n  /**\n   * @param {any} key cache key to use for this request\n   * @param {any} data data passed as the first argument to the fill callback\n   * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n   * @param {statusCallback} a callback to get the current status of a pending async operation\n   */\n  get(\n    key: string,\n    data: T,\n    signal?: AbortSignal,\n    statusCallback?: Function,\n  ): Promise<U> {\n    if (!signal && data instanceof AbortSignal) {\n      throw new TypeError(\n        'second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?',\n      )\n    }\n    const cacheEntry = this.cache.get(key)\n\n    if (cacheEntry) {\n      if (cacheEntry.aborted && !cacheEntry.settled) {\n        // if it's aborted but has not realized it yet, evict it and redispatch\n        this.evict(key, cacheEntry)\n        return this.get(key, data, signal, statusCallback)\n      }\n\n      if (cacheEntry.settled) {\n        // too late to abort, just return it\n        return cacheEntry.promise\n      }\n\n      // request is in-flight, add this signal to its list of signals,\n      // or if there is no signal, the aborter will become non-abortable\n      cacheEntry.aborter.addSignal(signal)\n      cacheEntry.statusReporter.addCallback(statusCallback)\n\n      return AbortablePromiseCache.checkSinglePromise(\n        cacheEntry.promise,\n        signal,\n      )\n    }\n\n    // if we got here, it is not in the cache. fill.\n    this.fill(key, data, signal, statusCallback)\n    return AbortablePromiseCache.checkSinglePromise(\n      //see https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#non-null-assertion-operator-postfix-\n\n      this.cache.get(key)!.promise,\n      signal,\n    )\n  }\n\n  /**\n   * delete the given entry from the cache. if it exists and its fill request has\n   * not yet settled, the fill will be signaled to abort.\n   *\n   * @param {any} key\n   */\n  delete(key: string) {\n    const cachedEntry = this.cache.get(key)\n    if (cachedEntry) {\n      if (!cachedEntry.settled) {\n        cachedEntry.aborter.abort()\n      }\n      this.cache.delete(key)\n    }\n  }\n\n  /**\n   * Clear all requests from the cache. Aborts any that have not settled.\n   * @returns {number} count of entries deleted\n   */\n  clear() {\n    // iterate without needing regenerator-runtime\n    const keyIter = this.cache.keys()\n    let deleteCount = 0\n    for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n      this.delete(result.value)\n      deleteCount += 1\n    }\n    return deleteCount\n  }\n}\n","export default class VirtualOffset {\n  public blockPosition: number\n  public dataPosition: number\n  constructor(blockPosition: number, dataPosition: number) {\n    this.blockPosition = blockPosition // < offset of the compressed data block\n    this.dataPosition = dataPosition // < offset into the uncompressed data\n  }\n\n  toString() {\n    return `${this.blockPosition}:${this.dataPosition}`\n  }\n\n  compareTo(b: VirtualOffset) {\n    return (\n      this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition\n    )\n  }\n\n  static min(...args: VirtualOffset[]) {\n    let min\n    let i = 0\n    for (; !min; i += 1) {\n      min = args[i]\n    }\n    for (; i < args.length; i += 1) {\n      if (min.compareTo(args[i]) > 0) {\n        min = args[i]\n      }\n    }\n    return min\n  }\n}\nexport function fromBytes(bytes: Buffer, offset = 0, bigendian = false) {\n  if (bigendian) {\n    throw new Error('big-endian virtual file offsets not implemented')\n  }\n\n  return new VirtualOffset(\n    bytes[offset + 7] * 0x10000000000 +\n      bytes[offset + 6] * 0x100000000 +\n      bytes[offset + 5] * 0x1000000 +\n      bytes[offset + 4] * 0x10000 +\n      bytes[offset + 3] * 0x100 +\n      bytes[offset + 2],\n    (bytes[offset + 1] << 8) | bytes[offset],\n  )\n}\n","import VirtualOffset from './virtualOffset'\n\n// little class representing a chunk in the index\nexport default class Chunk {\n  public buffer?: Buffer\n\n  constructor(\n    public minv: VirtualOffset,\n    public maxv: VirtualOffset,\n    public bin: number,\n    public _fetchedSize?: number,\n  ) {}\n\n  toUniqueString() {\n    return `${this.minv.toString()}..${this.maxv.toString()} (bin ${\n      this.bin\n    }, fetchedSize ${this.fetchedSize()})`\n  }\n\n  toString() {\n    return this.toUniqueString()\n  }\n\n  compareTo(b: Chunk) {\n    return (\n      this.minv.compareTo(b.minv) ||\n      this.maxv.compareTo(b.maxv) ||\n      this.bin - b.bin\n    )\n  }\n\n  fetchedSize() {\n    if (this._fetchedSize !== undefined) {\n      return this._fetchedSize\n    }\n    return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition\n  }\n}\n","import Long from 'long'\nimport Chunk from './chunk'\nimport VirtualOffset from './virtualOffset'\n\nexport function timeout(ms: number) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\nexport function longToNumber(long: Long) {\n  if (\n    long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n    long.lessThan(Number.MIN_SAFE_INTEGER)\n  ) {\n    throw new Error('integer overflow')\n  }\n  return long.toNumber()\n}\n\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal?: AbortSignal) {\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    // console.log('bam aborted!')\n    if (typeof DOMException === 'undefined') {\n      const e = new Error('aborted')\n      //@ts-ignore\n      e.code = 'ERR_ABORTED'\n      throw e\n    } else {\n      throw new DOMException('aborted', 'AbortError')\n    }\n  }\n}\n\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal?: AbortSignal) {\n  await Promise.resolve()\n  checkAbortSignal(signal)\n}\n\nexport function canMergeBlocks(chunk1: Chunk, chunk2: Chunk) {\n  return (\n    chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n    chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000\n  )\n}\n\nexport interface BamOpts {\n  viewAsPairs?: boolean\n  pairAcrossChr?: boolean\n  maxInsertSize?: number\n  signal?: AbortSignal\n}\n\nexport interface BaseOpts {\n  signal?: AbortSignal\n}\n\nexport function makeOpts(obj: AbortSignal | BaseOpts = {}): BaseOpts {\n  return 'aborted' in obj ? ({ signal: obj } as BaseOpts) : obj\n}\n\nexport function optimizeChunks(chunks: Chunk[], lowest?: VirtualOffset) {\n  const mergedChunks: Chunk[] = []\n  let lastChunk: Chunk | undefined\n\n  if (chunks.length === 0) {\n    return chunks\n  }\n\n  chunks.sort((c0, c1) => {\n    const dif = c0.minv.blockPosition - c1.minv.blockPosition\n    return dif === 0 ? c0.minv.dataPosition - c1.minv.dataPosition : dif\n  })\n\n  for (const chunk of chunks) {\n    if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n      if (lastChunk === undefined) {\n        mergedChunks.push(chunk)\n        lastChunk = chunk\n      } else {\n        if (canMergeBlocks(lastChunk, chunk)) {\n          if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n            lastChunk.maxv = chunk.maxv\n          }\n        } else {\n          mergedChunks.push(chunk)\n          lastChunk = chunk\n        }\n      }\n    }\n  }\n\n  return mergedChunks\n}\n\nexport function parsePseudoBin(bytes: Buffer, offset: number) {\n  const lineCount = longToNumber(\n    Long.fromBytesLE(\n      Array.prototype.slice.call(bytes, offset, offset + 8),\n      true,\n    ),\n  )\n  return { lineCount }\n}\n\nexport function findFirstData(\n  firstDataLine: VirtualOffset | undefined,\n  virtualOffset: VirtualOffset,\n) {\n  return firstDataLine\n    ? firstDataLine.compareTo(virtualOffset) > 0\n      ? virtualOffset\n      : firstDataLine\n    : virtualOffset\n}\n\nexport function parseNameBytes(\n  namesBytes: Buffer,\n  renameRefSeq: (arg: string) => string = s => s,\n) {\n  let currRefId = 0\n  let currNameStart = 0\n  const refIdToName = []\n  const refNameToId: Record<string, number> = {}\n  for (let i = 0; i < namesBytes.length; i += 1) {\n    if (!namesBytes[i]) {\n      if (currNameStart < i) {\n        let refName = namesBytes.toString('utf8', currNameStart, i)\n        refName = renameRefSeq(refName)\n        refIdToName[currRefId] = refName\n        refNameToId[refName] = currRefId\n      }\n      currNameStart = i + 1\n      currRefId += 1\n    }\n  }\n  return { refNameToId, refIdToName }\n}\n","import { GenericFilehandle } from 'generic-filehandle'\nimport Chunk from './chunk'\nimport { BaseOpts } from './util'\n\nexport default abstract class IndexFile {\n  public filehandle: GenericFilehandle\n  public renameRefSeq: (s: string) => string\n\n  /**\n   * @param {filehandle} filehandle\n   * @param {function} [renameRefSeqs]\n   */\n  constructor({\n    filehandle,\n    renameRefSeq = (n: string) => n,\n  }: {\n    filehandle: GenericFilehandle\n    renameRefSeq?: (a: string) => string\n  }) {\n    this.filehandle = filehandle\n    this.renameRefSeq = renameRefSeq\n  }\n  public abstract lineCount(refId: number): Promise<number>\n  public abstract indexCov(\n    refId: number,\n    start?: number,\n    end?: number,\n  ): Promise<{ start: number; end: number; score: number }[]>\n\n  public abstract blocksForRange(\n    chrId: number,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ): Promise<Chunk[]>\n}\n","import VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\n\nimport { optimizeChunks, parsePseudoBin, findFirstData, BaseOpts } from './util'\nimport IndexFile from './indexFile'\n\nconst BAI_MAGIC = 21578050 // BAI\\1\n\nfunction roundDown(n: number, multiple: number) {\n  return n - (n % multiple)\n}\nfunction roundUp(n: number, multiple: number) {\n  return n - (n % multiple) + multiple\n}\n\nfunction reg2bins(beg: number, end: number) {\n  end -= 1\n  return [\n    [0, 0],\n    [1 + (beg >> 26), 1 + (end >> 26)],\n    [9 + (beg >> 23), 9 + (end >> 23)],\n    [73 + (beg >> 20), 73 + (end >> 20)],\n    [585 + (beg >> 17), 585 + (end >> 17)],\n    [4681 + (beg >> 14), 4681 + (end >> 14)],\n  ]\n}\n\nexport default class BAI extends IndexFile {\n  public setupP?: ReturnType<BAI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  // fetch and parse the index\n  async _parse(opts?: BaseOpts) {\n    const bytes = (await this.filehandle.readFile(opts)) as Buffer\n\n    // check BAI magic numbers\n    if (bytes.readUInt32LE(0) !== BAI_MAGIC) {\n      throw new Error('Not a BAI file')\n    }\n\n    const refCount = bytes.readInt32LE(4)\n    const depth = 5\n    const binLimit = ((1 << ((depth + 1) * 3)) - 1) / 7\n\n    // read the indexes for each reference sequence\n    let curr = 8\n    let firstDataLine: VirtualOffset | undefined\n\n    type BinIndex = Record<string, Chunk[]>\n    type LinearIndex = VirtualOffset[]\n    const indices = new Array<{\n      binIndex: BinIndex\n      linearIndex: LinearIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      let stats\n\n      curr += 4\n      const binIndex: Record<number, Chunk[]> = {}\n\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin === binLimit + 1) {\n          curr += 4\n          stats = parsePseudoBin(bytes, curr + 16)\n          curr += 32\n        } else if (bin > binLimit + 1) {\n          throw new Error('bai index contains too many bins, please use CSI')\n        } else {\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k++) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      const linearCount = bytes.readInt32LE(curr)\n      curr += 4\n      // as we're going through the linear index, figure out the smallest\n      // virtual offset in the indexes, which tells us where the BAM header\n      // ends\n      const linearIndex = new Array<VirtualOffset>(linearCount)\n      for (let j = 0; j < linearCount; j++) {\n        const offset = fromBytes(bytes, curr)\n        curr += 8\n        firstDataLine = findFirstData(firstDataLine, offset)\n        linearIndex[j] = offset\n      }\n\n      indices[i] = { binIndex, linearIndex, stats }\n    }\n\n    return {\n      bai: true,\n      firstDataLine,\n      maxBlockSize: 1 << 16,\n      indices,\n      refCount,\n    }\n  }\n\n  async indexCov(\n    seqId: number,\n    start?: number,\n    end?: number,\n    opts: BaseOpts = {},\n  ): Promise<{ start: number; end: number; score: number }[]> {\n    const v = 16384\n    const range = start !== undefined\n    const indexData = await this.parse(opts)\n    const seqIdx = indexData.indices[seqId]\n    if (!seqIdx) {\n      return []\n    }\n    const { linearIndex = [], stats } = seqIdx\n    if (linearIndex.length === 0) {\n      return []\n    }\n    const e = end === undefined ? (linearIndex.length - 1) * v : roundUp(end, v)\n    const s = start === undefined ? 0 : roundDown(start, v)\n    const depths = range\n      ? new Array((e - s) / v)\n      : new Array(linearIndex.length - 1)\n    const totalSize = linearIndex[linearIndex.length - 1].blockPosition\n    if (e > (linearIndex.length - 1) * v) {\n      throw new Error('query outside of range of linear index')\n    }\n    let currentPos = linearIndex[s / v].blockPosition\n    for (let i = s / v, j = 0; i < e / v; i++, j++) {\n      depths[j] = {\n        score: linearIndex[i + 1].blockPosition - currentPos,\n        start: i * v,\n        end: i * v + v,\n      }\n      currentPos = linearIndex[i + 1].blockPosition\n    }\n    return depths.map(d => ({\n      ...d,\n      score: (d.score * (stats?.lineCount || 0)) / totalSize,\n    }))\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    if (!indexData) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    // List of bin #s that overlap min, max\n    const overlappingBins = reg2bins(min, max)\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const binChunk of binChunks) {\n            chunks.push(binChunk)\n          }\n        }\n      }\n    }\n\n    // Use the linear index to find minimum file position of chunks that could\n    // contain alignments in the region\n    const nintv = ba.linearIndex.length\n    let lowest: VirtualOffset | undefined\n    const minLin = Math.min(min >> 14, nintv - 1)\n    const maxLin = Math.min(max >> 14, nintv - 1)\n    for (let i = minLin; i <= maxLin; ++i) {\n      const vp = ba.linearIndex[i]\n      if (vp && (!lowest || vp.compareTo(lowest) < 0)) {\n        lowest = vp\n      }\n    }\n\n    return optimizeChunks(chunks, lowest)\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\nimport {\n  optimizeChunks,\n  findFirstData,\n  parsePseudoBin,\n  parseNameBytes,\n  BaseOpts,\n} from './util'\n\nimport IndexFile from './indexFile'\n\nconst CSI1_MAGIC = 21582659 // CSI\\1\nconst CSI2_MAGIC = 38359875 // CSI\\2\n\nfunction lshift(num: number, bits: number) {\n  return num * 2 ** bits\n}\nfunction rshift(num: number, bits: number) {\n  return Math.floor(num / 2 ** bits)\n}\n\nexport default class CSI extends IndexFile {\n  private maxBinNumber = 0\n  private depth = 0\n  private minShift = 0\n\n  public setupP?: ReturnType<CSI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  async indexCov() {\n    return []\n  }\n\n  parseAuxData(bytes: Buffer, offset: number) {\n    const formatFlags = bytes.readInt32LE(offset)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const format = (\n      { 0: 'generic', 1: 'SAM', 2: 'VCF' } as Record<number, string>\n    )[formatFlags & 0xf]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: bytes.readInt32LE(offset + 4),\n      start: bytes.readInt32LE(offset + 8),\n      end: bytes.readInt32LE(offset + 12),\n    }\n    const metaValue = bytes.readInt32LE(offset + 16)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : ''\n    const skipLines = bytes.readInt32LE(offset + 20)\n    const nameSectionLength = bytes.readInt32LE(offset + 24)\n\n    return {\n      columnNumbers,\n      coordinateType,\n      metaValue,\n      metaChar,\n      skipLines,\n      format,\n      formatFlags,\n      ...parseNameBytes(\n        bytes.subarray(offset + 28, offset + 28 + nameSectionLength),\n        this.renameRefSeq,\n      ),\n    }\n  }\n\n  // fetch and parse the index\n  async _parse(opts: { signal?: AbortSignal }) {\n    const buffer = await this.filehandle.readFile(opts)\n    const bytes = await unzip(buffer)\n\n    let csiVersion\n    // check TBI magic numbers\n    if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n      csiVersion = 1\n    } else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n      csiVersion = 2\n    } else {\n      throw new Error('Not a CSI file')\n      // TODO: do we need to support big-endian CSI files?\n    }\n\n    this.minShift = bytes.readInt32LE(4)\n    this.depth = bytes.readInt32LE(8)\n    this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7\n    const auxLength = bytes.readInt32LE(12)\n    const aux = auxLength >= 30 ? this.parseAuxData(bytes, 16) : undefined\n    const refCount = bytes.readInt32LE(16 + auxLength)\n\n    type BinIndex = Record<string, Chunk[]>\n\n    // read the indexes for each reference sequence\n    let curr = 16 + auxLength + 4\n    let firstDataLine: VirtualOffset | undefined\n    const indices = new Array<{\n      binIndex: BinIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      curr += 4\n      const binIndex: Record<string, Chunk[]> = {}\n      let stats // < provided by parsing a pseudo-bin, if present\n      for (let j = 0; j < binCount; j++) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin > this.maxBinNumber) {\n          stats = parsePseudoBin(bytes, curr + 28)\n          curr += 28 + 16\n        } else {\n          firstDataLine = findFirstData(firstDataLine, fromBytes(bytes, curr))\n          curr += 8\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      indices[i] = { binIndex, stats }\n    }\n\n    return {\n      csiVersion,\n      firstDataLine,\n      indices,\n      refCount,\n      csi: true,\n      maxBlockSize: 1 << 16,\n      ...aux,\n    }\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const ba = indexData?.indices[refId]\n    if (!ba) {\n      return []\n    }\n    const overlappingBins = this.reg2bins(min, max)\n\n    if (overlappingBins.length === 0) {\n      return []\n    }\n\n    const chunks = []\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const c of binChunks) {\n            chunks.push(c)\n          }\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, new VirtualOffset(0, 0))\n  }\n\n  /**\n   * calculate the list of bins that may overlap with region [beg,end)\n   * (zero-based half-open)\n   */\n  reg2bins(beg: number, end: number) {\n    beg -= 1 // < convert to 1-based closed\n    if (beg < 1) {\n      beg = 1\n    }\n    if (end > 2 ** 50) {\n      end = 2 ** 34\n    } // 17 GiB ought to be enough for anybody\n    end -= 1\n    let l = 0\n    let t = 0\n    let s = this.minShift + this.depth * 3\n    const bins = []\n    for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n      const b = t + rshift(beg, s)\n      const e = t + rshift(end, s)\n      if (e - b + bins.length > this.maxBinNumber) {\n        throw new Error(\n          `query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`,\n        )\n      }\n      bins.push([b, e])\n    }\n    return bins\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","export default {\n  //  the read is paired in sequencing, no matter whether it is mapped in a pair\n  BAM_FPAIRED: 1,\n  //  the read is mapped in a proper pair\n  BAM_FPROPER_PAIR: 2,\n  //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n  BAM_FUNMAP: 4,\n  //  the mate is unmapped\n  BAM_FMUNMAP: 8,\n  //  the read is mapped to the reverse strand\n  BAM_FREVERSE: 16,\n  //  the mate is mapped to the reverse strand\n  BAM_FMREVERSE: 32,\n  //  this is read1\n  BAM_FREAD1: 64,\n  //  this is read2\n  BAM_FREAD2: 128,\n  //  not primary alignment\n  BAM_FSECONDARY: 256,\n  //  QC failure\n  BAM_FQCFAIL: 512,\n  //  optical or PCR duplicate\n  BAM_FDUP: 1024,\n  //  supplementary alignment\n  BAM_FSUPPLEMENTARY: 2048,\n}\n","import Constants from './constants'\n\nconst SEQRET_DECODER = '=ACMGRSVTWYHKDBN'.split('')\nconst CIGAR_DECODER = 'MIDNSHP=X???????'.split('')\n\n/**\n * Class of each BAM record returned by this API.\n */\nexport default class BamRecord {\n  private data = {} as Record<string, any>\n  private bytes: { start: number; end: number; byteArray: Buffer }\n  private _id: number\n  private _tagOffset: number | undefined\n  private _tagList: string[] = []\n  private _allTagsParsed = false\n\n  public flags: any\n  public _refID: number\n  constructor(args: any) {\n    const { bytes, fileOffset } = args\n    const { byteArray, start } = bytes\n    this.data = { start: byteArray.readInt32LE(start + 8) }\n    this.bytes = bytes\n    this._id = fileOffset\n    this._refID = byteArray.readInt32LE(start + 4)\n    this.flags = (byteArray.readInt32LE(start + 16) & 0xffff0000) >> 16\n  }\n\n  get(field: string) {\n    //@ts-ignore\n    if (this[field]) {\n      //@ts-ignore\n      if (this.data[field]) {\n        return this.data[field]\n      }\n      //@ts-ignore\n      this.data[field] = this[field]()\n      return this.data[field]\n    }\n    return this._get(field.toLowerCase())\n  }\n\n  end() {\n    return this.get('start') + this.get('length_on_ref')\n  }\n\n  seq_id() {\n    return this._refID\n  }\n\n  // same as get(), except requires lower-case arguments.  used\n  // internally to save lots of calls to field.toLowerCase()\n  _get(field: string) {\n    if (field in this.data) {\n      return this.data[field]\n    }\n    this.data[field] = this._parseTag(field)\n    return this.data[field]\n  }\n\n  _tags() {\n    this._parseAllTags()\n\n    let tags = ['seq']\n\n    if (!this.isSegmentUnmapped()) {\n      tags.push(\n        'start',\n        'end',\n        'strand',\n        'score',\n        'qual',\n        'MQ',\n        'CIGAR',\n        'length_on_ref',\n        'template_length',\n      )\n    }\n    if (this.isPaired()) {\n      tags.push('next_segment_position', 'pair_orientation')\n    }\n    tags = tags.concat(this._tagList || [])\n\n    for (const k of Object.keys(this.data)) {\n      if (!k.startsWith('_') && k !== 'next_seq_id') {\n        tags.push(k)\n      }\n    }\n\n    const seen: Record<string, boolean> = {}\n    return tags.filter(t => {\n      if (\n        (t in this.data && this.data[t] === undefined) ||\n        t === 'CG' ||\n        t === 'cg'\n      ) {\n        return false\n      }\n\n      const lt = t.toLowerCase()\n      const s = seen[lt]\n      seen[lt] = true\n      return !s\n    })\n  }\n\n  parent() {\n    return\n  }\n\n  children() {\n    return this.get('subfeatures')\n  }\n\n  id() {\n    return this._id\n  }\n\n  // special parsers\n  /**\n   * Mapping quality score.\n   */\n  mq() {\n    const mq = (this.get('_bin_mq_nl') & 0xff00) >> 8\n    return mq === 255 ? undefined : mq\n  }\n\n  score() {\n    return this.get('mq')\n  }\n\n  qual() {\n    return this.qualRaw()?.join(' ')\n  }\n\n  qualRaw() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { start, byteArray } = this.bytes\n    const p =\n      start +\n      36 +\n      this.get('_l_read_name') +\n      this.get('_n_cigar_op') * 4 +\n      this.get('_seq_bytes')\n    const lseq = this.get('seq_length')\n    return byteArray.subarray(p, p + lseq)\n  }\n\n  strand() {\n    return this.isReverseComplemented() ? -1 : 1\n  }\n\n  multi_segment_next_segment_strand() {\n    if (this.isMateUnmapped()) {\n      return\n    }\n    return this.isMateReverseComplemented() ? -1 : 1\n  }\n\n  name() {\n    return this.get('_read_name')\n  }\n\n  _read_name() {\n    const nl = this.get('_l_read_name')\n    const { byteArray, start } = this.bytes\n    return byteArray.toString('ascii', start + 36, start + 36 + nl - 1)\n  }\n\n  /**\n   * Get the value of a tag, parsing the tags as far as necessary.\n   * Only called if we have not already parsed that field.\n   */\n  _parseTag(tagName?: string) {\n    // if all of the tags have been parsed and we're still being\n    // called, we already know that we have no such tag, because\n    // it would already have been cached.\n    if (this._allTagsParsed) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    let p =\n      this._tagOffset ||\n      start +\n        36 +\n        this.get('_l_read_name') +\n        this.get('_n_cigar_op') * 4 +\n        this.get('_seq_bytes') +\n        this.get('seq_length')\n\n    const blockEnd = this.bytes.end\n    let lcTag\n    while (p < blockEnd && lcTag !== tagName) {\n      const tag = String.fromCharCode(byteArray[p], byteArray[p + 1])\n      lcTag = tag.toLowerCase()\n      const type = String.fromCharCode(byteArray[p + 2])\n      p += 3\n\n      let value\n      switch (type) {\n        case 'A': {\n          value = String.fromCharCode(byteArray[p])\n          p += 1\n          break\n        }\n        case 'i': {\n          value = byteArray.readInt32LE(p)\n          p += 4\n          break\n        }\n        case 'I': {\n          value = byteArray.readUInt32LE(p)\n          p += 4\n          break\n        }\n        case 'c': {\n          value = byteArray.readInt8(p)\n          p += 1\n          break\n        }\n        case 'C': {\n          value = byteArray.readUInt8(p)\n          p += 1\n          break\n        }\n        case 's': {\n          value = byteArray.readInt16LE(p)\n          p += 2\n          break\n        }\n        case 'S': {\n          value = byteArray.readUInt16LE(p)\n          p += 2\n          break\n        }\n        case 'f': {\n          value = byteArray.readFloatLE(p)\n          p += 4\n          break\n        }\n        case 'Z':\n        case 'H': {\n          value = ''\n          while (p <= blockEnd) {\n            const cc = byteArray[p++]\n            if (cc === 0) {\n              break\n            } else {\n              value += String.fromCharCode(cc)\n            }\n          }\n          break\n        }\n        case 'B': {\n          value = ''\n          const cc = byteArray[p++]\n          const Btype = String.fromCharCode(cc)\n          const limit = byteArray.readInt32LE(p)\n          p += 4\n          if (Btype === 'i') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 'I') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readUInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readUInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 's') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'S') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'c') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'C') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'f') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readFloatLE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 4\n            }\n          }\n          break\n        }\n        default: {\n          console.warn(`Unknown BAM tag type '${type}', tags may be incomplete`)\n          value = undefined\n          p = blockEnd\n        } // stop parsing tags\n      }\n\n      this._tagOffset = p\n\n      this._tagList.push(tag)\n      if (lcTag === tagName) {\n        return value\n      }\n\n      this.data[lcTag] = value\n    }\n    this._allTagsParsed = true\n    return\n  }\n\n  _parseAllTags() {\n    this._parseTag('')\n  }\n\n  _parseCigar(cigar: string) {\n    return (\n      //@ts-ignore\n      cigar\n        .match(/\\d+\\D/g)\n        //@ts-ignore\n        .map(op => [/\\D/.exec(op)[0].toUpperCase(), Number.parseInt(op, 10)])\n    )\n  }\n\n  /**\n   * @returns {boolean} true if the read is paired, regardless of whether both\n   * segments are mapped\n   */\n  isPaired() {\n    return !!(this.flags & Constants.BAM_FPAIRED)\n  }\n\n  /** @returns {boolean} true if the read is paired, and both segments are mapped */\n  isProperlyPaired() {\n    return !!(this.flags & Constants.BAM_FPROPER_PAIR)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isSegmentUnmapped() {\n    return !!(this.flags & Constants.BAM_FUNMAP)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isMateUnmapped() {\n    return !!(this.flags & Constants.BAM_FMUNMAP)\n  }\n\n  /** @returns {boolean} true if the read is mapped to the reverse strand */\n  isReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FREVERSE)\n  }\n\n  /** @returns {boolean} true if the mate is mapped to the reverse strand */\n  isMateReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FMREVERSE)\n  }\n\n  /** @returns {boolean} true if this is read number 1 in a pair */\n  isRead1() {\n    return !!(this.flags & Constants.BAM_FREAD1)\n  }\n\n  /** @returns {boolean} true if this is read number 2 in a pair */\n  isRead2() {\n    return !!(this.flags & Constants.BAM_FREAD2)\n  }\n\n  /** @returns {boolean} true if this is a secondary alignment */\n  isSecondary() {\n    return !!(this.flags & Constants.BAM_FSECONDARY)\n  }\n\n  /** @returns {boolean} true if this read has failed QC checks */\n  isFailedQc() {\n    return !!(this.flags & Constants.BAM_FQCFAIL)\n  }\n\n  /** @returns {boolean} true if the read is an optical or PCR duplicate */\n  isDuplicate() {\n    return !!(this.flags & Constants.BAM_FDUP)\n  }\n\n  /** @returns {boolean} true if this is a supplementary alignment */\n  isSupplementary() {\n    return !!(this.flags & Constants.BAM_FSUPPLEMENTARY)\n  }\n\n  cigar() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    const numCigarOps = this.get('_n_cigar_op')\n    let p = start + 36 + this.get('_l_read_name')\n    const seqLen = this.get('seq_length')\n    let cigar = ''\n    let lref = 0\n\n    // check for CG tag by inspecting whether the CIGAR field\n    // contains a clip that consumes entire seqLen\n    let cigop = byteArray.readInt32LE(p)\n    let lop = cigop >> 4\n    let op = CIGAR_DECODER[cigop & 0xf]\n    if (op === 'S' && lop === seqLen) {\n      // if there is a CG the second CIGAR field will\n      // be a N tag the represents the length on ref\n      p += 4\n      cigop = byteArray.readInt32LE(p)\n      lop = cigop >> 4\n      op = CIGAR_DECODER[cigop & 0xf]\n      if (op !== 'N') {\n        console.warn('CG tag with no N tag')\n      }\n      this.data.length_on_ref = lop\n      return this.get('CG')\n    } else {\n      for (let c = 0; c < numCigarOps; ++c) {\n        cigop = byteArray.readInt32LE(p)\n        lop = cigop >> 4\n        op = CIGAR_DECODER[cigop & 0xf]\n        cigar += lop + op\n\n        // soft clip, hard clip, and insertion don't count toward\n        // the length on the reference\n        if (op !== 'H' && op !== 'S' && op !== 'I') {\n          lref += lop\n        }\n\n        p += 4\n      }\n\n      this.data.length_on_ref = lref\n      return cigar\n    }\n  }\n\n  length_on_ref() {\n    if (this.data.length_on_ref) {\n      return this.data.length_on_ref\n    } else {\n      this.get('cigar') // the length_on_ref is set as a side effect\n      return this.data.length_on_ref\n    }\n  }\n\n  _n_cigar_op() {\n    return this.get('_flag_nc') & 0xffff\n  }\n\n  _l_read_name() {\n    return this.get('_bin_mq_nl') & 0xff\n  }\n\n  /**\n   * number of bytes in the sequence field\n   */\n  _seq_bytes() {\n    return (this.get('seq_length') + 1) >> 1\n  }\n\n  getReadBases() {\n    return this.seq()\n  }\n\n  seq() {\n    const { byteArray, start } = this.bytes\n    const p =\n      start + 36 + this.get('_l_read_name') + this.get('_n_cigar_op') * 4\n    const seqBytes = this.get('_seq_bytes')\n    const len = this.get('seq_length')\n    let buf = ''\n    let i = 0\n    for (let j = 0; j < seqBytes; ++j) {\n      const sb = byteArray[p + j]\n      buf += SEQRET_DECODER[(sb & 0xf0) >> 4]\n      i++\n      if (i < len) {\n        buf += SEQRET_DECODER[sb & 0x0f]\n        i++\n      }\n    }\n    return buf\n  }\n\n  // adapted from igv.js\n  getPairOrientation() {\n    if (\n      !this.isSegmentUnmapped() &&\n      !this.isMateUnmapped() &&\n      this._refID === this._next_refid()\n    ) {\n      const s1 = this.isReverseComplemented() ? 'R' : 'F'\n      const s2 = this.isMateReverseComplemented() ? 'R' : 'F'\n      let o1 = ' '\n      let o2 = ' '\n      if (this.isRead1()) {\n        o1 = '1'\n        o2 = '2'\n      } else if (this.isRead2()) {\n        o1 = '2'\n        o2 = '1'\n      }\n\n      const tmp = []\n      const isize = this.template_length()\n      if (isize > 0) {\n        tmp[0] = s1\n        tmp[1] = o1\n        tmp[2] = s2\n        tmp[3] = o2\n      } else {\n        tmp[2] = s1\n        tmp[3] = o1\n        tmp[0] = s2\n        tmp[1] = o2\n      }\n      return tmp.join('')\n    }\n    return ''\n  }\n\n  _bin_mq_nl() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 12)\n  }\n\n  _flag_nc() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 16)\n  }\n\n  seq_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 20)\n  }\n\n  _next_refid() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 24)\n  }\n\n  _next_pos() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 28)\n  }\n\n  template_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 32)\n  }\n\n  toJSON() {\n    const data: Record<string, any> = {}\n    for (const k of Object.keys(this)) {\n      if (k.startsWith('_') || k === 'bytes') {\n        continue\n      }\n      //@ts-ignore\n      data[k] = this[k]\n    }\n\n    return data\n  }\n}\n","export function parseHeaderText(text: string) {\n  const lines = text.split(/\\r?\\n/)\n  const data: { tag: string; data: { tag: string; value: string }[] }[] = []\n  for (const line of lines) {\n    const [tag, ...fields] = line.split(/\\t/)\n    if (tag) {\n      data.push({\n        tag: tag.slice(1),\n        data: fields.map(f => {\n          const r = f.indexOf(':')\n          const fieldTag = f.slice(0, r)\n          const value = f.slice(r + 1)\n          return { tag: fieldTag, value }\n        }),\n      })\n    }\n  }\n  return data\n}\n","import { Buffer } from 'buffer'\nimport crc32 from 'crc/crc32'\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle'\nimport { LocalFile, RemoteFile, GenericFilehandle } from 'generic-filehandle'\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache'\nimport QuickLRU from 'quick-lru'\n\n// locals\nimport BAI from './bai'\nimport CSI from './csi'\nimport Chunk from './chunk'\nimport BAMFeature from './record'\nimport { parseHeaderText } from './sam'\nimport { checkAbortSignal, timeout, makeOpts, BamOpts, BaseOpts } from './util'\n\nexport const BAM_MAGIC = 21840194\n\nconst blockLen = 1 << 16\n\nasync function gen2array<T>(gen: AsyncIterable<T[]>): Promise<T[]> {\n  let out: T[] = []\n  for await (const x of gen) {\n    out = out.concat(x)\n  }\n  return out\n}\n\ninterface Args {\n  chunk: Chunk\n  opts: BaseOpts\n}\n\nclass NullFilehandle {\n  public read(): Promise<any> {\n    throw new Error('never called')\n  }\n  public stat(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public readFile(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public close(): Promise<any> {\n    throw new Error('never called')\n  }\n}\nexport default class BamFile {\n  public renameRefSeq: (a: string) => string\n  public bam: GenericFilehandle\n  public header?: string\n  public chrToIndex?: Record<string, number>\n  public indexToChr?: { refName: string; length: number }[]\n  public yieldThreadTime: number\n  public index?: BAI | CSI\n  public htsget = false\n  public headerP?: ReturnType<BamFile['getHeaderPre']>\n\n  private featureCache = new AbortablePromiseCache<Args, BAMFeature[]>({\n    cache: new QuickLRU({\n      maxSize: 50,\n    }),\n    fill: async (args: Args, signal) => {\n      const { chunk, opts } = args\n      const { data, cpositions, dpositions } = await this._readChunk({\n        chunk,\n        opts: { ...opts, signal },\n      })\n      return this.readBamFeatures(data, cpositions, dpositions, chunk)\n    },\n  })\n\n  constructor({\n    bamFilehandle,\n    bamPath,\n    bamUrl,\n    baiPath,\n    baiFilehandle,\n    baiUrl,\n    csiPath,\n    csiFilehandle,\n    csiUrl,\n    htsget,\n    yieldThreadTime = 100,\n    renameRefSeqs = n => n,\n  }: {\n    bamFilehandle?: GenericFilehandle\n    bamPath?: string\n    bamUrl?: string\n    baiPath?: string\n    baiFilehandle?: GenericFilehandle\n    baiUrl?: string\n    csiPath?: string\n    csiFilehandle?: GenericFilehandle\n    csiUrl?: string\n    renameRefSeqs?: (a: string) => string\n    yieldThreadTime?: number\n    htsget?: boolean\n  }) {\n    this.renameRefSeq = renameRefSeqs\n\n    if (bamFilehandle) {\n      this.bam = bamFilehandle\n    } else if (bamPath) {\n      this.bam = new LocalFile(bamPath)\n    } else if (bamUrl) {\n      this.bam = new RemoteFile(bamUrl)\n    } else if (htsget) {\n      this.htsget = true\n      this.bam = new NullFilehandle()\n    } else {\n      throw new Error('unable to initialize bam')\n    }\n    if (csiFilehandle) {\n      this.index = new CSI({ filehandle: csiFilehandle })\n    } else if (csiPath) {\n      this.index = new CSI({ filehandle: new LocalFile(csiPath) })\n    } else if (csiUrl) {\n      this.index = new CSI({ filehandle: new RemoteFile(csiUrl) })\n    } else if (baiFilehandle) {\n      this.index = new BAI({ filehandle: baiFilehandle })\n    } else if (baiPath) {\n      this.index = new BAI({ filehandle: new LocalFile(baiPath) })\n    } else if (baiUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(baiUrl) })\n    } else if (bamPath) {\n      this.index = new BAI({ filehandle: new LocalFile(`${bamPath}.bai`) })\n    } else if (bamUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(`${bamUrl}.bai`) })\n    } else if (htsget) {\n      this.htsget = true\n    } else {\n      throw new Error('unable to infer index format')\n    }\n    this.yieldThreadTime = yieldThreadTime\n  }\n\n  async getHeaderPre(origOpts?: BaseOpts) {\n    const opts = makeOpts(origOpts)\n    if (!this.index) {\n      return\n    }\n    const indexData = await this.index.parse(opts)\n    const ret = indexData.firstDataLine\n      ? indexData.firstDataLine.blockPosition + 65535\n      : undefined\n    let buffer\n    if (ret) {\n      const s = ret + blockLen\n      const res = await this.bam.read(Buffer.alloc(s), 0, s, 0, opts)\n      if (!res.bytesRead) {\n        throw new Error('Error reading header')\n      }\n      buffer = res.buffer.subarray(0, Math.min(res.bytesRead, ret))\n    } else {\n      buffer = await this.bam.readFile(opts)\n    }\n\n    const uncba = await unzip(buffer)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n\n    this.header = uncba.toString('utf8', 8, 8 + headLen)\n    const { chrToIndex, indexToChr } = await this._readRefSeqs(\n      headLen + 8,\n      65535,\n      opts,\n    )\n    this.chrToIndex = chrToIndex\n    this.indexToChr = indexToChr\n\n    return parseHeaderText(this.header)\n  }\n\n  getHeader(opts?: BaseOpts) {\n    if (!this.headerP) {\n      this.headerP = this.getHeaderPre(opts).catch(e => {\n        this.headerP = undefined\n        throw e\n      })\n    }\n    return this.headerP\n  }\n\n  async getHeaderText(opts: BaseOpts = {}) {\n    await this.getHeader(opts)\n    return this.header\n  }\n\n  // the full length of the refseq block is not given in advance so this grabs\n  // a chunk and doubles it if all refseqs haven't been processed\n  async _readRefSeqs(\n    start: number,\n    refSeqBytes: number,\n    opts?: BaseOpts,\n  ): Promise<{\n    chrToIndex: Record<string, number>\n    indexToChr: { refName: string; length: number }[]\n  }> {\n    if (start > refSeqBytes) {\n      return this._readRefSeqs(start, refSeqBytes * 2, opts)\n    }\n    const size = refSeqBytes + blockLen\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      refSeqBytes,\n      0,\n      opts,\n    )\n    if (!bytesRead) {\n      throw new Error('Error reading refseqs from header')\n    }\n    const uncba = await unzip(\n      buffer.subarray(0, Math.min(bytesRead, refSeqBytes)),\n    )\n    const nRef = uncba.readInt32LE(start)\n    let p = start + 4\n    const chrToIndex: Record<string, number> = {}\n    const indexToChr: { refName: string; length: number }[] = []\n    for (let i = 0; i < nRef; i += 1) {\n      const lName = uncba.readInt32LE(p)\n      const refName = this.renameRefSeq(\n        uncba.toString('utf8', p + 4, p + 4 + lName - 1),\n      )\n      const lRef = uncba.readInt32LE(p + lName + 4)\n\n      chrToIndex[refName] = i\n      indexToChr.push({ refName, length: lRef })\n\n      p = p + 8 + lName\n      if (p > uncba.length) {\n        console.warn(\n          `BAM header is very big.  Re-fetching ${refSeqBytes} bytes.`,\n        )\n        return this._readRefSeqs(start, refSeqBytes * 2, opts)\n      }\n    }\n    return { chrToIndex, indexToChr }\n  }\n\n  async getRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    return gen2array(this.streamRecordsForRange(chr, min, max, opts))\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    await this.getHeader(opts)\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined || !this.index) {\n      yield []\n    } else {\n      const chunks = await this.index.blocksForRange(chrId, min - 1, max, opts)\n      yield* this._fetchChunkFeatures(chunks, chrId, min, max, opts)\n    }\n  }\n\n  async *_fetchChunkFeatures(\n    chunks: Chunk[],\n    chrId: number,\n    min: number,\n    max: number,\n    opts: BamOpts = {},\n  ) {\n    const { viewAsPairs } = opts\n    const feats = [] as BAMFeature[][]\n    let done = false\n\n    for (const chunk of chunks) {\n      const records = await this.featureCache.get(\n        chunk.toString(),\n        { chunk, opts },\n        opts.signal,\n      )\n\n      const recs = [] as BAMFeature[]\n      for (const feature of records) {\n        if (feature.seq_id() === chrId) {\n          if (feature.get('start') >= max) {\n            // past end of range, can stop iterating\n            done = true\n            break\n          } else if (feature.get('end') >= min) {\n            // must be in range\n            recs.push(feature)\n          }\n        }\n      }\n      feats.push(recs)\n      yield recs\n      if (done) {\n        break\n      }\n    }\n\n    checkAbortSignal(opts.signal)\n    if (viewAsPairs) {\n      yield this.fetchPairs(chrId, feats, opts)\n    }\n  }\n\n  async fetchPairs(chrId: number, feats: BAMFeature[][], opts: BamOpts) {\n    const { pairAcrossChr, maxInsertSize = 200000 } = opts\n    const unmatedPairs: Record<string, boolean> = {}\n    const readIds: Record<string, number> = {}\n    feats.map(ret => {\n      const readNames: Record<string, number> = {}\n      for (const element of ret) {\n        const name = element.name()\n        const id = element.id()\n        if (!readNames[name]) {\n          readNames[name] = 0\n        }\n        readNames[name]++\n        readIds[id] = 1\n      }\n      for (const [k, v] of Object.entries(readNames)) {\n        if (v === 1) {\n          unmatedPairs[k] = true\n        }\n      }\n    })\n\n    const matePromises: Promise<Chunk[]>[] = []\n    feats.map(ret => {\n      for (const f of ret) {\n        const name = f.name()\n        const start = f.get('start')\n        const pnext = f._next_pos()\n        const rnext = f._next_refid()\n        if (\n          this.index &&\n          unmatedPairs[name] &&\n          (pairAcrossChr ||\n            (rnext === chrId && Math.abs(start - pnext) < maxInsertSize))\n        ) {\n          matePromises.push(\n            this.index.blocksForRange(rnext, pnext, pnext + 1, opts),\n          )\n        }\n      }\n    })\n\n    // filter out duplicate chunks (the blocks are lists of chunks, blocks are\n    // concatenated, then filter dup chunks)\n    const map = new Map<string, Chunk>()\n    const res = await Promise.all(matePromises)\n    for (const m of res.flat()) {\n      if (!map.has(m.toString())) {\n        map.set(m.toString(), m)\n      }\n    }\n\n    const mateFeatPromises = await Promise.all(\n      [...map.values()].map(async c => {\n        const { data, cpositions, dpositions, chunk } = await this._readChunk({\n          chunk: c,\n          opts,\n        })\n        const mateRecs = [] as BAMFeature[]\n        for (const feature of await this.readBamFeatures(\n          data,\n          cpositions,\n          dpositions,\n          chunk,\n        )) {\n          if (unmatedPairs[feature.get('name')] && !readIds[feature.id()]) {\n            mateRecs.push(feature)\n          }\n        }\n        return mateRecs\n      }),\n    )\n    return mateFeatPromises.flat()\n  }\n\n  async _readRegion(position: number, size: number, opts: BaseOpts = {}) {\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      size,\n      position,\n      opts,\n    )\n\n    return buffer.subarray(0, Math.min(bytesRead, size))\n  }\n\n  async _readChunk({ chunk, opts }: { chunk: Chunk; opts: BaseOpts }) {\n    const buffer = await this._readRegion(\n      chunk.minv.blockPosition,\n      chunk.fetchedSize(),\n      opts,\n    )\n\n    const {\n      buffer: data,\n      cpositions,\n      dpositions,\n    } = await unzipChunkSlice(buffer, chunk)\n    return { data, cpositions, dpositions, chunk }\n  }\n\n  async readBamFeatures(\n    ba: Buffer,\n    cpositions: number[],\n    dpositions: number[],\n    chunk: Chunk,\n  ) {\n    let blockStart = 0\n    const sink = [] as BAMFeature[]\n    let pos = 0\n    let last = +Date.now()\n\n    while (blockStart + 4 < ba.length) {\n      const blockSize = ba.readInt32LE(blockStart)\n      const blockEnd = blockStart + 4 + blockSize - 1\n\n      // increment position to the current decompressed status\n      if (dpositions) {\n        while (blockStart + chunk.minv.dataPosition >= dpositions[pos++]) {}\n        pos--\n      }\n\n      // only try to read the feature if we have all the bytes for it\n      if (blockEnd < ba.length) {\n        const feature = new BAMFeature({\n          bytes: {\n            byteArray: ba,\n            start: blockStart,\n            end: blockEnd,\n          },\n          // the below results in an automatically calculated file-offset based\n          // ID if the info for that is available, otherwise crc32 of the\n          // features\n          //\n          // cpositions[pos] refers to actual file offset of a bgzip block\n          // boundaries\n          //\n          // we multiply by (1 <<8) in order to make sure each block has a\n          // \"unique\" address space so that data in that block could never\n          // overlap\n          //\n          // then the blockStart-dpositions is an uncompressed file offset from\n          // that bgzip block boundary, and since the cpositions are multiplied\n          // by (1 << 8) these uncompressed offsets get a unique space\n          //\n          // this has an extra chunk.minv.dataPosition added on because it\n          // blockStart starts at 0 instead of chunk.minv.dataPosition\n          //\n          // the +1 is just to avoid any possible uniqueId 0 but this does not\n          // realistically happen\n          fileOffset:\n            cpositions.length > 0\n              ? cpositions[pos] * (1 << 8) +\n                (blockStart - dpositions[pos]) +\n                chunk.minv.dataPosition +\n                1\n              : // must be slice, not subarray for buffer polyfill on web\n                crc32.signed(ba.slice(blockStart, blockEnd)),\n        })\n\n        sink.push(feature)\n        if (this.yieldThreadTime && +Date.now() - last > this.yieldThreadTime) {\n          await timeout(1)\n          last = +Date.now()\n        }\n      }\n\n      blockStart = blockEnd + 1\n    }\n    return sink\n  }\n\n  async hasRefSeq(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? false : this.index?.hasRefSeq(seqId)\n  }\n\n  async lineCount(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined || !this.index ? 0 : this.index.lineCount(seqId)\n  }\n\n  async indexCov(seqName: string, start?: number, end?: number) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? [] : this.index.indexCov(seqId, start, end)\n  }\n\n  async blocksForRange(\n    seqName: string,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined\n      ? []\n      : this.index.blocksForRange(seqId, start, end, opts)\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport { Buffer } from 'buffer'\nimport { BaseOpts, BamOpts } from './util'\nimport BamFile, { BAM_MAGIC } from './bamFile'\nimport Chunk from './chunk'\nimport { parseHeaderText } from './sam'\n\ninterface HtsgetChunk {\n  url: string\n  headers?: Record<string, string>\n}\nasync function concat(arr: HtsgetChunk[], opts?: Record<string, any>) {\n  const res = await Promise.all(\n    arr.map(async chunk => {\n      const { url, headers } = chunk\n      if (url.startsWith('data:')) {\n        return Buffer.from(url.split(',')[1], 'base64')\n      } else {\n        //remove referer header, it is not even allowed to be specified\n        // @ts-expect-error\n\n        const { referer, ...rest } = headers\n        const res = await fetch(url, {\n          ...opts,\n          headers: { ...opts?.headers, ...rest },\n        })\n        if (!res.ok) {\n          throw new Error(\n            `HTTP ${res.status} fetching ${url}: ${await res.text()}`,\n          )\n        }\n        return Buffer.from(await res.arrayBuffer())\n      }\n    }),\n  )\n\n  return Buffer.concat(await Promise.all(res.map(elt => unzip(elt))))\n}\n\nexport default class HtsgetFile extends BamFile {\n  private baseUrl: string\n\n  private trackId: string\n\n  constructor(args: { trackId: string; baseUrl: string }) {\n    super({ htsget: true })\n    this.baseUrl = args.baseUrl\n    this.trackId = args.trackId\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    const base = `${this.baseUrl}/${this.trackId}`\n    const url = `${base}?referenceName=${chr}&start=${min}&end=${max}&format=BAM`\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined) {\n      yield []\n    } else {\n      const result = await fetch(url, { ...opts })\n      if (!result.ok) {\n        throw new Error(\n          `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n        )\n      }\n      const data = await result.json()\n      const uncba = await concat(data.htsget.urls.slice(1), opts)\n\n      yield* this._fetchChunkFeatures(\n        [\n          // fake stuff to pretend to be a Chunk\n          {\n            buffer: uncba,\n            _fetchedSize: undefined,\n            bin: 0,\n            compareTo() {\n              return 0\n            },\n            toUniqueString() {\n              return `${chr}_${min}_${max}`\n            },\n            fetchedSize() {\n              return 0\n            },\n            minv: {\n              dataPosition: 0,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            maxv: {\n              dataPosition: Number.MAX_SAFE_INTEGER,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            toString() {\n              return `${chr}_${min}_${max}`\n            },\n          },\n        ],\n        chrId,\n        min,\n        max,\n        opts,\n      )\n    }\n  }\n\n  async _readChunk({ chunk }: { chunk: Chunk; opts: BaseOpts }) {\n    if (!chunk.buffer) {\n      throw new Error('expected chunk.buffer in htsget')\n    }\n    return { data: chunk.buffer, cpositions: [], dpositions: [], chunk }\n  }\n\n  async getHeader(opts: BaseOpts = {}) {\n    const url = `${this.baseUrl}/${this.trackId}?referenceName=na&class=header`\n    const result = await fetch(url, opts)\n    if (!result.ok) {\n      throw new Error(\n        `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n      )\n    }\n    const data = await result.json()\n    const uncba = await concat(data.htsget.urls, opts)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n    const headerText = uncba.toString('utf8', 8, 8 + headLen)\n    const samHeader = parseHeaderText(headerText)\n\n    // use the @SQ lines in the header to figure out the\n    // mapping between ref ref ID numbers and names\n    const idToName: { refName: string; length: number }[] = []\n    const nameToId: Record<string, number> = {}\n    const sqLines = samHeader.filter(l => l.tag === 'SQ')\n    for (const [refId, sqLine] of sqLines.entries()) {\n      let refName = ''\n      let length = 0\n      for (const item of sqLine.data) {\n        if (item.tag === 'SN') {\n          refName = item.value\n        } else if (item.tag === 'LN') {\n          length = +item.value\n        }\n      }\n      nameToId[refName] = refId\n      idToName[refId] = { refName, length }\n    }\n    this.chrToIndex = nameToId\n    this.indexToChr = idToName\n    return samHeader\n  }\n}\n"],"names":["NullSignal","AggregateAbortController","signals","Set","abortController","AbortController","addSignal","signal","this","aborted","Error","add","handleAborted","addEventListener","delete","size","abort","AggregateStatusReporter","callbacks","addCallback","callback","currentMessage","message","elt","AbortablePromiseCache","constructor","fill","cache","TypeError","get","set","fillCallback","isAbortException","exception","name","code","evict","key","entry","data","statusCallback","aborter","statusReporter","newEntry","promise","settled","then","catch","error","console","checkSinglePromise","checkForSingleAbort","Object","assign","result","has","AbortSignal","cacheEntry","cachedEntry","clear","keyIter","keys","deleteCount","next","done","value","VirtualOffset","blockPosition","dataPosition","toString","compareTo","b","min","args","i","length","fromBytes","bytes","offset","bigendian","Chunk","minv","maxv","bin","_fetchedSize","toUniqueString","fetchedSize","undefined","timeout","ms","Promise","resolve","setTimeout","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","sort","c0","c1","dif","chunk","push","chunk1","chunk2","parsePseudoBin","lineCount","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","longToNumber","Array","prototype","slice","call","findFirstData","firstDataLine","virtualOffset","parseNameBytes","namesBytes","renameRefSeq","s","currRefId","currNameStart","refIdToName","refNameToId","refName","IndexFile","filehandle","n","BAI","refId","opts","parse","indices","stats","_parse","readFile","readUInt32LE","refCount","readInt32LE","curr","binCount","binIndex","j","binLimit","chunkCount","k","u","v","linearCount","linearIndex","bai","maxBlockSize","indexCov","seqId","start","end","range","seqIdx","e","roundDown","depths","totalSize","currentPos","score","map","d","blocksForRange","max","indexData","ba","overlappingBins","beg","binChunks","binChunk","nintv","minLin","Math","maxLin","vp","setupP","hasRefSeq","rshift","num","bits","floor","CSI","maxBinNumber","depth","minShift","parseAuxData","formatFlags","coordinateType","format","columnNumbers","ref","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","subarray","buffer","unzip","csiVersion","auxLength","aux","csi","reg2bins","c","l","t","bins","SEQRET_DECODER","split","CIGAR_DECODER","BamRecord","_tagList","_allTagsParsed","fileOffset","byteArray","_id","_refID","flags","field","_get","toLowerCase","seq_id","_parseTag","_tags","_parseAllTags","tags","isSegmentUnmapped","isPaired","concat","startsWith","seen","filter","lt","parent","children","id","mq","qual","qualRaw","join","p","lseq","strand","isReverseComplemented","multi_segment_next_segment_strand","isMateUnmapped","isMateReverseComplemented","_read_name","nl","tagName","_tagOffset","blockEnd","lcTag","tag","type","readInt8","readUInt8","readInt16LE","readUInt16LE","readFloatLE","cc","Btype","limit","cigop","warn","_parseCigar","cigar","match","op","exec","toUpperCase","parseInt","isProperlyPaired","isRead1","isRead2","isSecondary","isFailedQc","isDuplicate","isSupplementary","numCigarOps","seqLen","lref","lop","length_on_ref","_n_cigar_op","_l_read_name","_seq_bytes","getReadBases","seq","seqBytes","len","buf","sb","getPairOrientation","_next_refid","s1","s2","o1","o2","tmp","template_length","_bin_mq_nl","_flag_nc","seq_length","_next_pos","toJSON","parseHeaderText","text","lines","line","fields","f","r","indexOf","BAM_MAGIC","NullFilehandle","read","stat","close","BamFile","bamFilehandle","bamPath","bamUrl","baiPath","baiFilehandle","baiUrl","csiPath","csiFilehandle","csiUrl","htsget","yieldThreadTime","renameRefSeqs","featureCache","A","maxSize","async","cpositions","dpositions","_readChunk","readBamFeatures","bam","index","getHeaderPre","origOpts","obj","makeOpts","ret","res","Buffer","alloc","bytesRead","uncba","headLen","header","chrToIndex","indexToChr","_readRefSeqs","getHeader","headerP","getHeaderText","refSeqBytes","nRef","lName","lRef","getRecordsForRange","chr","gen","out","x","gen2array","streamRecordsForRange","chrId","_fetchChunkFeatures","viewAsPairs","feats","records","recs","feature","DOMException","checkAbortSignal","fetchPairs","pairAcrossChr","maxInsertSize","unmatedPairs","readIds","readNames","element","entries","matePromises","pnext","rnext","abs","Map","all","m","flat","values","mateRecs","_readRegion","position","blockStart","sink","pos","last","Date","now","crc32","signed","seqName","arr","url","headers","from","referer","rest","fetch","ok","status","arrayBuffer","HtsgetFile","super","baseUrl","trackId","json","urls","samHeader","idToName","nameToId","sqLines","sqLine","item"],"sourceRoot":""}